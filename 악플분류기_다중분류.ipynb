{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJumOSbc0_84"
      },
      "source": [
        "# 악플 분류기 - 다중분류\n",
        "- 데이터: https://github.com/smilegate-ai/korean_unsmile_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S766WUh3J_cb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GSgpe1q-Kf6W"
      },
      "outputs": [],
      "source": [
        "# 데이터 불러오기\n",
        "train_df = pd.read_csv(\"/content/unsmile_train_v1.0.tsv\",delimiter='\\t')\n",
        "test_df = pd.read_csv(\"/content/unsmile_valid_v1.0.tsv\", delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "FN35wYipfHTh",
        "outputId": "eb27e95b-cf64-414e-d40b-612a5f9b3886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15005, 12) (3737, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  문장  여성/가족  남성  성소수자  인종/국적  \\\n",
              "0                             일안하는 시간은 쉬고싶어서 그런게 아닐까      0   0     0      0   \n",
              "1  아동성범죄와 페도버는 기록바 끊어져 영원히 고통 받는다. 무슬림 50퍼 근친이다. ...      0   0     0      0   \n",
              "2  루나 솔로앨범 나왔을 때부터 머모 기운 있었음 ㅇㅇ Keep o  doin 진짜 띵...      0   0     0      0   \n",
              "\n",
              "   연령  지역  종교  기타 혐오  악플/욕설  clean  개인지칭  \n",
              "0   0   0   0      0      0      1     0  \n",
              "1   0   0   1      0      0      0     0  \n",
              "2   0   0   0      0      0      1     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d99a3327-5a5e-43e1-bce1-5ea30c64d75f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타 혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "      <th>개인지칭</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>일안하는 시간은 쉬고싶어서 그런게 아닐까</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>아동성범죄와 페도버는 기록바 끊어져 영원히 고통 받는다. 무슬림 50퍼 근친이다. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>루나 솔로앨범 나왔을 때부터 머모 기운 있었음 ㅇㅇ Keep o  doin 진짜 띵...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d99a3327-5a5e-43e1-bce1-5ea30c64d75f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d99a3327-5a5e-43e1-bce1-5ea30c64d75f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d99a3327-5a5e-43e1-bce1-5ea30c64d75f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "print(train_df.shape, test_df.shape)\n",
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIEEzkynfSIK"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4GDel_AfVVV"
      },
      "source": [
        "- train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJud5W4lKigh",
        "outputId": "a88d2e7b-b6c2-4652-d5cb-0bc80df09f10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null 값 체크\n",
        "train_df.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hOekkV6Kl1P",
        "outputId": "98c2be76-a02b-46ea-e7f7-48d7ad7d5d20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((15005, 12), 15004)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 중복 데이터 확인\n",
        "train_df.shape, train_df.문장.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_DUWt-c1aVM",
        "outputId": "449a4282-bacc-4ad7-fcbc-5f5201e89b98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15004, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 중복 데이터 제거\n",
        "train_df.drop_duplicates(subset=['문장'], inplace=True)\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "du4IN2Ir5XG5",
        "outputId": "c23ad015-bdd2-40d8-f45d-e1c5c0d7cedc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타 혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "      <th>개인지칭</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5876</th>\n",
              "      <td>혹시 돼지한명이랑 멸치 두명 무리 아니노 ㅋ 노천탕에서 자주봄 거기 사장들 달로 끊...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11942</th>\n",
              "      <td>누가 대통령이 지나가다가 여자 하나 성폭행했다고 고발해도 안했다는 증거 없으니 잡아...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      문장  여성/가족  남성  성소수자  \\\n",
              "5876   혹시 돼지한명이랑 멸치 두명 무리 아니노 ㅋ 노천탕에서 자주봄 거기 사장들 달로 끊...      0   0     0   \n",
              "11942  누가 대통령이 지나가다가 여자 하나 성폭행했다고 고발해도 안했다는 증거 없으니 잡아...      0   0     0   \n",
              "\n",
              "       인종/국적  연령  지역  종교  기타 혐오  악플/욕설  clean  개인지칭  \n",
              "5876       0   0   0   0      0      0      0     0  \n",
              "11942      0   0   0   0      0      0      0     0  "
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 분류가 안되어 있는 데이터 확인\n",
        "train_df[train_df.sum(axis=1) == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rmZjTjJi5dK4"
      },
      "outputs": [],
      "source": [
        "# 분류 안되어 있는 데이터 삭제\n",
        "train_df = train_df[train_df.sum(axis=1) != 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv7w5Ra3fq5i"
      },
      "source": [
        "- test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdK75sSwfsuZ",
        "outputId": "777f458c-33e2-4549-8fff-37b2854afa23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null 값 체크\n",
        "test_df.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmit9Jsdfx0X",
        "outputId": "f14cac66-322c-4448-f9a3-46463a0f762c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3737, 12), 3737)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 중복 데이터 확인\n",
        "test_df.shape, test_df.문장.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "zE28yhj_5ni9",
        "outputId": "f17660a9-ddc4-4bfd-fa81-32816d6f4091"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타 혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "      <th>개인지칭</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [문장, 여성/가족, 남성, 성소수자, 인종/국적, 연령, 지역, 종교, 기타 혐오, 악플/욕설, clean, 개인지칭]\n",
              "Index: []"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 분류가 안되어 있는 데이터 확인\n",
        "test_df[test_df.sum(axis=1) == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB1t0SEP5zQm"
      },
      "source": [
        "## 텍스트 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3aEp41q54Dt"
      },
      "source": [
        "- train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOokoq_t516o",
        "outputId": "1597cf0f-def6-4f11-c03c-38fb92beb1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14978, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
        "train_df.문장 = train_df.문장.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ').str.strip()\n",
        "train_df.문장.replace('', np.nan, inplace=True)\n",
        "print(train_df.문장.isna().sum())\n",
        "train_df.dropna(how='any', inplace=True)\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVzaeNqt59MF"
      },
      "source": [
        "- test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkgUd2Vg58WZ",
        "outputId": "6ac09760-6900-41b1-961b-e3ab061ff6e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3730, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
        "test_df.문장 = test_df.문장.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ').str.strip()\n",
        "test_df.문장.replace('', np.nan, inplace=True)\n",
        "print(test_df.문장.isna().sum())\n",
        "test_df.dropna(how='any', inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "test_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdHmL6byxeT3"
      },
      "source": [
        "- 데이터 분포"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDjX7UUhxb-q",
        "outputId": "209d1ba1-dffb-4ccf-bf17-44ee44b5ba0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "여성/가족    1599\n",
              "남성       1347\n",
              "성소수자     1140\n",
              "인종/국적    1727\n",
              "연령        603\n",
              "지역       1052\n",
              "종교       1181\n",
              "기타 혐오     569\n",
              "악플/욕설    3141\n",
              "clean    3718\n",
              "개인지칭      315\n",
              "dtype: object"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.sum()[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X8BEKpxx3AM",
        "outputId": "d3c1f619-b1c9-4018-f7b5-7d0c8c69625e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "여성/가족    393\n",
              "남성       334\n",
              "성소수자     280\n",
              "인종/국적    426\n",
              "연령       146\n",
              "지역       260\n",
              "종교       290\n",
              "기타 혐오    134\n",
              "악플/욕설    785\n",
              "clean    930\n",
              "개인지칭      74\n",
              "dtype: object"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.sum()[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 악플 데이터만 학습"
      ],
      "metadata": {
        "id": "z1VcQvHKklIY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MCZTpWqqjGM6"
      },
      "outputs": [],
      "source": [
        "train_df = train_df[train_df['clean'] ==0]\n",
        "test_df = test_df[test_df['clean'] ==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AABOIa27jGM6"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.iloc[:, :10]\n",
        "test_df = test_df.iloc[:, :10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이중 레이블 나누기\n",
        "- 레이블 열 생성"
      ],
      "metadata": {
        "id": "OoQmnmWckpmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨링\n",
        "df = pd.concat([train_df['문장'], train_df.iloc[:, 1:] * range(1, 10)], axis=1)\n",
        "\n",
        "dataset_train = pd.DataFrame()\n",
        "for i in range(1, 10):\n",
        "  data = df.loc[df.iloc[:, i] > 0][['문장', df.columns[i]]]\n",
        "  data.columns = ['문장', '라벨']\n",
        "  dataset_train = pd.concat([dataset_train, data])\n",
        "  \n",
        "  dataset_train.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Mg1ive2nkpL9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 오버 샘플링"
      ],
      "metadata": {
        "id": "FM54MQK4k6tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = dataset_train['문장'].values.reshape(-1, 1)\n",
        "y = dataset_train.iloc[:, 1:].values"
      ],
      "metadata": {
        "id": "LHBdQxguktYZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "X_resampled, y_resampled = RandomOverSampler(random_state=0).fit_resample(x, y)"
      ],
      "metadata": {
        "id": "daYECe4Ak90r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "counter = Counter(y_resampled)\n",
        "plt.bar(counter.keys(), counter.values())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "QfCCyBM6k-3z",
        "outputId": "3a35daa0-4152-45b6-d984-e74bec9cdfc3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fmZEr0l1oEG"
      },
      "source": [
        "## 한글 형태소 분석"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JSig7wwjeac",
        "outputId": "462c398e-cc4d-48fe-e69d-e6b6953bb633"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 16.89 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 671 kB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 63.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-06-09 04:18:45--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=Ju3z1UfZMt3g0QYl6kubANQ2%2Fa0%3D&Expires=1654749770&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2022-06-09 04:18:45--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=Ju3z1UfZMt3g0QYl6kubANQ2%2Fa0%3D&Expires=1654749770&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.74.172\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.74.172|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-06-09 04:18:45 (11.8 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-06-09 04:20:01--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::3403:4be7, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=%2FhHzpQJpE%2Bd6IUED7V%2BzCao%2Bae0%3D&Expires=1654749711&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2022-06-09 04:20:01--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=%2FhHzpQJpE%2Bd6IUED7V%2BzCao%2Bae0%3D&Expires=1654749711&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.198.1\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.198.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  90.5MB/s    in 0.5s    \n",
            "\n",
            "2022-06-09 04:20:01 (90.5 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n",
            "문제를 해결해주신 combacsa님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rEFvYMqc12vQ"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qVKQQvnc1dw6"
      },
      "outputs": [],
      "source": [
        "mecab = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0373952cecf44d029e834be6103ce4ee",
            "33f3086771f64a89984f8c28cbb842bf",
            "66880c3e8efa427f9bc92e496642d920",
            "b7b0e72cb56e48c4a9b238f6a66b3a54",
            "b69caba12f0145019f0cca46f541547c",
            "861ffa6f4a104ebf9f866b395e3902c0",
            "3aef427bd52b4cd492e6fcaef6ce0e89",
            "2eee331c467d433abddbaf8e7cb06805",
            "9e9b2fef59f04a18b6fd9fd02635c581",
            "1fd04efd0b5e4ad1a0f5ced089ffeb8a",
            "04138f51fa284e3d81827cec3d5da1af"
          ]
        },
        "id": "d1a73tac2aaT",
        "outputId": "64d2c494-8385-4041-e3e9-2c72971741f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28269 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0373952cecf44d029e834be6103ce4ee"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data = []\n",
        "for sentence in tqdm(X_resampled):\n",
        "  morphs = mecab.morphs(sentence[0])\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  train_data.append(tmp_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "778c27d29a4445a1b7f88492de62d032",
            "408c0e28de2946eda323c235dc06d3c8",
            "1f1c6bef85f8406e8a8481fb3a228734",
            "c9e006298be44b55a0fb23436ce210ab",
            "75ff6108908040f9b67764ba7aa7f8fd",
            "b35f69d3b2004185abc8e97b7c3b4374",
            "c4915a6349db46ef8ea33746d258ae5a",
            "5943804bf7e74ba7b1b1cd3dd0f3577d",
            "82a0958b658b47948205912b237ce823",
            "8b964b18f2b54fb2b567097ca79e598b",
            "1570b31a0bb749f9856ea0ae190f58a2"
          ]
        },
        "id": "s_NJnMypOxY0",
        "outputId": "1e72c3cd-5084-4ece-c05e-338faa9233d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2800 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "778c27d29a4445a1b7f88492de62d032"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "test_data = []\n",
        "for sentence in tqdm(test_df.문장):\n",
        "  morphs = mecab.morphs(sentence)\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  test_data.append(tmp_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QETCaH3cTqzb"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sG2k08NMhPpK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0KeqSe5QPHlJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ix6-ej1c26NR"
      },
      "outputs": [],
      "source": [
        "# 등장 빈도가 3 미만인 것의 갯수\n",
        "threshold = 5\n",
        "total_cnt = len(t.word_index)   # 단어의 수\n",
        "rare_cnt = 0                    # 등장 빈도가 threshold 보다 작은 단어의 갯수\n",
        "total_freq = 0                  # 훈련 데이터의 전체 단어의 빈도수의 합\n",
        "rare_freq = 0                   # 등장 빈도가 threshold 보다 작은 단어의 등장 빈도수의 합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Fc_Yniiu3LKN"
      },
      "outputs": [],
      "source": [
        "for key, value in t.word_counts.items():\n",
        "  total_freq += value\n",
        "  if value < threshold:\n",
        "    rare_cnt += 1\n",
        "    rare_freq += value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpRyvzQa3MbH",
        "outputId": "322f61b0-973b-4d89-9df0-3828eadc3d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 17000\n",
            "등장 빈도가 4번 이하인 희귀 단어의 수: 8990\n",
            "단어 집합에서 희귀 단어의 비율: 52.88235294117647\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.6434870822174976\n"
          ]
        }
      ],
      "source": [
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print(f'등장 빈도가 {threshold - 1}번 이하인 희귀 단어의 수: {rare_cnt}')\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoo8rfzc3cCX",
        "outputId": "634a69d8-61f0-4420-c8c4-50570108bacb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17001"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# 모든 단어 사용\n",
        "vocab_size = total_cnt + 2\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jhbvjJoE3nae"
      },
      "outputs": [],
      "source": [
        "t = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "t.fit_on_texts(train_data)\n",
        "X_train = t.texts_to_sequences(train_data)\n",
        "X_test = t.texts_to_sequences(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJDeO7fUT9wK",
        "outputId": "abe5d6d3-56e5-400a-df01-270cf5ece030"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74, 18.202341787824118)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# 데이터의 최대/평균 길이\n",
        "max(len(s) for s in X_train), sum(map(len, X_train)) / len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aYq1T83SUgWD"
      },
      "outputs": [],
      "source": [
        "# 악플 길이를 60으로 설정\n",
        "max_len = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK-Df341Uh8J",
        "outputId": "4db72c31-175e-4358-bdfa-9ccbbef8931b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28269, 60), (2800, 60))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqsiqzEZh6Ck",
        "outputId": "cf850273-14c7-4bf7-b9bd-8c2a0df7b3e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28269, 9), (2800, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "# Y_train = train_df.iloc[:, 1:].values\n",
        "Y_train = to_categorical(y_resampled)\n",
        "Y_train = np.delete(Y_train, 0, 1)\n",
        "Y_test = test_df.iloc[:, 1:].values\n",
        "Y_train.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln0RXe-liL9D"
      },
      "source": [
        "## 모델 정의/설정/학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFRq8MvYiLtM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D, Dropout, Concatenate\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYao6huG6zUD"
      },
      "source": [
        "### 1. CNN\n",
        "- Embedding Layer\n",
        "- 2 One-Dimension Convolution Layers (Dropout: 50%)\n",
        "- 1-Dimension Global Max Pooling\n",
        "- Concatenate\n",
        "- Fully Connected Layer\n",
        "- 1-Dimension Fully Connected Layer\n",
        "- Sigmoid Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNlLB89IiQ-G",
        "outputId": "d39b3543-57bf-4d4c-e33f-12cecc7e66be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 60, 128)           2176128   \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 56, 64)            41024     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 56, 64)            0         \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 52, 32)            10272     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 52, 32)            0         \n",
            "                                                                 \n",
            " global_max_pooling1d_6 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 9)                 297       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,228,777\n",
            "Trainable params: 2,228,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1 = Sequential([ \n",
        "    Embedding(vocab_size, 128, input_length=max_len),\n",
        "    Conv1D(64, 5, padding='valid', activation='relu', strides=1),\n",
        "    Dropout(0.5),\n",
        "    Conv1D(32, 5, padding='valid', activation='relu', strides=1),\n",
        "    Dropout(0.5),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(9, activation='softmax')\n",
        "])\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycvr9ua3i6Ap"
      },
      "outputs": [],
      "source": [
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1_path = 'best-cnn.h5py'\n",
        "mc1 = ModelCheckpoint(model1_path, verbose=1, save_best_only=True)\n",
        "es1 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkJyf7h4jAWD",
        "outputId": "429ca96d-c4bb-443e-df4a-4b225354a5d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 1.9413 - accuracy: 0.2507\n",
            "Epoch 1: val_loss improved from inf to 2.39377, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 3s 13ms/step - loss: 1.9283 - accuracy: 0.2572 - val_loss: 2.3938 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "172/177 [============================>.] - ETA: 0s - loss: 1.2159 - accuracy: 0.5798\n",
            "Epoch 2: val_loss improved from 2.39377 to 2.20965, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 1.2100 - accuracy: 0.5817 - val_loss: 2.2096 - val_accuracy: 0.1089\n",
            "Epoch 3/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 0.8612 - accuracy: 0.7267\n",
            "Epoch 3: val_loss improved from 2.20965 to 1.83348, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.8569 - accuracy: 0.7285 - val_loss: 1.8335 - val_accuracy: 0.3141\n",
            "Epoch 4/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.8149\n",
            "Epoch 4: val_loss improved from 1.83348 to 1.50532, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.6196 - accuracy: 0.8149 - val_loss: 1.5053 - val_accuracy: 0.4468\n",
            "Epoch 5/30\n",
            "169/177 [===========================>..] - ETA: 0s - loss: 0.4920 - accuracy: 0.8528\n",
            "Epoch 5: val_loss improved from 1.50532 to 1.30807, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.4937 - accuracy: 0.8524 - val_loss: 1.3081 - val_accuracy: 0.5002\n",
            "Epoch 6/30\n",
            "169/177 [===========================>..] - ETA: 0s - loss: 0.4245 - accuracy: 0.8705\n",
            "Epoch 6: val_loss improved from 1.30807 to 1.20942, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.4251 - accuracy: 0.8703 - val_loss: 1.2094 - val_accuracy: 0.5522\n",
            "Epoch 7/30\n",
            "170/177 [===========================>..] - ETA: 0s - loss: 0.3777 - accuracy: 0.8787\n",
            "Epoch 7: val_loss improved from 1.20942 to 1.10119, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 0.3759 - accuracy: 0.8788 - val_loss: 1.1012 - val_accuracy: 0.6070\n",
            "Epoch 8/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 0.3320 - accuracy: 0.8883\n",
            "Epoch 8: val_loss improved from 1.10119 to 1.00043, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3331 - accuracy: 0.8879 - val_loss: 1.0004 - val_accuracy: 0.6638\n",
            "Epoch 9/30\n",
            "169/177 [===========================>..] - ETA: 0s - loss: 0.3099 - accuracy: 0.8935\n",
            "Epoch 9: val_loss improved from 1.00043 to 0.94411, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3085 - accuracy: 0.8938 - val_loss: 0.9441 - val_accuracy: 0.6744\n",
            "Epoch 10/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 0.2878 - accuracy: 0.8998\n",
            "Epoch 10: val_loss improved from 0.94411 to 0.87511, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.2879 - accuracy: 0.8998 - val_loss: 0.8751 - val_accuracy: 0.6673\n",
            "Epoch 11/30\n",
            "169/177 [===========================>..] - ETA: 0s - loss: 0.2705 - accuracy: 0.9031\n",
            "Epoch 11: val_loss improved from 0.87511 to 0.76694, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.2730 - accuracy: 0.9021 - val_loss: 0.7669 - val_accuracy: 0.7326\n",
            "Epoch 12/30\n",
            "169/177 [===========================>..] - ETA: 0s - loss: 0.2554 - accuracy: 0.9045\n",
            "Epoch 12: val_loss did not improve from 0.76694\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.2565 - accuracy: 0.9045 - val_loss: 0.7689 - val_accuracy: 0.7007\n",
            "Epoch 13/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 0.2492 - accuracy: 0.9057\n",
            "Epoch 13: val_loss improved from 0.76694 to 0.74827, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.2497 - accuracy: 0.9057 - val_loss: 0.7483 - val_accuracy: 0.7096\n",
            "Epoch 14/30\n",
            "170/177 [===========================>..] - ETA: 0s - loss: 0.2430 - accuracy: 0.9037\n",
            "Epoch 14: val_loss improved from 0.74827 to 0.64423, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.2429 - accuracy: 0.9036 - val_loss: 0.6442 - val_accuracy: 0.7356\n",
            "Epoch 15/30\n",
            "169/177 [===========================>..] - ETA: 0s - loss: 0.2362 - accuracy: 0.9056\n",
            "Epoch 15: val_loss did not improve from 0.64423\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.2366 - accuracy: 0.9054 - val_loss: 0.6498 - val_accuracy: 0.7257\n",
            "Epoch 16/30\n",
            "174/177 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.9097\n",
            "Epoch 16: val_loss improved from 0.64423 to 0.60823, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 0.2238 - accuracy: 0.9095 - val_loss: 0.6082 - val_accuracy: 0.7480\n",
            "Epoch 17/30\n",
            "172/177 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9107\n",
            "Epoch 17: val_loss did not improve from 0.60823\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.2175 - accuracy: 0.9105 - val_loss: 0.6368 - val_accuracy: 0.7096\n",
            "Epoch 18/30\n",
            "170/177 [===========================>..] - ETA: 0s - loss: 0.2151 - accuracy: 0.9105\n",
            "Epoch 18: val_loss improved from 0.60823 to 0.59341, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.2165 - accuracy: 0.9103 - val_loss: 0.5934 - val_accuracy: 0.7320\n",
            "Epoch 19/30\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.2090 - accuracy: 0.9107\n",
            "Epoch 19: val_loss did not improve from 0.59341\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.2099 - accuracy: 0.9101 - val_loss: 0.5983 - val_accuracy: 0.7319\n",
            "Epoch 20/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 0.2064 - accuracy: 0.9137\n",
            "Epoch 20: val_loss improved from 0.59341 to 0.52634, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.2074 - accuracy: 0.9136 - val_loss: 0.5263 - val_accuracy: 0.7557\n",
            "Epoch 21/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 0.2048 - accuracy: 0.9115\n",
            "Epoch 21: val_loss did not improve from 0.52634\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.2047 - accuracy: 0.9115 - val_loss: 0.5400 - val_accuracy: 0.7481\n",
            "Epoch 22/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 0.1990 - accuracy: 0.9164\n",
            "Epoch 22: val_loss did not improve from 0.52634\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.1991 - accuracy: 0.9164 - val_loss: 0.5858 - val_accuracy: 0.7154\n",
            "Epoch 23/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 0.2022 - accuracy: 0.9142\n",
            "Epoch 23: val_loss did not improve from 0.52634\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.2017 - accuracy: 0.9145 - val_loss: 0.5661 - val_accuracy: 0.7052\n",
            "Epoch 24/30\n",
            "173/177 [============================>.] - ETA: 0s - loss: 0.1947 - accuracy: 0.9158\n",
            "Epoch 24: val_loss improved from 0.52634 to 0.51794, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.1947 - accuracy: 0.9155 - val_loss: 0.5179 - val_accuracy: 0.7513\n",
            "Epoch 25/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 0.1917 - accuracy: 0.9161\n",
            "Epoch 25: val_loss did not improve from 0.51794\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.1911 - accuracy: 0.9163 - val_loss: 0.5350 - val_accuracy: 0.7464\n",
            "Epoch 26/30\n",
            "172/177 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9152\n",
            "Epoch 26: val_loss improved from 0.51794 to 0.50348, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.1903 - accuracy: 0.9154 - val_loss: 0.5035 - val_accuracy: 0.7313\n",
            "Epoch 27/30\n",
            "171/177 [===========================>..] - ETA: 0s - loss: 0.1885 - accuracy: 0.9162\n",
            "Epoch 27: val_loss improved from 0.50348 to 0.50216, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.1886 - accuracy: 0.9159 - val_loss: 0.5022 - val_accuracy: 0.7206\n",
            "Epoch 28/30\n",
            "172/177 [============================>.] - ETA: 0s - loss: 0.1802 - accuracy: 0.9186\n",
            "Epoch 28: val_loss improved from 0.50216 to 0.47766, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.1809 - accuracy: 0.9180 - val_loss: 0.4777 - val_accuracy: 0.7481\n",
            "Epoch 29/30\n",
            "173/177 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.9159\n",
            "Epoch 29: val_loss improved from 0.47766 to 0.47395, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.1844 - accuracy: 0.9156 - val_loss: 0.4739 - val_accuracy: 0.7308\n",
            "Epoch 30/30\n",
            "169/177 [===========================>..] - ETA: 0s - loss: 0.1821 - accuracy: 0.9179\n",
            "Epoch 30: val_loss improved from 0.47395 to 0.46435, saving model to best-cnn.h5py\n",
            "INFO:tensorflow:Assets written to: best-cnn.h5py/assets\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 0.1823 - accuracy: 0.9170 - val_loss: 0.4643 - val_accuracy: 0.7340\n"
          ]
        }
      ],
      "source": [
        "hist = model1.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, \n",
        "    batch_size=128,\n",
        "    callbacks=[mc1, es1]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgfBrsAQjCa7",
        "outputId": "2652773d-b866-472f-894a-c86886dbbfe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117/117 [==============================] - 0s 3ms/step - loss: 1.0104 - accuracy: 0.5394\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0103671550750732, 0.5394101738929749]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "best_model1 = load_model(model1_path)\n",
        "best_model1.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. BiLSTM\n",
        "- Embedding Layer\n",
        "- Bidirectional LSTM (Dropout: 10%)\n",
        "- 1-Dimension Global Max Pooling\n",
        "- 1-Dimension Fully Connected Layer\n",
        "- Sigmoid Activation"
      ],
      "metadata": {
        "id": "njdq4I51nOn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Dropout, GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "WxTs70aHndfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model2"
      ],
      "metadata": {
        "id": "GPBEkzfUoSL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([ \n",
        "    Embedding(vocab_size, 200, input_length=max_len),\n",
        "    Bidirectional(LSTM(200, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(9, activation='softmax')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIRQTLtanRtA",
        "outputId": "db45686e-4f6f-471a-a7ae-0e079156a26e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 60, 200)           3400200   \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 60, 400)          641600    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 60, 400)           0         \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Glo  (None, 400)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 9)                 3609      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,045,409\n",
            "Trainable params: 4,045,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2_path = 'best-biLSTM.h5'\n",
        "mc2 = ModelCheckpoint(model2_path, verbose=1, save_best_only=True)\n",
        "es2 = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "JeiFVFadnmTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist2 = model2.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc2,es2]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHepa9HDnr2q",
        "outputId": "304d71cb-c187-4b63-b94a-2030a91b3b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.6188 - accuracy: 0.8098\n",
            "Epoch 1: val_loss improved from inf to 1.33801, saving model to best-biLSTM.h5\n",
            "177/177 [==============================] - 6s 34ms/step - loss: 0.6189 - accuracy: 0.8099 - val_loss: 1.3380 - val_accuracy: 0.4622\n",
            "Epoch 2/30\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.3736 - accuracy: 0.8721\n",
            "Epoch 2: val_loss improved from 1.33801 to 1.08113, saving model to best-biLSTM.h5\n",
            "177/177 [==============================] - 5s 26ms/step - loss: 0.3724 - accuracy: 0.8725 - val_loss: 1.0811 - val_accuracy: 0.6074\n",
            "Epoch 3/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.8952\n",
            "Epoch 3: val_loss improved from 1.08113 to 0.86459, saving model to best-biLSTM.h5\n",
            "177/177 [==============================] - 4s 24ms/step - loss: 0.2783 - accuracy: 0.8952 - val_loss: 0.8646 - val_accuracy: 0.6942\n",
            "Epoch 4/30\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.2371 - accuracy: 0.9028\n",
            "Epoch 4: val_loss improved from 0.86459 to 0.75959, saving model to best-biLSTM.h5\n",
            "177/177 [==============================] - 4s 24ms/step - loss: 0.2371 - accuracy: 0.9028 - val_loss: 0.7596 - val_accuracy: 0.7184\n",
            "Epoch 5/30\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.9094\n",
            "Epoch 5: val_loss improved from 0.75959 to 0.63039, saving model to best-biLSTM.h5\n",
            "177/177 [==============================] - 4s 24ms/step - loss: 0.2135 - accuracy: 0.9094 - val_loss: 0.6304 - val_accuracy: 0.7706\n",
            "Epoch 6/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 0.9106\n",
            "Epoch 6: val_loss did not improve from 0.63039\n",
            "177/177 [==============================] - 4s 24ms/step - loss: 0.1992 - accuracy: 0.9106 - val_loss: 0.6694 - val_accuracy: 0.7319\n",
            "Epoch 7/30\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.1895 - accuracy: 0.9128\n",
            "Epoch 7: val_loss did not improve from 0.63039\n",
            "177/177 [==============================] - 4s 24ms/step - loss: 0.1891 - accuracy: 0.9130 - val_loss: 0.7314 - val_accuracy: 0.7163\n",
            "Epoch 8/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9125\n",
            "Epoch 8: val_loss improved from 0.63039 to 0.54859, saving model to best-biLSTM.h5\n",
            "177/177 [==============================] - 5s 26ms/step - loss: 0.1847 - accuracy: 0.9125 - val_loss: 0.5486 - val_accuracy: 0.7506\n",
            "Epoch 9/30\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1762 - accuracy: 0.9150\n",
            "Epoch 9: val_loss did not improve from 0.54859\n",
            "177/177 [==============================] - 4s 25ms/step - loss: 0.1761 - accuracy: 0.9150 - val_loss: 0.5581 - val_accuracy: 0.7374\n",
            "Epoch 10/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9171\n",
            "Epoch 10: val_loss did not improve from 0.54859\n",
            "177/177 [==============================] - 4s 24ms/step - loss: 0.1741 - accuracy: 0.9171 - val_loss: 0.5540 - val_accuracy: 0.7239\n",
            "Epoch 11/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1684 - accuracy: 0.9169\n",
            "Epoch 11: val_loss improved from 0.54859 to 0.52202, saving model to best-biLSTM.h5\n",
            "177/177 [==============================] - 5s 26ms/step - loss: 0.1684 - accuracy: 0.9169 - val_loss: 0.5220 - val_accuracy: 0.7391\n",
            "Epoch 12/30\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9189\n",
            "Epoch 12: val_loss improved from 0.52202 to 0.51188, saving model to best-biLSTM.h5\n",
            "177/177 [==============================] - 5s 26ms/step - loss: 0.1644 - accuracy: 0.9189 - val_loss: 0.5119 - val_accuracy: 0.7386\n",
            "Epoch 13/30\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9187\n",
            "Epoch 13: val_loss did not improve from 0.51188\n",
            "177/177 [==============================] - 4s 23ms/step - loss: 0.1647 - accuracy: 0.9187 - val_loss: 0.5487 - val_accuracy: 0.7252\n",
            "Epoch 14/30\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1604 - accuracy: 0.9195\n",
            "Epoch 14: val_loss did not improve from 0.51188\n",
            "177/177 [==============================] - 4s 25ms/step - loss: 0.1607 - accuracy: 0.9194 - val_loss: 0.5152 - val_accuracy: 0.7274\n",
            "Epoch 15/30\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9212\n",
            "Epoch 15: val_loss improved from 0.51188 to 0.42283, saving model to best-biLSTM.h5\n",
            "177/177 [==============================] - 4s 24ms/step - loss: 0.1577 - accuracy: 0.9213 - val_loss: 0.4228 - val_accuracy: 0.7940\n",
            "Epoch 16/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1624 - accuracy: 0.9176\n",
            "Epoch 16: val_loss did not improve from 0.42283\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 0.1624 - accuracy: 0.9176 - val_loss: 0.4934 - val_accuracy: 0.7487\n",
            "Epoch 17/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.9197\n",
            "Epoch 17: val_loss did not improve from 0.42283\n",
            "177/177 [==============================] - 4s 23ms/step - loss: 0.1588 - accuracy: 0.9197 - val_loss: 0.5243 - val_accuracy: 0.7131\n",
            "Epoch 18/30\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1591 - accuracy: 0.9204\n",
            "Epoch 18: val_loss did not improve from 0.42283\n",
            "177/177 [==============================] - 4s 23ms/step - loss: 0.1590 - accuracy: 0.9206 - val_loss: 0.4871 - val_accuracy: 0.7402\n",
            "Epoch 19/30\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1535 - accuracy: 0.9217\n",
            "Epoch 19: val_loss did not improve from 0.42283\n",
            "177/177 [==============================] - 4s 25ms/step - loss: 0.1539 - accuracy: 0.9212 - val_loss: 0.5009 - val_accuracy: 0.7405\n",
            "Epoch 20/30\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1515 - accuracy: 0.9237\n",
            "Epoch 20: val_loss did not improve from 0.42283\n",
            "177/177 [==============================] - 4s 25ms/step - loss: 0.1519 - accuracy: 0.9235 - val_loss: 0.4939 - val_accuracy: 0.7319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model2 = load_model(model2_path)\n",
        "best_model2.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zcP6tNwnxXE",
        "outputId": "e6ac730d-23b0-4818-991b-f20894bbd131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117/117 [==============================] - 1s 7ms/step - loss: 0.7850 - accuracy: 0.5601\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7849991917610168, 0.5600536465644836]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실제 데이터 예측"
      ],
      "metadata": {
        "id": "zIUfY6NpqZN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "blWhsLdJqlNm"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    return score"
      ],
      "metadata": {
        "id": "4I_TClp1oDMv"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = test_df['문장'][1]"
      ],
      "metadata": {
        "id": "4-tXPu9tqqjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',text).strip()\n",
        "morphs = mecab.morphs(text)\n",
        "morphs = [word for word in morphs if word not in stopwords]\n",
        "encoded = t.texts_to_sequences([morphs])\n",
        "padded = pad_sequences(encoded, maxlen=max_len)"
      ],
      "metadata": {
        "id": "WMia42jmq_7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model2.predict(padded).argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bSK4bJgq4Xy",
        "outputId": "461f932d-38ee-4faf-998f-a8f69405d14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 양방향 LSTM과 어텐션 메커니즘"
      ],
      "metadata": {
        "id": "gxq2qLD557W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "wLusTASK7eDd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query): # 단, key와 value는 같음\n",
        "    # query shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "bkcLze-_8Jyb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D, Dropout, Concatenate\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "89bs7_5XAHp2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)\n",
        "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)\n",
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
        "  (LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)\n",
        "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
        "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태\n",
        "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
        "context_vector, attention_weights = attention(lstm, state_h)\n",
        "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(9, activation=\"softmax\")(dropout)\n",
        "model3 = Model(inputs=sequence_input, outputs=output)\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ADXq9Na8NKj",
        "outputId": "f1c44d56-14ae-4b72-fe91-0c9568422761"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 60, 128)      2176256     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 60, 128)     98816       ['embedding_1[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  [(None, 60, 128),   98816       ['bidirectional_2[0][0]']        \n",
            " )                               (None, 64),                                                      \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128)          0           ['bidirectional_3[0][1]',        \n",
            "                                                                  'bidirectional_3[0][3]']        \n",
            "                                                                                                  \n",
            " bahdanau_attention_1 (Bahdanau  ((None, 128),       16577       ['bidirectional_3[0][0]',        \n",
            " Attention)                      (None, 60, 1))                   'concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 20)           2580        ['bahdanau_attention_1[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 20)           0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 9)            189         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,393,234\n",
            "Trainable params: 2,393,234\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3_path = 'best-lstm-attention.h5py'\n",
        "mc3 = ModelCheckpoint(model3_path, verbose=1, save_best_only=True)\n",
        "es3 = EarlyStopping(patience=3)"
      ],
      "metadata": {
        "id": "C2MjWWd78b8L"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(X_train, Y_train, epochs = 100, batch_size = 256, \n",
        "                     validation_data=(X_test, Y_test), verbose=1, \n",
        "                     callbacks=[mc3, es3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx1_xdQe8e-D",
        "outputId": "6a85c655-e2cc-41e8-c7b9-7c2601d174c9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - ETA: 0s - loss: 1.7949 - accuracy: 0.3586\n",
            "Epoch 1: val_loss improved from inf to 1.78833, saving model to best-lstm-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-lstm-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-lstm-attention.h5py/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0455768450> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f045678a350> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0456179cd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f045617a850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r111/111 [==============================] - 136s 1s/step - loss: 1.7949 - accuracy: 0.3586 - val_loss: 1.7883 - val_accuracy: 0.4682\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - ETA: 0s - loss: 1.3785 - accuracy: 0.5276\n",
            "Epoch 2: val_loss improved from 1.78833 to 1.52394, saving model to best-lstm-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-lstm-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-lstm-attention.h5py/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0455768450> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f045678a350> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0456179cd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f045617a850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r111/111 [==============================] - 117s 1s/step - loss: 1.3785 - accuracy: 0.5276 - val_loss: 1.5239 - val_accuracy: 0.5875\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - ETA: 0s - loss: 1.1423 - accuracy: 0.6156\n",
            "Epoch 3: val_loss improved from 1.52394 to 1.42450, saving model to best-lstm-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-lstm-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-lstm-attention.h5py/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0455768450> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f045678a350> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0456179cd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f045617a850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r111/111 [==============================] - 116s 1s/step - loss: 1.1423 - accuracy: 0.6156 - val_loss: 1.4245 - val_accuracy: 0.6014\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.9916 - accuracy: 0.6795\n",
            "Epoch 4: val_loss improved from 1.42450 to 1.35825, saving model to best-lstm-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-lstm-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-lstm-attention.h5py/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0455768450> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f045678a350> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0456179cd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f045617a850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r111/111 [==============================] - 118s 1s/step - loss: 0.9916 - accuracy: 0.6795 - val_loss: 1.3582 - val_accuracy: 0.6361\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.8796 - accuracy: 0.7184\n",
            "Epoch 5: val_loss did not improve from 1.35825\n",
            "111/111 [==============================] - 66s 599ms/step - loss: 0.8796 - accuracy: 0.7184 - val_loss: 1.3929 - val_accuracy: 0.6400\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.7713 - accuracy: 0.7569\n",
            "Epoch 6: val_loss improved from 1.35825 to 1.34572, saving model to best-lstm-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-lstm-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-lstm-attention.h5py/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0455768450> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f045678a350> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0456179cd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f045617a850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r111/111 [==============================] - 117s 1s/step - loss: 0.7713 - accuracy: 0.7569 - val_loss: 1.3457 - val_accuracy: 0.6625\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.7810\n",
            "Epoch 7: val_loss did not improve from 1.34572\n",
            "111/111 [==============================] - 66s 596ms/step - loss: 0.6949 - accuracy: 0.7810 - val_loss: 1.4965 - val_accuracy: 0.6654\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.7952\n",
            "Epoch 8: val_loss did not improve from 1.34572\n",
            "111/111 [==============================] - 66s 592ms/step - loss: 0.6324 - accuracy: 0.7952 - val_loss: 1.6802 - val_accuracy: 0.6614\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.8014\n",
            "Epoch 9: val_loss did not improve from 1.34572\n",
            "111/111 [==============================] - 66s 593ms/step - loss: 0.6061 - accuracy: 0.8014 - val_loss: 1.6040 - val_accuracy: 0.6639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXXxdqzn8hy2",
        "outputId": "08e56b6a-3345-439b-c577-44cd8e7e0754"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 6s 64ms/step - loss: 1.2746 - accuracy: 0.6718\n",
            "\n",
            " 테스트 정확도: 0.6718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 셀프 어텐션"
      ],
      "metadata": {
        "id": "tmCT-WN4E6gf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 멀티 헤드 어텐션\n",
        "- 트랜스포머 인코더의 첫번째 서브층"
      ],
      "metadata": {
        "id": "fF8L16qOq-9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "d1yPCxZtE8ak"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads=8):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.embedding_dim = embedding_dim # d_model\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        assert embedding_dim % self.num_heads == 0\n",
        "\n",
        "        self.projection_dim = embedding_dim // num_heads\n",
        "        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
        "\n",
        "    def scaled_dot_product_attention(self, query, key, value):\n",
        "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        logits = matmul_qk / tf.math.sqrt(depth)\n",
        "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "        output = tf.matmul(attention_weights, value)\n",
        "        return output, attention_weights\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # (batch_size, seq_len, embedding_dim)\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "\n",
        "        # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        query = self.split_heads(query, batch_size)  \n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
        "        # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
        "\n",
        "        # (batch_size, seq_len, embedding_dim)\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
        "        outputs = self.dense(concat_attention)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "y131InpHE9ye"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 인코더 설계하기\n",
        "- 두번째 서브칭인 포지션 와이즈 피드 포워드 신경망 추가"
      ],
      "metadata": {
        "id": "NdgKGc1lrVda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(embedding_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
        "             tf.keras.layers.Dense(embedding_dim),]\n",
        "        )\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs) # 첫번째 서브층 : 멀티 헤드 어텐션\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output) # Add & Norm\n",
        "        ffn_output = self.ffn(out1) # 두번째 서브층 : 포지션 와이즈 피드 포워드 신경망\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output) # Add & Norm"
      ],
      "metadata": {
        "id": "BaLUJacxE_En"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 포지션 임베딩\n",
        "- 임베딩 층을 사용하되, 위치 벡터 학습하도록 임베딩 층의 첫번째 인자로 단어 집합의 크기가 아니라 문장의 최대 길이를 넣어줌"
      ],
      "metadata": {
        "id": "IIRp1iN7rcmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos_emb = tf.keras.layers.Embedding(max_len, embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        max_len = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "id": "qUAfcMBFFA0h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리"
      ],
      "metadata": {
        "id": "ZMmiJDrjrsra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "zNXdyb3CFDuW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 정의/학습"
      ],
      "metadata": {
        "id": "NcxgA6mrs3ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "IIv4f5j0s6zT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "-6pxy9ytGOnQ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 32  # 각 단어의 임베딩 벡터의 차원\n",
        "num_heads = 2  # 어텐션 헤드의 수\n",
        "dff = 32  # 포지션 와이즈 피드 포워드 신경망의 은닉층의 크기\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(max_len,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
        "x = transformer_block(x)\n",
        "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "outputs = tf.keras.layers.Dense(9, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAfl2tw5FbzJ",
        "outputId": "3d25e730-8f4c-40b2-c0e7-94e9edd6cf67"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 60)]              0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 60, 32)           545952    \n",
            " g_11 (TokenAndPositionEmbed                                     \n",
            " ding)                                                           \n",
            "                                                                 \n",
            " transformer_block_11 (Trans  (None, 60, 32)           6464      \n",
            " formerBlock)                                                    \n",
            "                                                                 \n",
            " global_max_pooling1d_9 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 20)                660       \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 20)                0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 9)                 189       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 553,265\n",
            "Trainable params: 553,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model_path = 'best-transforemr-attention.h5py'\n",
        "mc = ModelCheckpoint(model_path, verbose=1, save_best_only=True)\n",
        "es = EarlyStopping(patience=3)\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data=(X_test, Y_test), callbacks=[mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPlf-xQxFdpp",
        "outputId": "9ca50b50-da31-4dae-91f2-89386b5c8700"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "884/884 [==============================] - ETA: 0s - loss: 1.6337 - accuracy: 0.4292\n",
            "Epoch 1: val_loss improved from inf to 1.14289, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_11_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fc0e9000410> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r884/884 [==============================] - 11s 11ms/step - loss: 1.6337 - accuracy: 0.4292 - val_loss: 1.1429 - val_accuracy: 0.7125\n",
            "Epoch 2/100\n",
            "883/884 [============================>.] - ETA: 0s - loss: 0.7786 - accuracy: 0.7576\n",
            "Epoch 2: val_loss improved from 1.14289 to 0.99249, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_11_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fc0e9000410> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r884/884 [==============================] - 10s 11ms/step - loss: 0.7783 - accuracy: 0.7577 - val_loss: 0.9925 - val_accuracy: 0.7386\n",
            "Epoch 3/100\n",
            "877/884 [============================>.] - ETA: 0s - loss: 0.5144 - accuracy: 0.8362\n",
            "Epoch 3: val_loss did not improve from 0.99249\n",
            "884/884 [==============================] - 7s 7ms/step - loss: 0.5141 - accuracy: 0.8361 - val_loss: 1.0724 - val_accuracy: 0.7089\n",
            "Epoch 4/100\n",
            "881/884 [============================>.] - ETA: 0s - loss: 0.3973 - accuracy: 0.8680\n",
            "Epoch 4: val_loss did not improve from 0.99249\n",
            "884/884 [==============================] - 7s 7ms/step - loss: 0.3970 - accuracy: 0.8679 - val_loss: 1.1899 - val_accuracy: 0.7300\n",
            "Epoch 5/100\n",
            "880/884 [============================>.] - ETA: 0s - loss: 0.3386 - accuracy: 0.8801\n",
            "Epoch 5: val_loss did not improve from 0.99249\n",
            "884/884 [==============================] - 7s 7ms/step - loss: 0.3386 - accuracy: 0.8802 - val_loss: 1.2931 - val_accuracy: 0.7204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model(model_path)\n",
        "best_model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e08LhEntJA5e",
        "outputId": "7640994b-1b7c-4264-fea8-78994e579ae9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 1s 4ms/step - loss: 0.9925 - accuracy: 0.7386\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9924857020378113, 0.7385714054107666]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = test_df.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\")"
      ],
      "metadata": {
        "id": "i4cvmug0JJUF"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = test_df['문장'][23]\n",
        "sentiment_predict(text, best_model,tokenizer=t, max_len=max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5JrmwarFfCL",
        "outputId": "366eedbb-e1cd-4f9b-f3b0-0bb9436bae16"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'야이 점쟁이새끼야 더러운글 그만올리고점사나 잘봐라'\n",
            " 91.53352379798889%의 확률로 악플/욕설에 대한 악플입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',text).strip()\n",
        "morphs = mecab.morphs(review)\n",
        "morphs = [word for word in morphs if word not in stopwords]\n",
        "encoded = t.texts_to_sequences([morphs])\n",
        "padded = pad_sequences(encoded, maxlen=max_len)\n",
        "score = best_model.predict(padded)\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbXvijTUJLxO",
        "outputId": "edea6f96-926c-4871-deb3-e8b235da4d71"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20046328, 0.27338484, 0.04363228, 0.14791888, 0.03756335,\n",
              "        0.07241045, 0.02485918, 0.17876512, 0.02100265]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_text = test_df.columns[1:]\n",
        "class_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q7OBmI0JgdB",
        "outputId": "ef40fe4b-21b9-480d-e840-3d08bbef0844"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['여성/가족', '남성', '성소수자', '인종/국적', '연령', '지역', '종교', '기타 혐오', '악플/욕설'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0v6px9B2QUFf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "악플분류기-다중분류.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "9f5feb42f08914aecde0ece13ac07afe9f84906579ba918f8c70eb200f669000"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 ('min')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0373952cecf44d029e834be6103ce4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33f3086771f64a89984f8c28cbb842bf",
              "IPY_MODEL_66880c3e8efa427f9bc92e496642d920",
              "IPY_MODEL_b7b0e72cb56e48c4a9b238f6a66b3a54"
            ],
            "layout": "IPY_MODEL_b69caba12f0145019f0cca46f541547c"
          }
        },
        "33f3086771f64a89984f8c28cbb842bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_861ffa6f4a104ebf9f866b395e3902c0",
            "placeholder": "​",
            "style": "IPY_MODEL_3aef427bd52b4cd492e6fcaef6ce0e89",
            "value": "100%"
          }
        },
        "66880c3e8efa427f9bc92e496642d920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eee331c467d433abddbaf8e7cb06805",
            "max": 28269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e9b2fef59f04a18b6fd9fd02635c581",
            "value": 28269
          }
        },
        "b7b0e72cb56e48c4a9b238f6a66b3a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fd04efd0b5e4ad1a0f5ced089ffeb8a",
            "placeholder": "​",
            "style": "IPY_MODEL_04138f51fa284e3d81827cec3d5da1af",
            "value": " 28269/28269 [00:09&lt;00:00, 3687.66it/s]"
          }
        },
        "b69caba12f0145019f0cca46f541547c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861ffa6f4a104ebf9f866b395e3902c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aef427bd52b4cd492e6fcaef6ce0e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eee331c467d433abddbaf8e7cb06805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e9b2fef59f04a18b6fd9fd02635c581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fd04efd0b5e4ad1a0f5ced089ffeb8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04138f51fa284e3d81827cec3d5da1af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "778c27d29a4445a1b7f88492de62d032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_408c0e28de2946eda323c235dc06d3c8",
              "IPY_MODEL_1f1c6bef85f8406e8a8481fb3a228734",
              "IPY_MODEL_c9e006298be44b55a0fb23436ce210ab"
            ],
            "layout": "IPY_MODEL_75ff6108908040f9b67764ba7aa7f8fd"
          }
        },
        "408c0e28de2946eda323c235dc06d3c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35f69d3b2004185abc8e97b7c3b4374",
            "placeholder": "​",
            "style": "IPY_MODEL_c4915a6349db46ef8ea33746d258ae5a",
            "value": "100%"
          }
        },
        "1f1c6bef85f8406e8a8481fb3a228734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5943804bf7e74ba7b1b1cd3dd0f3577d",
            "max": 2800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82a0958b658b47948205912b237ce823",
            "value": 2800
          }
        },
        "c9e006298be44b55a0fb23436ce210ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b964b18f2b54fb2b567097ca79e598b",
            "placeholder": "​",
            "style": "IPY_MODEL_1570b31a0bb749f9856ea0ae190f58a2",
            "value": " 2800/2800 [00:01&lt;00:00, 2141.05it/s]"
          }
        },
        "75ff6108908040f9b67764ba7aa7f8fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35f69d3b2004185abc8e97b7c3b4374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4915a6349db46ef8ea33746d258ae5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5943804bf7e74ba7b1b1cd3dd0f3577d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a0958b658b47948205912b237ce823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b964b18f2b54fb2b567097ca79e598b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1570b31a0bb749f9856ea0ae190f58a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}