{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9CfSaiVib0r"
      },
      "source": [
        "# 악플 분류기 - 다중분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a_ypjpJOTlVQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HTAfT9JFAir0"
      },
      "outputs": [],
      "source": [
        "smile_train = pd.read_csv(\"../data/multi label data/common_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>문재앙은 김정은의 운전사도 안되는 똥휴지다  개돼지들이 뽑은 재앙민국이 망해간다</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>근데 사람들이 우스갯소리로  일 재앙이라고 했는데 이제보니 장난아니고  일   재앙...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>공무뭔들도 정권 바뀐다는걸 아는구나 이놈들은 원래 연줄이 밥줄이라 눈치는 백단이지 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>조옷도 모르는게 가만히 쳐있어 그냥 주둥이 나불대지말구 이 좌빨    니들 얘기하는...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>토착빨갱이같으니라고</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47404</th>\n",
              "      <td>께롱께롱께롱</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47405</th>\n",
              "      <td>갱상도가아니라 홍어지 개좃같은 홍어년들</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47406</th>\n",
              "      <td>말레이시아랑 인도네시아 여자 존나 못생겼던데</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47407</th>\n",
              "      <td>링크도 안박고 가서 글 쓰자고 선동하네</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47408</th>\n",
              "      <td>멸치가 틀딱 짜증나서 트러블나면 조직적으로 좀스럽게 보복함    수건찜유도탄  틀한...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47409 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      문장  여성/가족  남성  성소수자  \\\n",
              "0           문재앙은 김정은의 운전사도 안되는 똥휴지다  개돼지들이 뽑은 재앙민국이 망해간다      0   0     0   \n",
              "1      근데 사람들이 우스갯소리로  일 재앙이라고 했는데 이제보니 장난아니고  일   재앙...      0   0     0   \n",
              "2      공무뭔들도 정권 바뀐다는걸 아는구나 이놈들은 원래 연줄이 밥줄이라 눈치는 백단이지 ...      0   0     0   \n",
              "3      조옷도 모르는게 가만히 쳐있어 그냥 주둥이 나불대지말구 이 좌빨    니들 얘기하는...      0   0     0   \n",
              "4                                             토착빨갱이같으니라고      0   0     0   \n",
              "...                                                  ...    ...  ..   ...   \n",
              "47404                                             께롱께롱께롱      0   0     0   \n",
              "47405                              갱상도가아니라 홍어지 개좃같은 홍어년들      0   0     0   \n",
              "47406                           말레이시아랑 인도네시아 여자 존나 못생겼던데      1   0     0   \n",
              "47407                              링크도 안박고 가서 글 쓰자고 선동하네      0   0     0   \n",
              "47408  멸치가 틀딱 짜증나서 트러블나면 조직적으로 좀스럽게 보복함    수건찜유도탄  틀한...      0   0     0   \n",
              "\n",
              "       인종/국적  연령  지역  종교  기타혐오  악플/욕설  clean  \n",
              "0          0   0   0   0     0      1      0  \n",
              "1          0   0   0   0     0      0      0  \n",
              "2          0   0   0   0     0      1      0  \n",
              "3          0   0   0   0     0      0      0  \n",
              "4          0   0   0   0     0      0      0  \n",
              "...      ...  ..  ..  ..   ...    ...    ...  \n",
              "47404      0   0   0   0     0      0      1  \n",
              "47405      0   0   1   0     0      0      0  \n",
              "47406      1   0   0   0     0      0      0  \n",
              "47407      0   0   0   0     0      1      0  \n",
              "47408      0   1   0   0     0      0      0  \n",
              "\n",
              "[47409 rows x 11 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smile_train.drop(['교정문장', '띄어쓰기수정문장', '분쟁유발'], axis='columns', inplace=True)\n",
        "smile_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "from tqdm import tqdm\n",
        "mecab = Mecab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfzxEBh7iiw0"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iea1QZm8iOZF",
        "outputId": "1317df0e-ff8a-4fa8-afce-8b10f31b8bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47409, 11) 47409\n"
          ]
        }
      ],
      "source": [
        "# 중복 데이터 확인\n",
        "print(smile_train.shape, smile_train.문장.nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JNI4tD4imPr",
        "outputId": "facf0d51-7f16-484d-c273-f4679a1235e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Int64Index([    1,     3,     4,     5,     6,     7,     8,     9,    12,\n",
            "               13,\n",
            "            ...\n",
            "             4665,  4666,  4668,  4669,  4670,  4671,  4672,  4673, 38299,\n",
            "            44356],\n",
            "           dtype='int64', length=3497)\n"
          ]
        }
      ],
      "source": [
        "# 분류가 안되어 있는 데이터 확인\n",
        "print(smile_train[smile_train.sum(axis=1) == 0].index)\n",
        "\n",
        "# 분류 안되어 있는 데이터 삭제\n",
        "smile_train = smile_train[smile_train.sum(axis=1) != 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKer_96DitFo"
      },
      "source": [
        "## 텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5IX3wYqiogr",
        "outputId": "4fb09a60-7240-4a41-b74d-1a75f10d9202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(43912, 11)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
        "smile_train.문장 = smile_train.문장.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ').str.strip()\n",
        "smile_train.문장.replace('', np.nan, inplace=True)\n",
        "print(smile_train.문장.isna().sum())\n",
        "smile_train.dropna(how='any', inplace=True)\n",
        "smile_train.reset_index(drop=True, inplace=True)\n",
        "smile_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfuo5EuEi1jJ"
      },
      "source": [
        "## 한글 형태소 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jQI8aeFUi24V"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "60sRgabei6L_"
      },
      "outputs": [],
      "source": [
        "mecab = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "12a19fed85ac44e0a0ff9d0d315a2437",
            "c1b3b5cf469d4724bee0b683d086bd6a",
            "fa9cb9feb5a94822a034d7de70e532a4",
            "9bb720b3ffca49dfbbf7daed4a38bd8f",
            "e198174bd77b4f7f956ea3400c2ec411",
            "52111a848d5f457bae141141c13789a5",
            "eea6b7fbd97042a5bb334412275fa376",
            "8e5fdd00a9e042119747510e31e4ed6f",
            "7effcfa595ab453c931f6ac6d6331949",
            "6c5cec716bca435e83751a7d4a4f7148",
            "1b256fdaa85c4a43b5ffd51e24a2ef26"
          ]
        },
        "id": "1IY6fmFYi7Wh",
        "outputId": "079725fc-44c5-4866-8c08-7a887ac79cfe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00c9fca8c29d4344a8b4e91f5786780b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/43912 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_data = []\n",
        "for sentence in tqdm(smile_train.문장):\n",
        "  morphs = mecab.morphs(sentence)\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  train_data.append(tmp_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTlxIum4jAGS"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DK_cTI4UjBQ0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3tzDrKc8j0MU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nTBi_b7ej3TX"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(train_data, smile_train.iloc[:, 1:], test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_AvY2UCej78F"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OerlaZlPkNIC"
      },
      "outputs": [],
      "source": [
        "# 등장 빈도가 3 미만인 것의 갯수\n",
        "threshold = 3\n",
        "total_cnt = len(t.word_index)   # 단어의 수\n",
        "rare_cnt = 0                    # 등장 빈도가 threshold 보다 작은 단어의 갯수\n",
        "total_freq = 0                  # 훈련 데이터의 전체 단어의 빈도수의 합\n",
        "rare_freq = 0                   # 등장 빈도가 threshold 보다 작은 단어의 등장 빈도수의 합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XLLIkcmPkOvd"
      },
      "outputs": [],
      "source": [
        "for key, value in t.word_counts.items():\n",
        "  total_freq += value\n",
        "  if value < threshold:\n",
        "    rare_cnt += 1\n",
        "    rare_freq += value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9CcXvimkQzA",
        "outputId": "fe1c2a0c-3150-4238-c28c-72c19a446e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 35570\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 20492\n",
            "단어 집합에서 희귀 단어의 비율: 57.61034579701996\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.0437820936317173\n"
          ]
        }
      ],
      "source": [
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print(f'등장 빈도가 {threshold - 1}번 이하인 희귀 단어의 수: {rare_cnt}')\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFc63qS0kR5b",
        "outputId": "fe315ca8-c01e-42f9-de5a-7ac354d8feb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35572"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모든 단어 사용\n",
        "vocab_size = total_cnt + 2\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6sr9gEiokTSV"
      },
      "outputs": [],
      "source": [
        "t = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "t.fit_on_texts(train_data)\n",
        "X_train = t.texts_to_sequences(X_train)\n",
        "X_test = t.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yrcPP3FfwQIl"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('tokenizer.pkl','wb') as f:\n",
        "  pickle.dump(t,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv_x4Zeljkuw",
        "outputId": "974bc5e2-fac9-46c3-d291-b68ed795d0fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(164, 23.87093284750491)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터의 최대/평균 길이\n",
        "max(len(s) for s in X_train), sum(map(len, X_train)) / len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gFF3yk2BkY5C"
      },
      "outputs": [],
      "source": [
        "# 악플 길이를 70으로 설정\n",
        "max_len = 70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig1n57APkbNq",
        "outputId": "df60ac80-98da-4335-ae75-35d59e0155ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((35129, 70), (8783, 70))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ny4EYotFtWTY"
      },
      "outputs": [],
      "source": [
        "Y_train = Y_train.values\n",
        "Y_test = Y_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y5-Xs4Pkdou",
        "outputId": "d2c2d67f-ebee-43e3-8e7c-f5b9412e3ecb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((35129, 10), (8783, 10))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd5Jmi-Vkqdi"
      },
      "source": [
        "## 모델 정의/설정/학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pIjOoRfpeIw"
      },
      "source": [
        "### BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gBOrKzzypfOH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzmfYHqvphTp",
        "outputId": "b6376c05-4674-4716-c5f9-165d3a13634a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-16 09:26:18.671554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-16 09:26:18.744323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-16 09:26:18.744458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-16 09:26:18.745302: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-06-16 09:26:18.745995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-16 09:26:18.746096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-16 09:26:18.746161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-16 09:26:19.634673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-16 09:26:19.634827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-16 09:26:19.634894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-16 09:26:19.634962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9531 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 70)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 70, 128)           4553216   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 70, 256)          263168    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 70, 256)           0         \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,818,954\n",
            "Trainable params: 4,818,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 128, input_length=max_len)(inputs)\n",
        "\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(em)\n",
        "x = Dropout(0.1)(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model2 = Model(inputs = inputs, outputs = outputs)\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7i2F7s2Ypiim"
      },
      "outputs": [],
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2_path = 'best-bilstm.h5'\n",
        "mc2 = ModelCheckpoint(model2_path, verbose=1, save_best_only=True)\n",
        "es2 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGCadgvUpkoo",
        "outputId": "d1051269-cc2a-43f4-9f44-0566606f0479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-16 09:26:26.012668: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8101\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/220 [..............................] - ETA: 12:29 - loss: 2.7455 - accuracy: 0.1484"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-16 09:26:27.206047: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "215/220 [============================>.] - ETA: 0s - loss: 2.4039 - accuracy: 0.2316\n",
            "Epoch 00001: val_loss improved from inf to 1.93467, saving model to best-bilstm.h5\n",
            "220/220 [==============================] - 6s 14ms/step - loss: 2.3939 - accuracy: 0.2363 - val_loss: 1.9347 - val_accuracy: 0.4472\n",
            "Epoch 2/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 1.6349 - accuracy: 0.5838\n",
            "Epoch 00002: val_loss improved from 1.93467 to 1.55496, saving model to best-bilstm.h5\n",
            "220/220 [==============================] - 3s 12ms/step - loss: 1.6349 - accuracy: 0.5838 - val_loss: 1.5550 - val_accuracy: 0.6123\n",
            "Epoch 3/30\n",
            "217/220 [============================>.] - ETA: 0s - loss: 1.3496 - accuracy: 0.6860\n",
            "Epoch 00003: val_loss improved from 1.55496 to 1.52554, saving model to best-bilstm.h5\n",
            "220/220 [==============================] - 3s 12ms/step - loss: 1.3514 - accuracy: 0.6855 - val_loss: 1.5255 - val_accuracy: 0.6281\n",
            "Epoch 4/30\n",
            "218/220 [============================>.] - ETA: 0s - loss: 1.2737 - accuracy: 0.7061\n",
            "Epoch 00004: val_loss improved from 1.52554 to 1.47728, saving model to best-bilstm.h5\n",
            "220/220 [==============================] - 3s 12ms/step - loss: 1.2743 - accuracy: 0.7059 - val_loss: 1.4773 - val_accuracy: 0.6484\n",
            "Epoch 5/30\n",
            "216/220 [============================>.] - ETA: 0s - loss: 1.1821 - accuracy: 0.7292\n",
            "Epoch 00005: val_loss did not improve from 1.47728\n",
            "220/220 [==============================] - 2s 11ms/step - loss: 1.1817 - accuracy: 0.7295 - val_loss: 1.5989 - val_accuracy: 0.6207\n",
            "Epoch 6/30\n",
            "219/220 [============================>.] - ETA: 0s - loss: 1.1472 - accuracy: 0.7437\n",
            "Epoch 00006: val_loss did not improve from 1.47728\n",
            "220/220 [==============================] - 2s 11ms/step - loss: 1.1478 - accuracy: 0.7434 - val_loss: 1.6828 - val_accuracy: 0.6318\n",
            "Epoch 7/30\n",
            "215/220 [============================>.] - ETA: 0s - loss: 1.1168 - accuracy: 0.7547\n",
            "Epoch 00007: val_loss did not improve from 1.47728\n",
            "220/220 [==============================] - 2s 11ms/step - loss: 1.1157 - accuracy: 0.7549 - val_loss: 1.8065 - val_accuracy: 0.6159\n",
            "Epoch 8/30\n",
            "217/220 [============================>.] - ETA: 0s - loss: 1.1492 - accuracy: 0.7461\n",
            "Epoch 00008: val_loss did not improve from 1.47728\n",
            "220/220 [==============================] - 2s 11ms/step - loss: 1.1481 - accuracy: 0.7465 - val_loss: 1.9423 - val_accuracy: 0.5834\n",
            "Epoch 9/30\n",
            "216/220 [============================>.] - ETA: 0s - loss: 1.1385 - accuracy: 0.7544\n",
            "Epoch 00009: val_loss did not improve from 1.47728\n",
            "220/220 [==============================] - 2s 11ms/step - loss: 1.1371 - accuracy: 0.7550 - val_loss: 2.0332 - val_accuracy: 0.5983\n"
          ]
        }
      ],
      "source": [
        "hist = model2.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc2, es2]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyoZGMyVplu9",
        "outputId": "eda4579b-a4ae-4587-9f78-77b161ff00f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "275/275 [==============================] - 1s 3ms/step - loss: 1.4604 - accuracy: 0.6613\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.4603980779647827, 0.6612774729728699]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model2 = load_model(model2_path)\n",
        "best_model2.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'종북좌파 빨갱이새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 38.78412842750549%의 확률로 악플/욕설에 대한 악플입니다.\n",
            "[5.3943645e-02 9.8933339e-02 2.9625958e-02 7.0890278e-02 1.1872431e-01\n",
            " 5.2823655e-02 6.8609685e-02 1.1859394e-01 3.8784128e-01 1.3939148e-05]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model2,t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBwTTu6WqLNn"
      },
      "source": [
        "### BiLSTM + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "vS9_9RyXqOZS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional, LayerNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8hfkXehqP6N",
        "outputId": "7c6d1da0-6c4e-4fba-e009-c6936e880607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 70)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 70, 512)      18212864    ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 70, 512)     1574912     ['embedding_1[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 70, 512)     0           ['embedding_1[0][0]',            \n",
            " da)                                                              'bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 70, 512)     1024        ['tf.__operators__.add[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 512)          2099200     ['layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10)           5130        ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,893,130\n",
            "Trainable params: 21,893,130\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 512, input_length=max_len)(inputs)\n",
        "\n",
        "x = Bidirectional(LSTM(256, return_sequences=True))(em)\n",
        "x = LayerNormalization(epsilon=1e-6)(em + x)\n",
        "# x = Conv1D(256, 5, activation='relu')(x)\n",
        "# x = GlobalMaxPooling1D()(x)\n",
        "x = LSTM(512)(x)\n",
        "# x = Dropout(0.1)(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model3 = Model(inputs = inputs, outputs = outputs)\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ls8kJK5UqViC"
      },
      "outputs": [],
      "source": [
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3_path = 'best-bilstm-lstm.h5'\n",
        "mc3 = ModelCheckpoint(model3_path, verbose=1, save_best_only=True)\n",
        "es3 = EarlyStopping(patience=5)\n",
        "X_train = X_train.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2PtavLkqXty",
        "outputId": "2ff90d93-4e8f-40c4-8157-ad6783ecb366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "219/220 [============================>.] - ETA: 0s - loss: 1.4594 - accuracy: 0.6495\n",
            "Epoch 00001: val_loss improved from inf to 1.17998, saving model to best-bilstm-lstm.h5\n",
            "220/220 [==============================] - 14s 56ms/step - loss: 1.4591 - accuracy: 0.6497 - val_loss: 1.1800 - val_accuracy: 0.7721\n",
            "Epoch 2/50\n",
            "219/220 [============================>.] - ETA: 0s - loss: 1.0925 - accuracy: 0.8151\n",
            "Epoch 00002: val_loss did not improve from 1.17998\n",
            "220/220 [==============================] - 11s 50ms/step - loss: 1.0919 - accuracy: 0.8150 - val_loss: 1.4744 - val_accuracy: 0.7556\n",
            "Epoch 3/50\n",
            "219/220 [============================>.] - ETA: 0s - loss: 1.1361 - accuracy: 0.8439\n",
            "Epoch 00003: val_loss did not improve from 1.17998\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 1.1365 - accuracy: 0.8435 - val_loss: 4.4579 - val_accuracy: 0.5084\n",
            "Epoch 4/50\n",
            "219/220 [============================>.] - ETA: 0s - loss: 1.7219 - accuracy: 0.8184\n",
            "Epoch 00004: val_loss did not improve from 1.17998\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 1.7231 - accuracy: 0.8185 - val_loss: 2.5428 - val_accuracy: 0.7401\n",
            "Epoch 5/50\n",
            "220/220 [==============================] - ETA: 0s - loss: 1.2504 - accuracy: 0.8564\n",
            "Epoch 00005: val_loss did not improve from 1.17998\n",
            "220/220 [==============================] - 11s 50ms/step - loss: 1.2504 - accuracy: 0.8564 - val_loss: 3.8554 - val_accuracy: 0.7357\n",
            "Epoch 6/50\n",
            "220/220 [==============================] - ETA: 0s - loss: 1.2332 - accuracy: 0.8808\n",
            "Epoch 00006: val_loss did not improve from 1.17998\n",
            "220/220 [==============================] - 11s 50ms/step - loss: 1.2332 - accuracy: 0.8808 - val_loss: 3.7219 - val_accuracy: 0.7280\n"
          ]
        }
      ],
      "source": [
        "hist = model3.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=50, batch_size=128, callbacks=[mc3, es3]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbZ4nbsGqZEp",
        "outputId": "78aaa222-035f-4f27-cd4e-4388da82f6cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "275/275 [==============================] - 3s 8ms/step - loss: 1.1700 - accuracy: 0.7729\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.170005440711975, 0.7728566527366638]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model3 = load_model(model3_path)\n",
        "best_model3.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq7kw1lBEX7H",
        "outputId": "249368ef-abec-45df-e483-56828eda7cf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 1., 0., 1.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smile_train.iloc[:, 1:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "OA28wGcY-TPM"
      },
      "outputs": [],
      "source": [
        "a = best_model3.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0 3660  299 1708    7   45 1745\n",
            "  142 1892   49   37 1618 3072 4991  183    8   22   15   26  131    2\n",
            "   43 1204 1713  145    7    6    5  357   30   22   19 2705 3295    5] [1.8566119e-02 8.6000663e-01 1.2465653e-02 8.5147601e-03 7.9079801e-03\n",
            " 8.3633262e-04 1.7706309e-03 1.8368376e-02 4.7879521e-02 2.3684096e-02]\n"
          ]
        }
      ],
      "source": [
        "print(X_test[0],a[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VFp0R03gD3Iw",
        "outputId": "58f1aa31-2e18-455a-8a1b-0a20bffc2248"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'개인지칭'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/envs/kdig/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[0;32m~/anaconda3/envs/kdig/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/anaconda3/envs/kdig/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '개인지칭'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/home/wdc/바탕화면/Multi_5/modeling/220615_다중분류_코드.ipynb Cell 51'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wdc/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/Multi_5/modeling/220615_%EB%8B%A4%EC%A4%91%EB%B6%84%EB%A5%98_%EC%BD%94%EB%93%9C.ipynb#ch0000050?line=0'>1</a>\u001b[0m smile_train[smile_train[\u001b[39m'\u001b[39;49m\u001b[39m개인지칭\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m~/anaconda3/envs/kdig/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/anaconda3/envs/kdig/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: '개인지칭'"
          ]
        }
      ],
      "source": [
        "smile_train[smile_train['개인지칭'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "GWXihsJ4vel0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYMlHC6kAxRj",
        "outputId": "be23c66c-9f72-4a7a-fe9d-2cdbce179fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'짱꺠 씨발놈들'\n",
            " 85.09088158607483%의 확률로 인종/국적에 대한 악플입니다.\n",
            "[1.2451771e-03 1.5109007e-03 1.0151444e-04 8.5090882e-01 5.2194246e-03\n",
            " 1.0189397e-02 1.9893625e-03 3.2475218e-03 1.2555911e-01 2.8718128e-05]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('짱꺠 씨발놈들', best_model3,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDSOoC1dyC1P"
      },
      "source": [
        "### CNN + BiLSTM + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ZnThUWNSwvlQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional, LayerNormalization, Conv1D, Reshape\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXe6JWT6yGvQ",
        "outputId": "9e766f41-1ade-45b4-a1c1-e2b1b8c2ad79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 70)]              0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 70, 256)           9106432   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 66, 256)           327936    \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 66, 256)          394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,027,018\n",
            "Trainable params: 10,027,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 256, input_length=max_len)(inputs)\n",
        "\n",
        "x = Conv1D(256, 5, activation='relu')(em)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "x = LSTM(128)(x)\n",
        "# x = GlobalMaxPooling1D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model4 = Model(inputs = inputs, outputs = outputs)\n",
        "model4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "12RVVEVpyIrQ"
      },
      "outputs": [],
      "source": [
        "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model4_path = 'best-cnn-bilstm-lstm.h5'\n",
        "mc4 = ModelCheckpoint(model4_path, verbose=1, save_best_only=True)\n",
        "es4 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vyCd042yLCx",
        "outputId": "6ae86157-d050-4548-dc2d-e303227fefa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 2.2245 - accuracy: 0.4022\n",
            "Epoch 00001: val_loss improved from inf to 1.48260, saving model to best-cnn-bilstm-lstm.h5\n",
            "220/220 [==============================] - 9s 23ms/step - loss: 2.2245 - accuracy: 0.4022 - val_loss: 1.4826 - val_accuracy: 0.6909\n",
            "Epoch 2/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 1.6110 - accuracy: 0.6675\n",
            "Epoch 00002: val_loss improved from 1.48260 to 1.35963, saving model to best-cnn-bilstm-lstm.h5\n",
            "220/220 [==============================] - 5s 21ms/step - loss: 1.6110 - accuracy: 0.6675 - val_loss: 1.3596 - val_accuracy: 0.7091\n",
            "Epoch 3/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 1.4272 - accuracy: 0.7226\n",
            "Epoch 00003: val_loss did not improve from 1.35963\n",
            "220/220 [==============================] - 4s 20ms/step - loss: 1.4272 - accuracy: 0.7226 - val_loss: 1.5048 - val_accuracy: 0.7048\n",
            "Epoch 4/30\n",
            "219/220 [============================>.] - ETA: 0s - loss: 1.3727 - accuracy: 0.7546\n",
            "Epoch 00004: val_loss did not improve from 1.35963\n",
            "220/220 [==============================] - 4s 20ms/step - loss: 1.3739 - accuracy: 0.7546 - val_loss: 1.5965 - val_accuracy: 0.7424\n",
            "Epoch 5/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 1.3611 - accuracy: 0.7764\n",
            "Epoch 00005: val_loss did not improve from 1.35963\n",
            "220/220 [==============================] - 4s 20ms/step - loss: 1.3611 - accuracy: 0.7764 - val_loss: 1.8295 - val_accuracy: 0.7407\n",
            "Epoch 6/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 1.4468 - accuracy: 0.7732\n",
            "Epoch 00006: val_loss did not improve from 1.35963\n",
            "220/220 [==============================] - 4s 20ms/step - loss: 1.4468 - accuracy: 0.7732 - val_loss: 2.0030 - val_accuracy: 0.7249\n",
            "Epoch 7/30\n",
            "219/220 [============================>.] - ETA: 0s - loss: 1.4447 - accuracy: 0.7854\n",
            "Epoch 00007: val_loss did not improve from 1.35963\n",
            "220/220 [==============================] - 4s 20ms/step - loss: 1.4436 - accuracy: 0.7854 - val_loss: 2.2672 - val_accuracy: 0.7505\n"
          ]
        }
      ],
      "source": [
        "hist = model4.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc4, es4]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx2dRbD4yS7X",
        "outputId": "0f875d20-8b73-4d0f-bde9-e548d7a80a15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "275/275 [==============================] - 2s 4ms/step - loss: 1.3599 - accuracy: 0.7126\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.3598785400390625, 0.7126266360282898]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model4 = load_model(model4_path)\n",
        "best_model4.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 76.64451003074646%의 확률로 악플/욕설에 대한 악플입니다.\n",
            "[1.9820195e-02 1.0527811e-02 2.8749626e-02 5.3500343e-02 6.2547727e-03\n",
            " 1.0713669e-02 5.3658128e-02 5.0156832e-02 7.6644510e-01 1.7356283e-04]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model4,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Conv1D\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, None, 256)         9106432   \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, None, 64)          82176     \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 32)                12416     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,201,354\n",
            "Trainable params: 9,201,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model10 = Sequential()\n",
        "model10.add(Embedding(vocab_size,256))\n",
        "model10.add(LSTM(64, return_sequences=True))\n",
        "model10.add(LSTM(32))\n",
        "model10.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model10.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "model10.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model10_path = 'LSTM.h5'\n",
        "mc10 = ModelCheckpoint(model10_path, verbose=1, save_best_only=True)\n",
        "es10 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "215/220 [============================>.] - ETA: 0s - loss: 2.4691 - accuracy: 0.1907\n",
            "Epoch 00001: val_loss improved from inf to 2.03651, saving model to LSTM.h5\n",
            "220/220 [==============================] - 4s 14ms/step - loss: 2.4598 - accuracy: 0.1944 - val_loss: 2.0365 - val_accuracy: 0.4039\n",
            "Epoch 2/30\n",
            "216/220 [============================>.] - ETA: 0s - loss: 1.7067 - accuracy: 0.5752\n",
            "Epoch 00002: val_loss improved from 2.03651 to 1.63259, saving model to LSTM.h5\n",
            "220/220 [==============================] - 2s 11ms/step - loss: 1.7044 - accuracy: 0.5760 - val_loss: 1.6326 - val_accuracy: 0.5909\n",
            "Epoch 3/30\n",
            "215/220 [============================>.] - ETA: 0s - loss: 1.3436 - accuracy: 0.6974\n",
            "Epoch 00003: val_loss improved from 1.63259 to 1.48826, saving model to LSTM.h5\n",
            "220/220 [==============================] - 3s 11ms/step - loss: 1.3446 - accuracy: 0.6973 - val_loss: 1.4883 - val_accuracy: 0.6449\n",
            "Epoch 4/30\n",
            "216/220 [============================>.] - ETA: 0s - loss: 1.1554 - accuracy: 0.7586\n",
            "Epoch 00004: val_loss improved from 1.48826 to 1.46816, saving model to LSTM.h5\n",
            "220/220 [==============================] - 3s 12ms/step - loss: 1.1580 - accuracy: 0.7584 - val_loss: 1.4682 - val_accuracy: 0.6988\n",
            "Epoch 5/30\n",
            "217/220 [============================>.] - ETA: 0s - loss: 1.0327 - accuracy: 0.8045\n",
            "Epoch 00005: val_loss did not improve from 1.46816\n",
            "220/220 [==============================] - 2s 10ms/step - loss: 1.0319 - accuracy: 0.8045 - val_loss: 1.5786 - val_accuracy: 0.6917\n",
            "Epoch 6/30\n",
            "219/220 [============================>.] - ETA: 0s - loss: 0.9525 - accuracy: 0.8289\n",
            "Epoch 00006: val_loss did not improve from 1.46816\n",
            "220/220 [==============================] - 2s 10ms/step - loss: 0.9535 - accuracy: 0.8288 - val_loss: 1.7309 - val_accuracy: 0.6642\n",
            "Epoch 7/30\n",
            "219/220 [============================>.] - ETA: 0s - loss: 0.9034 - accuracy: 0.8465\n",
            "Epoch 00007: val_loss did not improve from 1.46816\n",
            "220/220 [==============================] - 2s 10ms/step - loss: 0.9030 - accuracy: 0.8465 - val_loss: 1.8248 - val_accuracy: 0.7003\n",
            "Epoch 8/30\n",
            "218/220 [============================>.] - ETA: 0s - loss: 0.8795 - accuracy: 0.8589\n",
            "Epoch 00008: val_loss did not improve from 1.46816\n",
            "220/220 [==============================] - 2s 10ms/step - loss: 0.8789 - accuracy: 0.8589 - val_loss: 1.9356 - val_accuracy: 0.6752\n",
            "Epoch 9/30\n",
            "216/220 [============================>.] - ETA: 0s - loss: 0.8948 - accuracy: 0.8570\n",
            "Epoch 00009: val_loss did not improve from 1.46816\n",
            "220/220 [==============================] - 2s 10ms/step - loss: 0.8954 - accuracy: 0.8575 - val_loss: 2.0917 - val_accuracy: 0.6886\n"
          ]
        }
      ],
      "source": [
        "hist10 = model10.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc10, es10]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "275/275 [==============================] - 1s 2ms/step - loss: 1.4706 - accuracy: 0.6987\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.4706467390060425, 0.6987361907958984]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model10 = load_model(model10_path)\n",
        "best_model10.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 81.13899230957031%의 확률로 악플/욕설에 대한 악플입니다.\n",
            "[1.1817344e-02 1.1788056e-02 2.0742339e-04 1.0794081e-02 7.7460550e-02\n",
            " 1.2709951e-02 8.5514765e-03 5.5103309e-02 8.1138992e-01 1.7784587e-04]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model10,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conv1D + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 70, 512)           18212864  \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 68, 32)            49184     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 34, 32)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 32, 32)            3104      \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,273,802\n",
            "Trainable params: 18,273,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "\n",
        "model6 = Sequential()\n",
        "model6.add(Embedding(vocab_size, 512, input_length=max_len))\n",
        "model6.add(Conv1D(32, 3, activation = 'relu'))\n",
        "model6.add(MaxPooling1D(2))\n",
        "model6.add(Conv1D(32, 3, activation = 'relu'))\n",
        "model6.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
        "model6.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model6.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "model6.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model6_path = 'Conv1D_LSTM.h5'\n",
        "mc6 = ModelCheckpoint(model6_path, verbose=1, save_best_only=True)\n",
        "es6 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 2.0849 - accuracy: 0.3847\n",
            "Epoch 00001: val_loss improved from inf to 1.46950, saving model to Conv1D_LSTM.h5\n",
            "220/220 [==============================] - 11s 47ms/step - loss: 2.0849 - accuracy: 0.3847 - val_loss: 1.4695 - val_accuracy: 0.6795\n",
            "Epoch 2/30\n",
            "219/220 [============================>.] - ETA: 0s - loss: 1.2726 - accuracy: 0.7404\n",
            "Epoch 00002: val_loss improved from 1.46950 to 1.30272, saving model to Conv1D_LSTM.h5\n",
            "220/220 [==============================] - 11s 49ms/step - loss: 1.2721 - accuracy: 0.7403 - val_loss: 1.3027 - val_accuracy: 0.7498\n",
            "Epoch 3/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 1.0548 - accuracy: 0.8136\n",
            "Epoch 00003: val_loss did not improve from 1.30272\n",
            "220/220 [==============================] - 10s 46ms/step - loss: 1.0548 - accuracy: 0.8136 - val_loss: 1.4207 - val_accuracy: 0.7381\n",
            "Epoch 4/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 0.9373 - accuracy: 0.8439\n",
            "Epoch 00004: val_loss did not improve from 1.30272\n",
            "220/220 [==============================] - 10s 46ms/step - loss: 0.9373 - accuracy: 0.8439 - val_loss: 1.5000 - val_accuracy: 0.7395\n",
            "Epoch 5/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 0.8705 - accuracy: 0.8629\n",
            "Epoch 00005: val_loss did not improve from 1.30272\n",
            "220/220 [==============================] - 10s 46ms/step - loss: 0.8705 - accuracy: 0.8629 - val_loss: 1.6545 - val_accuracy: 0.7232\n",
            "Epoch 6/30\n",
            "219/220 [============================>.] - ETA: 0s - loss: 0.8192 - accuracy: 0.8751\n",
            "Epoch 00006: val_loss did not improve from 1.30272\n",
            "220/220 [==============================] - 10s 45ms/step - loss: 0.8197 - accuracy: 0.8751 - val_loss: 1.8475 - val_accuracy: 0.7267\n",
            "Epoch 7/30\n",
            "220/220 [==============================] - ETA: 0s - loss: 0.7968 - accuracy: 0.8814\n",
            "Epoch 00007: val_loss did not improve from 1.30272\n",
            "220/220 [==============================] - 10s 46ms/step - loss: 0.7968 - accuracy: 0.8814 - val_loss: 2.0715 - val_accuracy: 0.7162\n"
          ]
        }
      ],
      "source": [
        "hist6 = model6.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc6, es6]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "275/275 [==============================] - 2s 6ms/step - loss: 1.3048 - accuracy: 0.7454\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.3047595024108887, 0.7454172968864441]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model6 = load_model(model6_path)\n",
        "best_model6.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 77.11883783340454%의 확률로 악플/욕설에 대한 악플입니다.\n",
            "[0.01707654 0.00433943 0.00714698 0.01873564 0.00339313 0.05533494\n",
            " 0.00262584 0.118674   0.7711884  0.00148509]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model6,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conv1D + BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 70, 512)           18212864  \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 68, 32)            49184     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 34, 32)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 32, 32)            3104      \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 32, 64)           16640     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,282,442\n",
            "Trainable params: 18,282,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "\n",
        "model7 = Sequential()\n",
        "model7.add(Embedding(vocab_size, 512, input_length=max_len))\n",
        "model7.add(Conv1D(32, 3, activation = 'relu'))\n",
        "model7.add(MaxPooling1D(2))\n",
        "model7.add(Conv1D(32, 3, activation = 'relu'))\n",
        "model7.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model7.add(GlobalMaxPooling1D())\n",
        "model7.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model7.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "model7.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
        "model7_path = 'Conv1D_BiLSTM.h5'\n",
        "mc7 = ModelCheckpoint(model7_path, verbose=1, save_best_only=True)\n",
        "es7 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "440/440 [==============================] - ETA: 0s - loss: 1.9254 - accuracy: 0.4487\n",
            "Epoch 00001: val_loss improved from inf to 1.44538, saving model to Conv1D_BiLSTM.h5\n",
            "440/440 [==============================] - 7s 14ms/step - loss: 1.9254 - accuracy: 0.4487 - val_loss: 1.4454 - val_accuracy: 0.6691\n",
            "Epoch 2/100\n",
            "438/440 [============================>.] - ETA: 0s - loss: 1.2821 - accuracy: 0.7283\n",
            "Epoch 00002: val_loss improved from 1.44538 to 1.40377, saving model to Conv1D_BiLSTM.h5\n",
            "440/440 [==============================] - 6s 14ms/step - loss: 1.2817 - accuracy: 0.7282 - val_loss: 1.4038 - val_accuracy: 0.7065\n",
            "Epoch 3/100\n",
            "436/440 [============================>.] - ETA: 0s - loss: 1.1210 - accuracy: 0.7967\n",
            "Epoch 00003: val_loss did not improve from 1.40377\n",
            "440/440 [==============================] - 6s 13ms/step - loss: 1.1228 - accuracy: 0.7961 - val_loss: 1.5218 - val_accuracy: 0.7134\n",
            "Epoch 4/100\n",
            "439/440 [============================>.] - ETA: 0s - loss: 1.0733 - accuracy: 0.8228\n",
            "Epoch 00004: val_loss did not improve from 1.40377\n",
            "440/440 [==============================] - 5s 12ms/step - loss: 1.0732 - accuracy: 0.8228 - val_loss: 1.7510 - val_accuracy: 0.6951\n",
            "Epoch 5/100\n",
            "437/440 [============================>.] - ETA: 0s - loss: 1.0402 - accuracy: 0.8426\n",
            "Epoch 00005: val_loss did not improve from 1.40377\n",
            "440/440 [==============================] - 5s 12ms/step - loss: 1.0406 - accuracy: 0.8423 - val_loss: 1.9154 - val_accuracy: 0.6988\n",
            "Epoch 6/100\n",
            "438/440 [============================>.] - ETA: 0s - loss: 1.0117 - accuracy: 0.8571\n",
            "Epoch 00006: val_loss did not improve from 1.40377\n",
            "440/440 [==============================] - 5s 12ms/step - loss: 1.0122 - accuracy: 0.8570 - val_loss: 2.2735 - val_accuracy: 0.6931\n",
            "Epoch 7/100\n",
            "437/440 [============================>.] - ETA: 0s - loss: 1.0156 - accuracy: 0.8681\n",
            "Epoch 00007: val_loss did not improve from 1.40377\n",
            "440/440 [==============================] - 6s 13ms/step - loss: 1.0154 - accuracy: 0.8680 - val_loss: 2.3234 - val_accuracy: 0.7035\n"
          ]
        }
      ],
      "source": [
        "hist7 = model7.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=100, batch_size=64, callbacks=[mc7, es7]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "275/275 [==============================] - 1s 2ms/step - loss: 1.3981 - accuracy: 0.7115\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.3981177806854248, 0.7114881277084351]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model7 = load_model(model7_path)\n",
        "best_model7.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    epochs=30, batch_size=32, callbacks=[mc8, es8]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 280 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f59f1d36b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "'종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 69.932621717453%의 확률로 악플/욕설에 대한 악플입니다.\n",
            "[9.0369083e-02 2.5155197e-03 1.2356249e-02 1.2679873e-02 1.5516406e-01\n",
            " 6.4723648e-04 4.9875593e-03 2.1878414e-02 6.9932622e-01 7.5757089e-05]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model7,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 70, 512)           18212864  \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               246528    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,460,682\n",
            "Trainable params: 18,460,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "\n",
        "model8 = Sequential()\n",
        "\n",
        "model8.add(Embedding(vocab_size, 512, input_length=max_len))\n",
        "model8.add(GRU(128))\n",
        "model8.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model8.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "model8.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
        "model8_path = 'GRU.h5'\n",
        "mc8 = ModelCheckpoint(model8_path, verbose=1, save_best_only=True)\n",
        "es8 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "878/879 [============================>.] - ETA: 0s - loss: 1.5210 - accuracy: 0.6098\n",
            "Epoch 00001: val_loss improved from inf to 1.15553, saving model to GRU.h5\n",
            "879/879 [==============================] - 12s 13ms/step - loss: 1.5213 - accuracy: 0.6098 - val_loss: 1.1555 - val_accuracy: 0.7636\n",
            "Epoch 2/30\n",
            "876/879 [============================>.] - ETA: 0s - loss: 1.1349 - accuracy: 0.7847\n",
            "Epoch 00002: val_loss did not improve from 1.15553\n",
            "879/879 [==============================] - 10s 12ms/step - loss: 1.1350 - accuracy: 0.7846 - val_loss: 1.4041 - val_accuracy: 0.7586\n",
            "Epoch 3/30\n",
            "875/879 [============================>.] - ETA: 0s - loss: 1.1171 - accuracy: 0.8251\n",
            "Epoch 00003: val_loss did not improve from 1.15553\n",
            "879/879 [==============================] - 10s 12ms/step - loss: 1.1168 - accuracy: 0.8250 - val_loss: 1.7807 - val_accuracy: 0.7445\n",
            "Epoch 4/30\n",
            "878/879 [============================>.] - ETA: 0s - loss: 1.1619 - accuracy: 0.8472\n",
            "Epoch 00004: val_loss did not improve from 1.15553\n",
            "879/879 [==============================] - 11s 12ms/step - loss: 1.1631 - accuracy: 0.8472 - val_loss: 2.7654 - val_accuracy: 0.7084\n",
            "Epoch 5/30\n",
            "879/879 [==============================] - ETA: 0s - loss: 1.2156 - accuracy: 0.8537\n",
            "Epoch 00005: val_loss did not improve from 1.15553\n",
            "879/879 [==============================] - 11s 12ms/step - loss: 1.2156 - accuracy: 0.8537 - val_loss: 2.8335 - val_accuracy: 0.7199\n",
            "Epoch 6/30\n",
            "879/879 [==============================] - ETA: 0s - loss: 1.2443 - accuracy: 0.8535\n",
            "Epoch 00006: val_loss did not improve from 1.15553\n",
            "879/879 [==============================] - 11s 12ms/step - loss: 1.2443 - accuracy: 0.8535 - val_loss: 3.3918 - val_accuracy: 0.7051\n"
          ]
        }
      ],
      "source": [
        "hist8 = model8.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=32, callbacks=[mc8, es8]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "275/275 [==============================] - 1s 2ms/step - loss: 1.1498 - accuracy: 0.7634\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.1497737169265747, 0.7634065747261047]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model8 = load_model(model8_path)\n",
        "best_model8.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 281 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f59f133b8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "'종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 72.1695601940155%의 확률로 악플/욕설에 대한 악플입니다.\n",
            "[6.9866166e-02 3.5645917e-02 1.0984234e-02 3.2379553e-02 3.2086052e-02\n",
            " 1.0130853e-02 1.5756112e-02 7.0944749e-02 7.2169560e-01 5.1076728e-04]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model8,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 70, 512)           18212864  \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 66, 32)            81952     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 32)                6336      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,301,482\n",
            "Trainable params: 18,301,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "\n",
        "model9 = Sequential()\n",
        "\n",
        "model9.add(Embedding(vocab_size, 512, input_length=max_len))\n",
        "model9.add(Conv1D(32, 5, activation = 'relu'))\n",
        "model9.add(GRU(32))\n",
        "model9.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model9.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "model9.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
        "model9_path = 'Conv1D_GRU.h5'\n",
        "mc9 = ModelCheckpoint(model9_path, verbose=1, save_best_only=True)\n",
        "es9 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "440/440 [==============================] - ETA: 0s - loss: 1.7560 - accuracy: 0.5272\n",
            "Epoch 00001: val_loss improved from inf to 1.21036, saving model to Conv1D_GRU.h5\n",
            "440/440 [==============================] - 7s 14ms/step - loss: 1.7560 - accuracy: 0.5272 - val_loss: 1.2104 - val_accuracy: 0.7639\n",
            "Epoch 2/100\n",
            "439/440 [============================>.] - ETA: 0s - loss: 1.0346 - accuracy: 0.8063\n",
            "Epoch 00002: val_loss improved from 1.21036 to 1.19940, saving model to Conv1D_GRU.h5\n",
            "440/440 [==============================] - 6s 13ms/step - loss: 1.0345 - accuracy: 0.8064 - val_loss: 1.1994 - val_accuracy: 0.7599\n",
            "Epoch 3/100\n",
            "438/440 [============================>.] - ETA: 0s - loss: 0.8550 - accuracy: 0.8587\n",
            "Epoch 00003: val_loss did not improve from 1.19940\n",
            "440/440 [==============================] - 5s 12ms/step - loss: 0.8552 - accuracy: 0.8586 - val_loss: 1.3681 - val_accuracy: 0.7394\n",
            "Epoch 4/100\n",
            "440/440 [==============================] - ETA: 0s - loss: 0.7706 - accuracy: 0.8905\n",
            "Epoch 00004: val_loss did not improve from 1.19940\n",
            "440/440 [==============================] - 5s 12ms/step - loss: 0.7706 - accuracy: 0.8905 - val_loss: 1.6087 - val_accuracy: 0.7328\n",
            "Epoch 5/100\n",
            "439/440 [============================>.] - ETA: 0s - loss: 0.7300 - accuracy: 0.9049\n",
            "Epoch 00005: val_loss did not improve from 1.19940\n",
            "440/440 [==============================] - 5s 12ms/step - loss: 0.7300 - accuracy: 0.9049 - val_loss: 1.8394 - val_accuracy: 0.7259\n",
            "Epoch 6/100\n",
            "436/440 [============================>.] - ETA: 0s - loss: 0.6973 - accuracy: 0.9111\n",
            "Epoch 00006: val_loss did not improve from 1.19940\n",
            "440/440 [==============================] - 5s 12ms/step - loss: 0.6998 - accuracy: 0.9109 - val_loss: 2.1306 - val_accuracy: 0.7252\n",
            "Epoch 7/100\n",
            "440/440 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.9180\n",
            "Epoch 00007: val_loss did not improve from 1.19940\n",
            "440/440 [==============================] - 5s 12ms/step - loss: 0.6944 - accuracy: 0.9180 - val_loss: 2.5021 - val_accuracy: 0.7146\n"
          ]
        }
      ],
      "source": [
        "hist9 = model9.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=100, batch_size=64, callbacks=[mc9, es9]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "275/275 [==============================] - 1s 2ms/step - loss: 1.1855 - accuracy: 0.7672\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1.1854721307754517, 0.7671638131141663)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model9 = load_model(model9_path)\n",
        "loss9, acc9 = best_model9.evaluate(X_test, Y_test)\n",
        "loss9, acc9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'안녕 개새끼들아'\n",
            " 59.7104549407959%의 확률로 악플/욕설에 대한 악플입니다.\n",
            "[0.01004287 0.01034687 0.00304204 0.0219156  0.02924209 0.06849256\n",
            " 0.00078374 0.05692672 0.59710455 0.20210299]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('안녕 개새끼들아', best_model9,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPH2KlEDOQngwJKJeWZb7mV",
      "collapsed_sections": [],
      "name": "악플 다중 분류기.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('kdig')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "2331b4e723e7fb95574426231c2e7dc69a881cc0353adc5d6ad18e8a0d6e58aa"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "022175175d014a6b9198a150c0809b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08516e149bcc44ceb00363d403370336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bee5d6df3c9484c9e3dc1cb7c2381b3",
              "IPY_MODEL_abd0ce1e092045e0886f38f7c9ac9aae",
              "IPY_MODEL_c57efda8f0b144cbb714d5cb9a75d61f"
            ],
            "layout": "IPY_MODEL_09ea2325e69744de9bdff94fb1a035bd"
          }
        },
        "09af3b0e7f9646319240a8fe7d55fceb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ea2325e69744de9bdff94fb1a035bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a19fed85ac44e0a0ff9d0d315a2437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1b3b5cf469d4724bee0b683d086bd6a",
              "IPY_MODEL_fa9cb9feb5a94822a034d7de70e532a4",
              "IPY_MODEL_9bb720b3ffca49dfbbf7daed4a38bd8f"
            ],
            "layout": "IPY_MODEL_e198174bd77b4f7f956ea3400c2ec411"
          }
        },
        "1b256fdaa85c4a43b5ffd51e24a2ef26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bee5d6df3c9484c9e3dc1cb7c2381b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09af3b0e7f9646319240a8fe7d55fceb",
            "placeholder": "​",
            "style": "IPY_MODEL_a1112dda635c4a0d8efeae4269238341",
            "value": "100%"
          }
        },
        "46568df230764cf6bdf54f04cd4018ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52111a848d5f457bae141141c13789a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5cec716bca435e83751a7d4a4f7148": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7effcfa595ab453c931f6ac6d6331949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b6a160a24d54b17aff0db8b4e2badf3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e5fdd00a9e042119747510e31e4ed6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bb720b3ffca49dfbbf7daed4a38bd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c5cec716bca435e83751a7d4a4f7148",
            "placeholder": "​",
            "style": "IPY_MODEL_1b256fdaa85c4a43b5ffd51e24a2ef26",
            "value": " 47407/47407 [00:08&lt;00:00, 9126.68it/s]"
          }
        },
        "a1112dda635c4a0d8efeae4269238341": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abd0ce1e092045e0886f38f7c9ac9aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b6a160a24d54b17aff0db8b4e2badf3",
            "max": 14690,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_022175175d014a6b9198a150c0809b43",
            "value": 14690
          }
        },
        "c1b3b5cf469d4724bee0b683d086bd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52111a848d5f457bae141141c13789a5",
            "placeholder": "​",
            "style": "IPY_MODEL_eea6b7fbd97042a5bb334412275fa376",
            "value": "100%"
          }
        },
        "c57efda8f0b144cbb714d5cb9a75d61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eedc65d4ea8547a5a40bf97fe7f15e4c",
            "placeholder": "​",
            "style": "IPY_MODEL_46568df230764cf6bdf54f04cd4018ac",
            "value": " 14690/14690 [00:02&lt;00:00, 8716.82it/s]"
          }
        },
        "e198174bd77b4f7f956ea3400c2ec411": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea6b7fbd97042a5bb334412275fa376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eedc65d4ea8547a5a40bf97fe7f15e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa9cb9feb5a94822a034d7de70e532a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e5fdd00a9e042119747510e31e4ed6f",
            "max": 47407,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7effcfa595ab453c931f6ac6d6331949",
            "value": 47407
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
