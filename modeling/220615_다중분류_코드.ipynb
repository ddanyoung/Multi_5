{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9CfSaiVib0r"
      },
      "source": [
        "# 악플 분류기 - 다중분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a_ypjpJOTlVQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HTAfT9JFAir0"
      },
      "outputs": [],
      "source": [
        "smile_train = pd.read_csv(\"../data/multi label data/common_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "      <th>분쟁유발</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>문재앙은 김정은의 운전사도 안되는 똥휴지다  개돼지들이 뽑은 재앙민국이 망해간다</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>근데 사람들이 우스갯소리로  일 재앙이라고 했는데 이제보니 장난아니고  일   재앙...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>공무뭔들도 정권 바뀐다는걸 아는구나 이놈들은 원래 연줄이 밥줄이라 눈치는 백단이지 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>조옷도 모르는게 가만히 쳐있어 그냥 주둥이 나불대지말구 이 좌빨    니들 얘기하는...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>토착빨갱이같으니라고</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47404</th>\n",
              "      <td>께롱께롱께롱</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47405</th>\n",
              "      <td>갱상도가아니라 홍어지 개좃같은 홍어년들</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47406</th>\n",
              "      <td>말레이시아랑 인도네시아 여자 존나 못생겼던데</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47407</th>\n",
              "      <td>링크도 안박고 가서 글 쓰자고 선동하네</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47408</th>\n",
              "      <td>멸치가 틀딱 짜증나서 트러블나면 조직적으로 좀스럽게 보복함    수건찜유도탄  틀한...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47409 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      문장  여성/가족  남성  성소수자  \\\n",
              "0           문재앙은 김정은의 운전사도 안되는 똥휴지다  개돼지들이 뽑은 재앙민국이 망해간다      0   0     0   \n",
              "1      근데 사람들이 우스갯소리로  일 재앙이라고 했는데 이제보니 장난아니고  일   재앙...      0   0     0   \n",
              "2      공무뭔들도 정권 바뀐다는걸 아는구나 이놈들은 원래 연줄이 밥줄이라 눈치는 백단이지 ...      0   0     0   \n",
              "3      조옷도 모르는게 가만히 쳐있어 그냥 주둥이 나불대지말구 이 좌빨    니들 얘기하는...      0   0     0   \n",
              "4                                             토착빨갱이같으니라고      0   0     0   \n",
              "...                                                  ...    ...  ..   ...   \n",
              "47404                                             께롱께롱께롱      0   0     0   \n",
              "47405                              갱상도가아니라 홍어지 개좃같은 홍어년들      0   0     0   \n",
              "47406                           말레이시아랑 인도네시아 여자 존나 못생겼던데      1   0     0   \n",
              "47407                              링크도 안박고 가서 글 쓰자고 선동하네      0   0     0   \n",
              "47408  멸치가 틀딱 짜증나서 트러블나면 조직적으로 좀스럽게 보복함    수건찜유도탄  틀한...      0   0     0   \n",
              "\n",
              "       인종/국적  연령  지역  종교  기타혐오  악플/욕설  clean  분쟁유발  \n",
              "0          0   0   0   0     0      1      0   1.0  \n",
              "1          0   0   0   0     0      0      0   1.0  \n",
              "2          0   0   0   0     0      1      0   1.0  \n",
              "3          0   0   0   0     0      0      0   1.0  \n",
              "4          0   0   0   0     0      0      0   1.0  \n",
              "...      ...  ..  ..  ..   ...    ...    ...   ...  \n",
              "47404      0   0   0   0     0      0      1   0.0  \n",
              "47405      0   0   1   0     0      0      0   0.0  \n",
              "47406      1   0   0   0     0      0      0   0.0  \n",
              "47407      0   0   0   0     0      1      0   0.0  \n",
              "47408      0   1   0   0     0      0      0   0.0  \n",
              "\n",
              "[47409 rows x 12 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smile_train.drop(['교정문장', '띄어쓰기수정문장'], axis='columns', inplace=True)\n",
        "smile_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "from tqdm import tqdm\n",
        "mecab = Mecab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfzxEBh7iiw0"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iea1QZm8iOZF",
        "outputId": "1317df0e-ff8a-4fa8-afce-8b10f31b8bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47409, 12) 47409\n"
          ]
        }
      ],
      "source": [
        "# 중복 데이터 확인\n",
        "print(smile_train.shape, smile_train.문장.nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JNI4tD4imPr",
        "outputId": "facf0d51-7f16-484d-c273-f4679a1235e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Int64Index([38299, 44356], dtype='int64')\n"
          ]
        }
      ],
      "source": [
        "# 분류가 안되어 있는 데이터 확인\n",
        "print(smile_train[smile_train.sum(axis=1) == 0].index)\n",
        "\n",
        "# 분류 안되어 있는 데이터 삭제\n",
        "smile_train = smile_train[smile_train.sum(axis=1) != 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKer_96DitFo"
      },
      "source": [
        "## 텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5IX3wYqiogr",
        "outputId": "4fb09a60-7240-4a41-b74d-1a75f10d9202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(47407, 12)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
        "smile_train.문장 = smile_train.문장.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ').str.strip()\n",
        "smile_train.문장.replace('', np.nan, inplace=True)\n",
        "print(smile_train.문장.isna().sum())\n",
        "smile_train.dropna(how='any', inplace=True)\n",
        "smile_train.reset_index(drop=True, inplace=True)\n",
        "smile_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfuo5EuEi1jJ"
      },
      "source": [
        "## 한글 형태소 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jQI8aeFUi24V"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "60sRgabei6L_"
      },
      "outputs": [],
      "source": [
        "mecab = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "12a19fed85ac44e0a0ff9d0d315a2437",
            "c1b3b5cf469d4724bee0b683d086bd6a",
            "fa9cb9feb5a94822a034d7de70e532a4",
            "9bb720b3ffca49dfbbf7daed4a38bd8f",
            "e198174bd77b4f7f956ea3400c2ec411",
            "52111a848d5f457bae141141c13789a5",
            "eea6b7fbd97042a5bb334412275fa376",
            "8e5fdd00a9e042119747510e31e4ed6f",
            "7effcfa595ab453c931f6ac6d6331949",
            "6c5cec716bca435e83751a7d4a4f7148",
            "1b256fdaa85c4a43b5ffd51e24a2ef26"
          ]
        },
        "id": "1IY6fmFYi7Wh",
        "outputId": "079725fc-44c5-4866-8c08-7a887ac79cfe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94f573ecddd446b8acb1f3570abebff5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/47407 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_data = []\n",
        "for sentence in tqdm(smile_train.문장):\n",
        "  morphs = mecab.morphs(sentence)\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  train_data.append(tmp_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTlxIum4jAGS"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DK_cTI4UjBQ0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3tzDrKc8j0MU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nTBi_b7ej3TX"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(train_data, smile_train.iloc[:, 1:], test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_AvY2UCej78F"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OerlaZlPkNIC"
      },
      "outputs": [],
      "source": [
        "# 등장 빈도가 3 미만인 것의 갯수\n",
        "threshold = 3\n",
        "total_cnt = len(t.word_index)   # 단어의 수\n",
        "rare_cnt = 0                    # 등장 빈도가 threshold 보다 작은 단어의 갯수\n",
        "total_freq = 0                  # 훈련 데이터의 전체 단어의 빈도수의 합\n",
        "rare_freq = 0                   # 등장 빈도가 threshold 보다 작은 단어의 등장 빈도수의 합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XLLIkcmPkOvd"
      },
      "outputs": [],
      "source": [
        "for key, value in t.word_counts.items():\n",
        "  total_freq += value\n",
        "  if value < threshold:\n",
        "    rare_cnt += 1\n",
        "    rare_freq += value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9CcXvimkQzA",
        "outputId": "fe1c2a0c-3150-4238-c28c-72c19a446e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 36985\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 21328\n",
            "단어 집합에서 희귀 단어의 비율: 57.66662160335271\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.9262103314779724\n"
          ]
        }
      ],
      "source": [
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print(f'등장 빈도가 {threshold - 1}번 이하인 희귀 단어의 수: {rare_cnt}')\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFc63qS0kR5b",
        "outputId": "fe315ca8-c01e-42f9-de5a-7ac354d8feb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "36987"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모든 단어 사용\n",
        "vocab_size = total_cnt + 2\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6sr9gEiokTSV"
      },
      "outputs": [],
      "source": [
        "t = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "t.fit_on_texts(train_data)\n",
        "X_train = t.texts_to_sequences(X_train)\n",
        "X_test = t.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yrcPP3FfwQIl"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('tokenizer.pkl','wb') as f:\n",
        "  pickle.dump(t,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv_x4Zeljkuw",
        "outputId": "974bc5e2-fac9-46c3-d291-b68ed795d0fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(164, 23.960922874093605)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터의 최대/평균 길이\n",
        "max(len(s) for s in X_train), sum(map(len, X_train)) / len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gFF3yk2BkY5C"
      },
      "outputs": [],
      "source": [
        "# 악플 길이를 70으로 설정\n",
        "max_len = 70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig1n57APkbNq",
        "outputId": "df60ac80-98da-4335-ae75-35d59e0155ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((37925, 70), (9482, 70))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ny4EYotFtWTY"
      },
      "outputs": [],
      "source": [
        "Y_train = Y_train.values\n",
        "Y_test = Y_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y5-Xs4Pkdou",
        "outputId": "d2c2d67f-ebee-43e3-8e7c-f5b9412e3ecb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((37925, 11), (9482, 11))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd5Jmi-Vkqdi"
      },
      "source": [
        "## 모델 정의/설정/학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pIjOoRfpeIw"
      },
      "source": [
        "### BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gBOrKzzypfOH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzmfYHqvphTp",
        "outputId": "b6376c05-4674-4716-c5f9-165d3a13634a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 70)]              0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 70, 128)           4734336   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 70, 256)          263168    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 70, 256)           0         \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 11)                2827      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,000,331\n",
            "Trainable params: 5,000,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 128, input_length=max_len)(inputs)\n",
        "\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(em)\n",
        "x = Dropout(0.1)(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "outputs = Dense(11, activation='softmax')(x)\n",
        "\n",
        "model2 = Model(inputs = inputs, outputs = outputs)\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "7i2F7s2Ypiim"
      },
      "outputs": [],
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2_path = 'best-bilstm.h5'\n",
        "mc2 = ModelCheckpoint(model2_path, verbose=1, save_best_only=True)\n",
        "es2 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGCadgvUpkoo",
        "outputId": "d1051269-cc2a-43f4-9f44-0566606f0479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "235/238 [============================>.] - ETA: 0s - loss: 2.7351 - accuracy: 0.1862\n",
            "Epoch 00001: val_loss improved from inf to 2.33801, saving model to best-bilstm.h5\n",
            "238/238 [==============================] - 5s 13ms/step - loss: 2.7332 - accuracy: 0.1873 - val_loss: 2.3380 - val_accuracy: 0.2990\n",
            "Epoch 2/30\n",
            "236/238 [============================>.] - ETA: 0s - loss: 2.1767 - accuracy: 0.4219\n",
            "Epoch 00002: val_loss improved from 2.33801 to 2.08688, saving model to best-bilstm.h5\n",
            "238/238 [==============================] - 3s 12ms/step - loss: 2.1760 - accuracy: 0.4223 - val_loss: 2.0869 - val_accuracy: 0.4334\n",
            "Epoch 3/30\n",
            "236/238 [============================>.] - ETA: 0s - loss: 1.8518 - accuracy: 0.5410\n",
            "Epoch 00003: val_loss improved from 2.08688 to 1.95171, saving model to best-bilstm.h5\n",
            "238/238 [==============================] - 3s 12ms/step - loss: 1.8517 - accuracy: 0.5412 - val_loss: 1.9517 - val_accuracy: 0.5123\n",
            "Epoch 4/30\n",
            "236/238 [============================>.] - ETA: 0s - loss: 1.6822 - accuracy: 0.6097\n",
            "Epoch 00004: val_loss improved from 1.95171 to 1.90170, saving model to best-bilstm.h5\n",
            "238/238 [==============================] - 3s 12ms/step - loss: 1.6819 - accuracy: 0.6098 - val_loss: 1.9017 - val_accuracy: 0.5586\n",
            "Epoch 5/30\n",
            "235/238 [============================>.] - ETA: 0s - loss: 1.6016 - accuracy: 0.6446\n",
            "Epoch 00005: val_loss did not improve from 1.90170\n",
            "238/238 [==============================] - 3s 12ms/step - loss: 1.6042 - accuracy: 0.6436 - val_loss: 1.9596 - val_accuracy: 0.5475\n",
            "Epoch 6/30\n",
            "236/238 [============================>.] - ETA: 0s - loss: 1.5431 - accuracy: 0.6598\n",
            "Epoch 00006: val_loss did not improve from 1.90170\n",
            "238/238 [==============================] - 3s 12ms/step - loss: 1.5434 - accuracy: 0.6598 - val_loss: 1.9275 - val_accuracy: 0.5838\n",
            "Epoch 7/30\n",
            "236/238 [============================>.] - ETA: 0s - loss: 1.5633 - accuracy: 0.6636\n",
            "Epoch 00007: val_loss did not improve from 1.90170\n",
            "238/238 [==============================] - 3s 11ms/step - loss: 1.5653 - accuracy: 0.6632 - val_loss: 2.2415 - val_accuracy: 0.5226\n",
            "Epoch 8/30\n",
            "236/238 [============================>.] - ETA: 0s - loss: 1.5935 - accuracy: 0.6603\n",
            "Epoch 00008: val_loss did not improve from 1.90170\n",
            "238/238 [==============================] - 3s 11ms/step - loss: 1.5922 - accuracy: 0.6605 - val_loss: 2.1179 - val_accuracy: 0.5342\n",
            "Epoch 9/30\n",
            "236/238 [============================>.] - ETA: 0s - loss: 1.5221 - accuracy: 0.6740\n",
            "Epoch 00009: val_loss did not improve from 1.90170\n",
            "238/238 [==============================] - 3s 11ms/step - loss: 1.5247 - accuracy: 0.6737 - val_loss: 2.2399 - val_accuracy: 0.5453\n"
          ]
        }
      ],
      "source": [
        "hist = model2.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc2, es2]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyoZGMyVplu9",
        "outputId": "eda4579b-a4ae-4587-9f78-77b161ff00f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 1s 3ms/step - loss: 1.9146 - accuracy: 0.5500\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.9146223068237305, 0.5499894618988037]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model2 = load_model(model2_path)\n",
        "best_model2.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'종북좌파 빨갱이새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 59.67366695404053%의 확률로 분쟁유발에 대한 악플입니다.\n",
            "[1.0289536e-02 4.0037604e-03 2.7747632e-03 1.2924887e-02 8.9323103e-02\n",
            " 4.1950587e-02 1.3393288e-02 1.3148430e-01 9.7117752e-02 1.3318263e-06\n",
            " 5.9673667e-01]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model2,t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBwTTu6WqLNn"
      },
      "source": [
        "### BiLSTM + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vS9_9RyXqOZS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional, LayerNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8hfkXehqP6N",
        "outputId": "7c6d1da0-6c4e-4fba-e009-c6936e880607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 70)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 70, 512)      18937344    ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 70, 512)     1574912     ['embedding_3[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 70, 512)     0           ['embedding_3[0][0]',            \n",
            " da)                                                              'bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 70, 512)     1024        ['tf.__operators__.add[0][0]']   \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 512)          2099200     ['layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 11)           5643        ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22,618,123\n",
            "Trainable params: 22,618,123\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 512, input_length=max_len)(inputs)\n",
        "\n",
        "x = Bidirectional(LSTM(256, return_sequences=True))(em)\n",
        "x = LayerNormalization(epsilon=1e-6)(em + x)\n",
        "# x = Conv1D(256, 5, activation='relu')(x)\n",
        "# x = GlobalMaxPooling1D()(x)\n",
        "x = LSTM(512)(x)\n",
        "# x = Dropout(0.1)(x)\n",
        "outputs = Dense(11, activation='softmax')(x)\n",
        "\n",
        "model3 = Model(inputs = inputs, outputs = outputs)\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ls8kJK5UqViC"
      },
      "outputs": [],
      "source": [
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3_path = 'best-bilstm-lstm.h5'\n",
        "mc3 = ModelCheckpoint(model3_path, verbose=1, save_best_only=True)\n",
        "es3 = EarlyStopping(patience=5)\n",
        "X_train = X_train.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2PtavLkqXty",
        "outputId": "2ff90d93-4e8f-40c4-8157-ad6783ecb366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "237/238 [============================>.] - ETA: 0s - loss: 2.2354 - accuracy: 0.8089\n",
            "Epoch 00001: val_loss did not improve from 1.48607\n",
            "238/238 [==============================] - 12s 49ms/step - loss: 2.2354 - accuracy: 0.8088 - val_loss: 6.6521 - val_accuracy: 0.6894\n",
            "Epoch 2/50\n",
            "238/238 [==============================] - ETA: 0s - loss: 2.2159 - accuracy: 0.8249\n",
            "Epoch 00002: val_loss did not improve from 1.48607\n",
            "238/238 [==============================] - 12s 50ms/step - loss: 2.2159 - accuracy: 0.8249 - val_loss: 8.5403 - val_accuracy: 0.6345\n",
            "Epoch 3/50\n",
            "237/238 [============================>.] - ETA: 0s - loss: 2.0882 - accuracy: 0.8194\n",
            "Epoch 00003: val_loss did not improve from 1.48607\n",
            "238/238 [==============================] - 12s 51ms/step - loss: 2.0881 - accuracy: 0.8193 - val_loss: 6.8460 - val_accuracy: 0.6709\n",
            "Epoch 4/50\n",
            "238/238 [==============================] - ETA: 0s - loss: 2.3450 - accuracy: 0.8218\n",
            "Epoch 00004: val_loss did not improve from 1.48607\n",
            "238/238 [==============================] - 12s 50ms/step - loss: 2.3450 - accuracy: 0.8218 - val_loss: 10.2985 - val_accuracy: 0.6713\n",
            "Epoch 5/50\n",
            "237/238 [============================>.] - ETA: 0s - loss: 2.2925 - accuracy: 0.8195\n",
            "Epoch 00005: val_loss did not improve from 1.48607\n",
            "238/238 [==============================] - 12s 49ms/step - loss: 2.2931 - accuracy: 0.8194 - val_loss: 12.4745 - val_accuracy: 0.6745\n",
            "Epoch 6/50\n",
            "238/238 [==============================] - ETA: 0s - loss: 2.8048 - accuracy: 0.8064\n",
            "Epoch 00006: val_loss did not improve from 1.48607\n",
            "238/238 [==============================] - 12s 51ms/step - loss: 2.8048 - accuracy: 0.8064 - val_loss: 13.7642 - val_accuracy: 0.6629\n"
          ]
        }
      ],
      "source": [
        "hist = model3.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=50, batch_size=128, callbacks=[mc3, es3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbZ4nbsGqZEp",
        "outputId": "78aaa222-035f-4f27-cd4e-4388da82f6cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 3s 8ms/step - loss: 1.4628 - accuracy: 0.7281\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.4627939462661743, 0.7281164526939392]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model3 = load_model(model3_path)\n",
        "best_model3.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq7kw1lBEX7H",
        "outputId": "249368ef-abec-45df-e483-56828eda7cf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 1., 0., 1.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smile_train.iloc[:, 1:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OA28wGcY-TPM"
      },
      "outputs": [],
      "source": [
        "a = best_model3.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0  430 1788  543  954] [6.5020239e-03 5.3583640e-03 8.5508255e-03 6.1273631e-03 1.4967654e-03\n",
            " 6.5123998e-03 1.7228330e-02 2.2037890e-02 1.9144014e-01 7.3440826e-01\n",
            " 3.3765769e-04]\n"
          ]
        }
      ],
      "source": [
        "print(X_test[0],a[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VFp0R03gD3Iw",
        "outputId": "58f1aa31-2e18-455a-8a1b-0a20bffc2248"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타 혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "      <th>개인지칭</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [문장, 여성/가족, 남성, 성소수자, 인종/국적, 연령, 지역, 종교, 기타 혐오, 악플/욕설, clean, 개인지칭]\n",
              "Index: []"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smile_train[smile_train['개인지칭'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "GWXihsJ4vel0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYMlHC6kAxRj",
        "outputId": "be23c66c-9f72-4a7a-fe9d-2cdbce179fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'짱꺠 씨발놈들'\n",
            " 93.59042644500732%의 확률로 인종/국적에 대한 악플입니다.\n",
            "[1.7940421e-03 7.3899966e-05 3.7657669e-06 9.3590426e-01 1.9234995e-04\n",
            " 1.3980011e-03 2.4783649e-03 2.1128661e-03 5.4138895e-02 3.7260385e-08\n",
            " 1.9035075e-03]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('짱꺠 씨발놈들', best_model3,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDSOoC1dyC1P"
      },
      "source": [
        "### CNN + BiLSTM + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZnThUWNSwvlQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional, LayerNormalization, Conv1D, Reshape\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXe6JWT6yGvQ",
        "outputId": "9e766f41-1ade-45b4-a1c1-e2b1b8c2ad79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 70)]              0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 70, 256)           9468672   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 66, 256)           327936    \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 66, 256)          394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 11)                1419      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,389,387\n",
            "Trainable params: 10,389,387\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 256, input_length=max_len)(inputs)\n",
        "\n",
        "x = Conv1D(256, 5, activation='relu')(em)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "x = LSTM(128)(x)\n",
        "# x = GlobalMaxPooling1D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(11, activation='softmax')(x)\n",
        "\n",
        "model4 = Model(inputs = inputs, outputs = outputs)\n",
        "model4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "12RVVEVpyIrQ"
      },
      "outputs": [],
      "source": [
        "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model4_path = 'best-cnn-bilstm-lstm.h5'\n",
        "mc4 = ModelCheckpoint(model4_path, verbose=1, save_best_only=True)\n",
        "es4 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vyCd042yLCx",
        "outputId": "6ae86157-d050-4548-dc2d-e303227fefa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 13:20:55.525586: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "238/238 [==============================] - ETA: 0s - loss: 2.7416 - accuracy: 0.2983\n",
            "Epoch 00001: val_loss improved from inf to 1.85062, saving model to best-cnn-bilstm-lstm.h5\n",
            "238/238 [==============================] - 9s 23ms/step - loss: 2.7416 - accuracy: 0.2983 - val_loss: 1.8506 - val_accuracy: 0.5569\n",
            "Epoch 2/30\n",
            "235/238 [============================>.] - ETA: 0s - loss: 2.0696 - accuracy: 0.5646\n",
            "Epoch 00002: val_loss improved from 1.85062 to 1.78418, saving model to best-cnn-bilstm-lstm.h5\n",
            "238/238 [==============================] - 5s 22ms/step - loss: 2.0704 - accuracy: 0.5643 - val_loss: 1.7842 - val_accuracy: 0.6232\n",
            "Epoch 3/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.9913 - accuracy: 0.6162\n",
            "Epoch 00003: val_loss did not improve from 1.78418\n",
            "238/238 [==============================] - 5s 21ms/step - loss: 1.9912 - accuracy: 0.6162 - val_loss: 2.2238 - val_accuracy: 0.5974\n",
            "Epoch 4/30\n",
            "235/238 [============================>.] - ETA: 0s - loss: 1.9978 - accuracy: 0.6421\n",
            "Epoch 00004: val_loss did not improve from 1.78418\n",
            "238/238 [==============================] - 5s 21ms/step - loss: 2.0002 - accuracy: 0.6418 - val_loss: 2.0798 - val_accuracy: 0.6278\n",
            "Epoch 5/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 1.9958 - accuracy: 0.6583\n",
            "Epoch 00005: val_loss did not improve from 1.78418\n",
            "238/238 [==============================] - 5s 20ms/step - loss: 1.9958 - accuracy: 0.6583 - val_loss: 2.2527 - val_accuracy: 0.6007\n",
            "Epoch 6/30\n",
            "235/238 [============================>.] - ETA: 0s - loss: 2.0084 - accuracy: 0.6671\n",
            "Epoch 00006: val_loss did not improve from 1.78418\n",
            "238/238 [==============================] - 5s 21ms/step - loss: 2.0101 - accuracy: 0.6671 - val_loss: 2.5819 - val_accuracy: 0.5912\n",
            "Epoch 7/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 2.0464 - accuracy: 0.6748\n",
            "Epoch 00007: val_loss did not improve from 1.78418\n",
            "238/238 [==============================] - 5s 21ms/step - loss: 2.0461 - accuracy: 0.6748 - val_loss: 2.6423 - val_accuracy: 0.5893\n"
          ]
        }
      ],
      "source": [
        "hist = model4.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc4, es4]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx2dRbD4yS7X",
        "outputId": "0f875d20-8b73-4d0f-bde9-e548d7a80a15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 2s 4ms/step - loss: 1.7813 - accuracy: 0.6265\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.7812714576721191, 0.6264501214027405]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model4 = load_model(model4_path)\n",
        "best_model4.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 74.05869960784912%의 확률로 분쟁유발에 대한 악플입니다.\n",
            "[1.6937053e-03 1.7733898e-04 1.7560368e-06 2.1665713e-03 2.4574753e-02\n",
            " 1.9106083e-02 1.6512607e-04 1.4516079e-02 1.9701159e-01 1.9014257e-09\n",
            " 7.4058700e-01]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model4,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Conv1D\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, None, 256)         9468672   \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, None, 64)          82176     \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 32)                12416     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 11)                363       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,563,627\n",
            "Trainable params: 9,563,627\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model10 = Sequential()\n",
        "model10.add(Embedding(vocab_size,256))\n",
        "model10.add(LSTM(64, return_sequences=True))\n",
        "model10.add(LSTM(32))\n",
        "model10.add(Dense(11,activation='softmax'))\n",
        "\n",
        "model10.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "model10.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model10_path = 'LSTM.h5'\n",
        "mc10 = ModelCheckpoint(model10_path, verbose=1, save_best_only=True)\n",
        "es10 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 2.4510 - accuracy: 0.3302\n",
            "Epoch 00001: val_loss improved from inf to 1.85775, saving model to LSTM.h5\n",
            "238/238 [==============================] - 4s 13ms/step - loss: 2.4510 - accuracy: 0.3302 - val_loss: 1.8577 - val_accuracy: 0.5895\n",
            "Epoch 2/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 1.6690 - accuracy: 0.6488\n",
            "Epoch 00002: val_loss improved from 1.85775 to 1.70981, saving model to LSTM.h5\n",
            "238/238 [==============================] - 3s 12ms/step - loss: 1.6690 - accuracy: 0.6488 - val_loss: 1.7098 - val_accuracy: 0.6475\n",
            "Epoch 3/30\n",
            "234/238 [============================>.] - ETA: 0s - loss: 1.4637 - accuracy: 0.7244\n",
            "Epoch 00003: val_loss improved from 1.70981 to 1.65779, saving model to LSTM.h5\n",
            "238/238 [==============================] - 3s 12ms/step - loss: 1.4631 - accuracy: 0.7244 - val_loss: 1.6578 - val_accuracy: 0.6804\n",
            "Epoch 4/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.3554 - accuracy: 0.7536\n",
            "Epoch 00004: val_loss did not improve from 1.65779\n",
            "238/238 [==============================] - 2s 10ms/step - loss: 1.3552 - accuracy: 0.7537 - val_loss: 1.7480 - val_accuracy: 0.6695\n",
            "Epoch 5/30\n",
            "235/238 [============================>.] - ETA: 0s - loss: 1.2563 - accuracy: 0.7760\n",
            "Epoch 00005: val_loss did not improve from 1.65779\n",
            "238/238 [==============================] - 2s 10ms/step - loss: 1.2592 - accuracy: 0.7757 - val_loss: 1.8310 - val_accuracy: 0.6579\n",
            "Epoch 6/30\n",
            "236/238 [============================>.] - ETA: 0s - loss: 1.2099 - accuracy: 0.7937\n",
            "Epoch 00006: val_loss did not improve from 1.65779\n",
            "238/238 [==============================] - 3s 11ms/step - loss: 1.2111 - accuracy: 0.7935 - val_loss: 1.8973 - val_accuracy: 0.6790\n",
            "Epoch 7/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 1.1847 - accuracy: 0.8067\n",
            "Epoch 00007: val_loss did not improve from 1.65779\n",
            "238/238 [==============================] - 3s 11ms/step - loss: 1.1847 - accuracy: 0.8067 - val_loss: 2.0236 - val_accuracy: 0.6608\n",
            "Epoch 8/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.1665 - accuracy: 0.8069\n",
            "Epoch 00008: val_loss did not improve from 1.65779\n",
            "238/238 [==============================] - 2s 10ms/step - loss: 1.1663 - accuracy: 0.8070 - val_loss: 2.2136 - val_accuracy: 0.6512\n"
          ]
        }
      ],
      "source": [
        "hist10 = model10.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc10, es10]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 1s 3ms/step - loss: 1.6846 - accuracy: 0.6723\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.684566855430603, 0.6723265051841736]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model10 = load_model(model10_path)\n",
        "best_model10.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 71.69331312179565%의 확률로 분쟁유발에 대한 악플입니다.\n",
            "[9.2642097e-04 4.3856245e-04 2.7882159e-05 4.3939073e-03 1.8608904e-02\n",
            " 6.4900190e-02 5.7229603e-04 2.2416074e-02 1.7078160e-01 1.0642806e-06\n",
            " 7.1693313e-01]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model10,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conv1D + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 70, 512)           18937344  \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 68, 32)            49184     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 34, 32)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 32, 32)            3104      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                8320      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 11)                363       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,998,315\n",
            "Trainable params: 18,998,315\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 17:10:25.529730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-15 17:10:25.534144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-15 17:10:25.534272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-15 17:10:25.534688: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-06-15 17:10:25.534980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-15 17:10:25.535072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-15 17:10:25.535123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-15 17:10:25.880660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-15 17:10:25.880791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-15 17:10:25.880856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-15 17:10:25.880923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9443 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "\n",
        "model6 = Sequential()\n",
        "model6.add(Embedding(vocab_size, 512, input_length=max_len))\n",
        "model6.add(Conv1D(32, 3, activation = 'relu'))\n",
        "model6.add(MaxPooling1D(2))\n",
        "model6.add(Conv1D(32, 3, activation = 'relu'))\n",
        "model6.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
        "model6.add(Dense(11,activation='softmax'))\n",
        "\n",
        "model6.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "model6.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model6_path = 'Conv1D_LSTM.h5'\n",
        "mc6 = ModelCheckpoint(model6_path, verbose=1, save_best_only=True)\n",
        "es6 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 2.4796 - accuracy: 0.3162\n",
            "Epoch 00001: val_loss improved from inf to 1.89077, saving model to Conv1D_LSTM.h5\n",
            "238/238 [==============================] - 13s 50ms/step - loss: 2.4796 - accuracy: 0.3162 - val_loss: 1.8908 - val_accuracy: 0.5602\n",
            "Epoch 2/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.6110 - accuracy: 0.6581\n",
            "Epoch 00002: val_loss improved from 1.89077 to 1.59015, saving model to Conv1D_LSTM.h5\n",
            "238/238 [==============================] - 12s 50ms/step - loss: 1.6113 - accuracy: 0.6581 - val_loss: 1.5902 - val_accuracy: 0.6798\n",
            "Epoch 3/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 1.3471 - accuracy: 0.7496\n",
            "Epoch 00003: val_loss did not improve from 1.59015\n",
            "238/238 [==============================] - 11s 47ms/step - loss: 1.3471 - accuracy: 0.7496 - val_loss: 1.5990 - val_accuracy: 0.7018\n",
            "Epoch 4/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.2303 - accuracy: 0.7854\n",
            "Epoch 00004: val_loss did not improve from 1.59015\n",
            "238/238 [==============================] - 11s 46ms/step - loss: 1.2301 - accuracy: 0.7854 - val_loss: 1.7036 - val_accuracy: 0.6947\n",
            "Epoch 5/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.1652 - accuracy: 0.8016\n",
            "Epoch 00005: val_loss did not improve from 1.59015\n",
            "238/238 [==============================] - 11s 47ms/step - loss: 1.1657 - accuracy: 0.8015 - val_loss: 1.9318 - val_accuracy: 0.6700\n",
            "Epoch 6/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 1.1372 - accuracy: 0.8163\n",
            "Epoch 00006: val_loss did not improve from 1.59015\n",
            "238/238 [==============================] - 11s 45ms/step - loss: 1.1372 - accuracy: 0.8163 - val_loss: 2.0269 - val_accuracy: 0.6854\n",
            "Epoch 7/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 1.1279 - accuracy: 0.8274\n",
            "Epoch 00007: val_loss did not improve from 1.59015\n",
            "238/238 [==============================] - 11s 46ms/step - loss: 1.1279 - accuracy: 0.8274 - val_loss: 2.0843 - val_accuracy: 0.6911\n"
          ]
        }
      ],
      "source": [
        "hist6 = model6.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc6, es6]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 2s 6ms/step - loss: 1.5731 - accuracy: 0.6770\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.5730806589126587, 0.6769669055938721]"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model6 = load_model(model6_path)\n",
        "best_model6.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 79.82271909713745%의 확률로 분쟁유발에 대한 악플입니다.\n",
            "[2.6514418e-03 1.0753199e-02 5.2382902e-04 4.7517363e-03 2.5320426e-04\n",
            " 8.5379466e-02 1.3521438e-03 1.4312087e-02 8.1774481e-02 2.1191274e-05\n",
            " 7.9822719e-01]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model6,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conv1D + BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 70, 512)           18937344  \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 68, 32)            49184     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 34, 32)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 32, 32)            3104      \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 32, 64)           16640     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 11)                715       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,006,987\n",
            "Trainable params: 19,006,987\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "\n",
        "model7 = Sequential()\n",
        "model7.add(Embedding(vocab_size, 512, input_length=max_len))\n",
        "model7.add(Conv1D(32, 3, activation = 'relu'))\n",
        "model7.add(MaxPooling1D(2))\n",
        "model7.add(Conv1D(32, 3, activation = 'relu'))\n",
        "model7.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model7.add(GlobalMaxPooling1D())\n",
        "model7.add(Dense(11,activation='softmax'))\n",
        "\n",
        "model7.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "model7.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
        "model7_path = 'Conv1D_BiLSTM.h5'\n",
        "mc7 = ModelCheckpoint(model7_path, verbose=1, save_best_only=True)\n",
        "es7 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "474/475 [============================>.] - ETA: 0s - loss: 2.4221 - accuracy: 0.3026\n",
            "Epoch 00001: val_loss improved from inf to 2.02339, saving model to Conv1D_BiLSTM.h5\n",
            "475/475 [==============================] - 9s 16ms/step - loss: 2.4221 - accuracy: 0.3026 - val_loss: 2.0234 - val_accuracy: 0.4773\n",
            "Epoch 2/100\n",
            "474/475 [============================>.] - ETA: 0s - loss: 1.8754 - accuracy: 0.6091\n",
            "Epoch 00002: val_loss improved from 2.02339 to 1.89843, saving model to Conv1D_BiLSTM.h5\n",
            "475/475 [==============================] - 8s 16ms/step - loss: 1.8758 - accuracy: 0.6091 - val_loss: 1.8984 - val_accuracy: 0.6302\n",
            "Epoch 3/100\n",
            "474/475 [============================>.] - ETA: 0s - loss: 1.6672 - accuracy: 0.7131\n",
            "Epoch 00003: val_loss did not improve from 1.89843\n",
            "475/475 [==============================] - 7s 15ms/step - loss: 1.6671 - accuracy: 0.7131 - val_loss: 1.9269 - val_accuracy: 0.6653\n",
            "Epoch 4/100\n",
            "472/475 [============================>.] - ETA: 0s - loss: 1.5893 - accuracy: 0.7497\n",
            "Epoch 00004: val_loss did not improve from 1.89843\n",
            "475/475 [==============================] - 7s 15ms/step - loss: 1.5890 - accuracy: 0.7498 - val_loss: 2.0439 - val_accuracy: 0.6541\n",
            "Epoch 5/100\n",
            "473/475 [============================>.] - ETA: 0s - loss: 1.5696 - accuracy: 0.7662\n",
            "Epoch 00005: val_loss did not improve from 1.89843\n",
            "475/475 [==============================] - 7s 15ms/step - loss: 1.5696 - accuracy: 0.7661 - val_loss: 2.1462 - val_accuracy: 0.6740\n",
            "Epoch 6/100\n",
            "473/475 [============================>.] - ETA: 0s - loss: 1.5608 - accuracy: 0.7758\n",
            "Epoch 00006: val_loss did not improve from 1.89843\n",
            "475/475 [==============================] - 7s 15ms/step - loss: 1.5619 - accuracy: 0.7755 - val_loss: 2.5758 - val_accuracy: 0.6476\n",
            "Epoch 7/100\n",
            "474/475 [============================>.] - ETA: 0s - loss: 1.5818 - accuracy: 0.7822\n",
            "Epoch 00007: val_loss did not improve from 1.89843\n",
            "475/475 [==============================] - 7s 15ms/step - loss: 1.5816 - accuracy: 0.7822 - val_loss: 2.7685 - val_accuracy: 0.6401\n"
          ]
        }
      ],
      "source": [
        "hist7 = model7.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=100, batch_size=64, callbacks=[mc7, es7]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 1s 3ms/step - loss: 1.8742 - accuracy: 0.6297\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.8741521835327148, 0.6297194957733154]"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model7 = load_model(model7_path)\n",
        "best_model7.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c105059d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c105059d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 71.50145769119263%의 확률로 분쟁유발에 대한 악플입니다.\n",
            "[1.1188831e-02 4.8013989e-04 4.1934536e-06 6.7986222e-04 1.1881140e-01\n",
            " 4.0029157e-03 4.0260304e-04 8.7737096e-03 1.4064173e-01 7.4602056e-08\n",
            " 7.1501458e-01]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model7,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_30 (Embedding)    (None, 70, 512)           18937344  \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (None, 128)               246528    \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 11)                1419      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,185,291\n",
            "Trainable params: 19,185,291\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "\n",
        "model8 = Sequential()\n",
        "\n",
        "model8.add(Embedding(vocab_size, 512, input_length=max_len))\n",
        "model8.add(GRU(128))\n",
        "model8.add(Dense(11, activation='softmax'))\n",
        "\n",
        "model8.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "model8.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
        "model8_path = 'GRU.h5'\n",
        "mc8 = ModelCheckpoint(model8_path, verbose=1, save_best_only=True)\n",
        "es8 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "946/949 [============================>.] - ETA: 0s - loss: 2.2641 - accuracy: 0.4172\n",
            "Epoch 00001: val_loss improved from inf to 1.74823, saving model to GRU.h5\n",
            "949/949 [==============================] - 15s 15ms/step - loss: 2.2637 - accuracy: 0.4176 - val_loss: 1.7482 - val_accuracy: 0.6276\n",
            "Epoch 2/30\n",
            "947/949 [============================>.] - ETA: 0s - loss: 1.6733 - accuracy: 0.6517\n",
            "Epoch 00002: val_loss improved from 1.74823 to 1.71116, saving model to GRU.h5\n",
            "949/949 [==============================] - 13s 14ms/step - loss: 1.6735 - accuracy: 0.6516 - val_loss: 1.7112 - val_accuracy: 0.6537\n",
            "Epoch 3/30\n",
            "946/949 [============================>.] - ETA: 0s - loss: 1.6734 - accuracy: 0.6870\n",
            "Epoch 00003: val_loss did not improve from 1.71116\n",
            "949/949 [==============================] - 13s 13ms/step - loss: 1.6734 - accuracy: 0.6870 - val_loss: 1.9645 - val_accuracy: 0.6501\n",
            "Epoch 4/30\n",
            "949/949 [==============================] - ETA: 0s - loss: 1.7296 - accuracy: 0.7106\n",
            "Epoch 00004: val_loss did not improve from 1.71116\n",
            "949/949 [==============================] - 13s 14ms/step - loss: 1.7296 - accuracy: 0.7106 - val_loss: 2.3732 - val_accuracy: 0.6314\n",
            "Epoch 5/30\n",
            "949/949 [==============================] - ETA: 0s - loss: 1.8200 - accuracy: 0.7373\n",
            "Epoch 00005: val_loss did not improve from 1.71116\n",
            "949/949 [==============================] - 13s 14ms/step - loss: 1.8200 - accuracy: 0.7373 - val_loss: 2.8174 - val_accuracy: 0.6443\n",
            "Epoch 6/30\n",
            "946/949 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.7493\n",
            "Epoch 00006: val_loss did not improve from 1.71116\n",
            "949/949 [==============================] - 13s 14ms/step - loss: 1.9457 - accuracy: 0.7494 - val_loss: 3.2119 - val_accuracy: 0.6374\n",
            "Epoch 7/30\n",
            "948/949 [============================>.] - ETA: 0s - loss: 2.0702 - accuracy: 0.7550\n",
            "Epoch 00007: val_loss did not improve from 1.71116\n",
            "949/949 [==============================] - 13s 13ms/step - loss: 2.0699 - accuracy: 0.7550 - val_loss: 3.6599 - val_accuracy: 0.6430\n"
          ]
        }
      ],
      "source": [
        "hist8 = model8.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=32, callbacks=[mc8, es8]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 1s 3ms/step - loss: 1.7077 - accuracy: 0.6493\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.7077429294586182, 0.6493355631828308]"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model8 = load_model(model8_path)\n",
        "best_model8.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = smile_train.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\\n{score[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ'\n",
            " 87.47551441192627%의 확률로 분쟁유발에 대한 악플입니다.\n",
            "[6.29698741e-04 1.57084403e-04 6.16414468e-07 9.50239692e-03\n",
            " 1.49178095e-02 4.33272729e-03 1.20026169e-04 9.65251180e-04\n",
            " 9.46192592e-02 7.63067554e-10 8.74755144e-01]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('종북좌파 빨갱이 새끼들이 하는 짓이 그렇지 뭐 ㅋㅋ', best_model8,tokenizer=t, max_len=max_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 70, 512)           18937344  \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 66, 32)            81952     \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 32)                6336      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 11)                363       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,025,995\n",
            "Trainable params: 19,025,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "\n",
        "model9 = Sequential()\n",
        "\n",
        "model9.add(Embedding(vocab_size, 512, input_length=max_len))\n",
        "model9.add(Conv1D(32, 5, activation = 'relu'))\n",
        "model9.add(GRU(32))\n",
        "model9.add(Dense(11, activation='softmax'))\n",
        "\n",
        "model9.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "model9.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
        "model9_path = 'Conv1D_GRU.h5'\n",
        "mc9 = ModelCheckpoint(model9_path, verbose=1, save_best_only=True)\n",
        "es9 = EarlyStopping(patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 15:46:26.096657: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8101\n",
            "2022-06-15 15:46:26.563361: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2022-06-15 15:46:27.108480: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "475/475 [==============================] - ETA: 0s - loss: 1.9835 - accuracy: 0.4960\n",
            "Epoch 00001: val_loss improved from inf to 1.45646, saving model to Conv1D_GRU.h5\n",
            "475/475 [==============================] - 10s 15ms/step - loss: 1.9835 - accuracy: 0.4960 - val_loss: 1.4565 - val_accuracy: 0.6879\n",
            "Epoch 2/100\n",
            "473/475 [============================>.] - ETA: 0s - loss: 1.3105 - accuracy: 0.7262\n",
            "Epoch 00002: val_loss did not improve from 1.45646\n",
            "475/475 [==============================] - 6s 13ms/step - loss: 1.3108 - accuracy: 0.7261 - val_loss: 1.4843 - val_accuracy: 0.6893\n",
            "Epoch 3/100\n",
            "473/475 [============================>.] - ETA: 0s - loss: 1.1855 - accuracy: 0.7693\n",
            "Epoch 00003: val_loss did not improve from 1.45646\n",
            "475/475 [==============================] - 6s 13ms/step - loss: 1.1857 - accuracy: 0.7693 - val_loss: 1.7132 - val_accuracy: 0.6824\n",
            "Epoch 4/100\n",
            "472/475 [============================>.] - ETA: 0s - loss: 1.1489 - accuracy: 0.7939\n",
            "Epoch 00004: val_loss did not improve from 1.45646\n",
            "475/475 [==============================] - 6s 13ms/step - loss: 1.1493 - accuracy: 0.7939 - val_loss: 1.9518 - val_accuracy: 0.6817\n",
            "Epoch 5/100\n",
            "473/475 [============================>.] - ETA: 0s - loss: 1.1602 - accuracy: 0.8081\n",
            "Epoch 00005: val_loss did not improve from 1.45646\n",
            "475/475 [==============================] - 7s 14ms/step - loss: 1.1605 - accuracy: 0.8080 - val_loss: 2.2650 - val_accuracy: 0.6603\n",
            "Epoch 6/100\n",
            "473/475 [============================>.] - ETA: 0s - loss: 1.1914 - accuracy: 0.8142\n",
            "Epoch 00006: val_loss did not improve from 1.45646\n",
            "475/475 [==============================] - 7s 14ms/step - loss: 1.1914 - accuracy: 0.8142 - val_loss: 2.4461 - val_accuracy: 0.6722\n"
          ]
        }
      ],
      "source": [
        "hist9 = model9.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=100, batch_size=64, callbacks=[mc9, es9]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 1s 3ms/step - loss: 1.4381 - accuracy: 0.6884\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1.4380638599395752, 0.688356876373291)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model9 = load_model(model9_path)\n",
        "loss9, acc9 = best_model9.evaluate(X_test, Y_test)\n",
        "loss9, acc9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'안녕 개새끼들아'\n",
            " 39.093783497810364%의 확률로 악플/욕설에 대한 악플입니다.\n",
            "[0.01603041 0.01596536 0.1322199  0.06223116 0.01985264 0.01034814\n",
            " 0.0550108  0.0062829  0.39093783 0.2863286  0.00479228]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_predict('안녕 개새끼들아', best_model9,tokenizer=t, max_len=max_len))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPH2KlEDOQngwJKJeWZb7mV",
      "collapsed_sections": [],
      "name": "악플 다중 분류기.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kdig",
      "language": "python",
      "name": "kdig"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "2331b4e723e7fb95574426231c2e7dc69a881cc0353adc5d6ad18e8a0d6e58aa"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "022175175d014a6b9198a150c0809b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08516e149bcc44ceb00363d403370336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bee5d6df3c9484c9e3dc1cb7c2381b3",
              "IPY_MODEL_abd0ce1e092045e0886f38f7c9ac9aae",
              "IPY_MODEL_c57efda8f0b144cbb714d5cb9a75d61f"
            ],
            "layout": "IPY_MODEL_09ea2325e69744de9bdff94fb1a035bd"
          }
        },
        "09af3b0e7f9646319240a8fe7d55fceb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ea2325e69744de9bdff94fb1a035bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a19fed85ac44e0a0ff9d0d315a2437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1b3b5cf469d4724bee0b683d086bd6a",
              "IPY_MODEL_fa9cb9feb5a94822a034d7de70e532a4",
              "IPY_MODEL_9bb720b3ffca49dfbbf7daed4a38bd8f"
            ],
            "layout": "IPY_MODEL_e198174bd77b4f7f956ea3400c2ec411"
          }
        },
        "1b256fdaa85c4a43b5ffd51e24a2ef26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bee5d6df3c9484c9e3dc1cb7c2381b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09af3b0e7f9646319240a8fe7d55fceb",
            "placeholder": "​",
            "style": "IPY_MODEL_a1112dda635c4a0d8efeae4269238341",
            "value": "100%"
          }
        },
        "46568df230764cf6bdf54f04cd4018ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52111a848d5f457bae141141c13789a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5cec716bca435e83751a7d4a4f7148": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7effcfa595ab453c931f6ac6d6331949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b6a160a24d54b17aff0db8b4e2badf3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e5fdd00a9e042119747510e31e4ed6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bb720b3ffca49dfbbf7daed4a38bd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c5cec716bca435e83751a7d4a4f7148",
            "placeholder": "​",
            "style": "IPY_MODEL_1b256fdaa85c4a43b5ffd51e24a2ef26",
            "value": " 47407/47407 [00:08&lt;00:00, 9126.68it/s]"
          }
        },
        "a1112dda635c4a0d8efeae4269238341": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abd0ce1e092045e0886f38f7c9ac9aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b6a160a24d54b17aff0db8b4e2badf3",
            "max": 14690,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_022175175d014a6b9198a150c0809b43",
            "value": 14690
          }
        },
        "c1b3b5cf469d4724bee0b683d086bd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52111a848d5f457bae141141c13789a5",
            "placeholder": "​",
            "style": "IPY_MODEL_eea6b7fbd97042a5bb334412275fa376",
            "value": "100%"
          }
        },
        "c57efda8f0b144cbb714d5cb9a75d61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eedc65d4ea8547a5a40bf97fe7f15e4c",
            "placeholder": "​",
            "style": "IPY_MODEL_46568df230764cf6bdf54f04cd4018ac",
            "value": " 14690/14690 [00:02&lt;00:00, 8716.82it/s]"
          }
        },
        "e198174bd77b4f7f956ea3400c2ec411": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea6b7fbd97042a5bb334412275fa376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eedc65d4ea8547a5a40bf97fe7f15e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa9cb9feb5a94822a034d7de70e532a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e5fdd00a9e042119747510e31e4ed6f",
            "max": 47407,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7effcfa595ab453c931f6ac6d6331949",
            "value": 47407
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
