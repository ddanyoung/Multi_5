{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJumOSbc0_84"
      },
      "source": [
        "# 악플 분류기 - 다중분류\n",
        "- 데이터: https://github.com/smilegate-ai/korean_unsmile_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S766WUh3J_cb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GSgpe1q-Kf6W"
      },
      "outputs": [],
      "source": [
        "# 데이터 불러오기\n",
        "train_df = pd.read_csv(\"/content/unsmile_train_v1.0.tsv\",delimiter='\\t')\n",
        "test_df = pd.read_csv(\"/content/unsmile_valid_v1.0.tsv\", delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "FN35wYipfHTh",
        "outputId": "e9178c2a-9c6a-4ee7-db98-9582e840348b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15005, 12) (3737, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  문장  여성/가족  남성  성소수자  인종/국적  \\\n",
              "0                             일안하는 시간은 쉬고싶어서 그런게 아닐까      0   0     0      0   \n",
              "1  아동성범죄와 페도버는 기록바 끊어져 영원히 고통 받는다. 무슬림 50퍼 근친이다. ...      0   0     0      0   \n",
              "2  루나 솔로앨범 나왔을 때부터 머모 기운 있었음 ㅇㅇ Keep o  doin 진짜 띵...      0   0     0      0   \n",
              "\n",
              "   연령  지역  종교  기타 혐오  악플/욕설  clean  개인지칭  \n",
              "0   0   0   0      0      0      1     0  \n",
              "1   0   0   1      0      0      0     0  \n",
              "2   0   0   0      0      0      1     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13e03a92-cbdf-4c60-9e20-e3038da81dc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타 혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "      <th>개인지칭</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>일안하는 시간은 쉬고싶어서 그런게 아닐까</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>아동성범죄와 페도버는 기록바 끊어져 영원히 고통 받는다. 무슬림 50퍼 근친이다. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>루나 솔로앨범 나왔을 때부터 머모 기운 있었음 ㅇㅇ Keep o  doin 진짜 띵...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13e03a92-cbdf-4c60-9e20-e3038da81dc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13e03a92-cbdf-4c60-9e20-e3038da81dc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13e03a92-cbdf-4c60-9e20-e3038da81dc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "print(train_df.shape, test_df.shape)\n",
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIEEzkynfSIK"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4GDel_AfVVV"
      },
      "source": [
        "- train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJud5W4lKigh",
        "outputId": "a88d2e7b-b6c2-4652-d5cb-0bc80df09f10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null 값 체크\n",
        "train_df.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hOekkV6Kl1P",
        "outputId": "66f0e08e-9d01-4fb3-b4ac-03f8a60d95e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15005, 12) 15004\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15004, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# 중복 데이터 확인\n",
        "print(train_df.shape, train_df.문장.nunique())\n",
        "\n",
        "# 중복 데이터 제거\n",
        "train_df.drop_duplicates(subset=['문장'], inplace=True)\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du4IN2Ir5XG5",
        "outputId": "73c5e410-95ce-4435-ee69-63d94f1cbab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Int64Index([5876, 11942], dtype='int64')\n"
          ]
        }
      ],
      "source": [
        "# 분류가 안되어 있는 데이터 확인\n",
        "print(train_df[train_df.sum(axis=1) == 0].index)\n",
        "\n",
        "# 분류 안되어 있는 데이터 삭제\n",
        "train_df = train_df[train_df.sum(axis=1) != 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv7w5Ra3fq5i"
      },
      "source": [
        "- test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdK75sSwfsuZ",
        "outputId": "777f458c-33e2-4549-8fff-37b2854afa23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null 값 체크\n",
        "test_df.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmit9Jsdfx0X",
        "outputId": "62649e6d-2439-4d0a-bf5f-f0e63945dafb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3737, 12), 3737)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ],
      "source": [
        "# 중복 데이터 확인\n",
        "test_df.shape, test_df.문장.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "zE28yhj_5ni9",
        "outputId": "7de334d2-0876-4e43-9cdf-775e0fb02aaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [문장, 여성/가족, 남성, 성소수자, 인종/국적, 연령, 지역, 종교, 기타 혐오, 악플/욕설, clean, 개인지칭]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65256672-e058-415d-82f2-d6e2ae41c36d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타 혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "      <th>개인지칭</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65256672-e058-415d-82f2-d6e2ae41c36d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65256672-e058-415d-82f2-d6e2ae41c36d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65256672-e058-415d-82f2-d6e2ae41c36d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "source": [
        "# 분류가 안되어 있는 데이터 확인\n",
        "test_df[test_df.sum(axis=1) == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB1t0SEP5zQm"
      },
      "source": [
        "## 텍스트 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3aEp41q54Dt"
      },
      "source": [
        "- train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOokoq_t516o",
        "outputId": "75805f06-6dc5-45c3-c8c5-9d889e5e1f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14978, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
        "train_df.문장 = train_df.문장.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ').str.strip()\n",
        "train_df.문장.replace('', np.nan, inplace=True)\n",
        "print(train_df.문장.isna().sum())\n",
        "train_df.dropna(how='any', inplace=True)\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVzaeNqt59MF"
      },
      "source": [
        "- test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkgUd2Vg58WZ",
        "outputId": "23a93324-bdaf-4d36-f86a-a522cbd2cab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3730, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
        "test_df.문장 = test_df.문장.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ').str.strip()\n",
        "test_df.문장.replace('', np.nan, inplace=True)\n",
        "print(test_df.문장.isna().sum())\n",
        "test_df.dropna(how='any', inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "test_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdHmL6byxeT3"
      },
      "source": [
        "- 데이터 분포"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDjX7UUhxb-q",
        "outputId": "209d1ba1-dffb-4ccf-bf17-44ee44b5ba0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "여성/가족    1599\n",
              "남성       1347\n",
              "성소수자     1140\n",
              "인종/국적    1727\n",
              "연령        603\n",
              "지역       1052\n",
              "종교       1181\n",
              "기타 혐오     569\n",
              "악플/욕설    3141\n",
              "clean    3718\n",
              "개인지칭      315\n",
              "dtype: object"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.sum()[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X8BEKpxx3AM",
        "outputId": "d3c1f619-b1c9-4018-f7b5-7d0c8c69625e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "여성/가족    393\n",
              "남성       334\n",
              "성소수자     280\n",
              "인종/국적    426\n",
              "연령       146\n",
              "지역       260\n",
              "종교       290\n",
              "기타 혐오    134\n",
              "악플/욕설    785\n",
              "clean    930\n",
              "개인지칭      74\n",
              "dtype: object"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.sum()[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1VcQvHKklIY"
      },
      "source": [
        "## 악플 데이터만 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MCZTpWqqjGM6"
      },
      "outputs": [],
      "source": [
        "train_df = train_df[train_df['clean'] ==0]\n",
        "test_df = test_df[test_df['clean'] ==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AABOIa27jGM6"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.iloc[:, :10]\n",
        "test_df = test_df.iloc[:, :10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoQmnmWckpmq"
      },
      "source": [
        "- 이중 레이블 나누기\n",
        "- 레이블 열 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg1ive2nkpL9"
      },
      "outputs": [],
      "source": [
        "# 라벨링\n",
        "df = pd.concat([train_df['문장'], train_df.iloc[:, 1:] * range(1, 10)], axis=1)\n",
        "\n",
        "dataset_train = pd.DataFrame()\n",
        "for i in range(1, 10):\n",
        "  data = df.loc[df.iloc[:, i] > 0][['문장', df.columns[i]]]\n",
        "  data.columns = ['문장', '라벨']\n",
        "  dataset_train = pd.concat([dataset_train, data])\n",
        "  \n",
        "  dataset_train.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM54MQK4k6tl"
      },
      "source": [
        "- 오버 샘플링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHBdQxguktYZ"
      },
      "outputs": [],
      "source": [
        "x = dataset_train['문장'].values.reshape(-1, 1)\n",
        "y = dataset_train.iloc[:, 1:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daYECe4Ak90r"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "X_resampled, y_resampled = RandomOverSampler(random_state=0).fit_resample(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "QfCCyBM6k-3z",
        "outputId": "93c57bda-ae7b-46b1-fc04-2dc9e00b52ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "counter = Counter(y_resampled)\n",
        "plt.bar(counter.keys(), counter.values())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fmZEr0l1oEG"
      },
      "source": [
        "## 한글 형태소 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JSig7wwjeac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b132debc-97df-4219-faed-74e84bd848b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 9.03 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 495 kB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-06-10 08:36:26--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::3403:4be7, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=%2BeR3WEO2npPbHujRr99%2Ftg3n1is%3D&Expires=1654851771&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2022-06-10 08:36:26--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=%2BeR3WEO2npPbHujRr99%2Ftg3n1is%3D&Expires=1654851771&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.86.83\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.86.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  8.08MB/s    in 0.2s    \n",
            "\n",
            "2022-06-10 08:36:26 (8.08 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-06-10 08:38:09--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::22c0:3470, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=4PWlvU960MNSucPaJsz0E9L0tco%3D&Expires=1654851854&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2022-06-10 08:38:09--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=4PWlvU960MNSucPaJsz0E9L0tco%3D&Expires=1654851854&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.99.60\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.99.60|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  66.1MB/s    in 0.7s    \n",
            "\n",
            "2022-06-10 08:38:10 (66.1 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n",
            "문제를 해결해주신 combacsa님 감사합니다.\n"
          ]
        }
      ],
      "source": [
        "# Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEFvYMqc12vQ"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVKQQvnc1dw6"
      },
      "outputs": [],
      "source": [
        "mecab = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6c78e9985ce74a80b91ee88cdb1ea306",
            "c81183cb6a2142d1a009d73264ee88da",
            "e2af431ccd05417ea8fdfdafc56c8889",
            "72a9ae1c761642cf9512555a62c55389",
            "ef39627d7fb44d45936e426f27049cd9",
            "d4b9165854494d59859aeeeb822f930a",
            "553762c962d7431994097f49efe58df2",
            "0eb5b9ee324c47088ca8d66b56ccae58",
            "f2ad92551aee4e1e8b6661dc4c19f3cb",
            "492ac86a4d0343b883d5fa84ac7d5880",
            "a503f7730ec14edd9fb03524c09bd2fc"
          ]
        },
        "id": "d1a73tac2aaT",
        "outputId": "8131f757-438f-473f-a4c0-02f2a385987a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28269 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c78e9985ce74a80b91ee88cdb1ea306"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data = []\n",
        "for sentence in tqdm(X_resampled):\n",
        "  morphs = mecab.morphs(sentence[0])\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  train_data.append(tmp_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "611cddecd516470abbdbf9d6a9781eca",
            "b398155abd544262a59231b7d0351663",
            "177baabb726e4feb8378b091a439cb0e",
            "adf4976adf5840d7953c01c3fa926f13",
            "b29e00627b3746ba993f6831eed82184",
            "61c0235771cf45b4b28a59de60ab2ab9",
            "6382cf5cd703429e92ecaa8dd96d276e",
            "2d78a6acea384a8cba70a324824586c0",
            "59900c56414c40b0a313d29aa64f558f",
            "439fbf372c1744c49c7bd52010ede68a",
            "271f1bb0bbb7495189ec8121ec069ac8"
          ]
        },
        "id": "s_NJnMypOxY0",
        "outputId": "4bb0c665-47dd-412c-9be1-ac23b0f83f43"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2800 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "611cddecd516470abbdbf9d6a9781eca"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "test_data = []\n",
        "for sentence in tqdm(test_df.문장):\n",
        "  morphs = mecab.morphs(sentence)\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  test_data.append(tmp_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QETCaH3cTqzb"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG2k08NMhPpK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KeqSe5QPHlJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix6-ej1c26NR"
      },
      "outputs": [],
      "source": [
        "# 등장 빈도가 3 미만인 것의 갯수\n",
        "threshold = 3\n",
        "total_cnt = len(t.word_index)   # 단어의 수\n",
        "rare_cnt = 0                    # 등장 빈도가 threshold 보다 작은 단어의 갯수\n",
        "total_freq = 0                  # 훈련 데이터의 전체 단어의 빈도수의 합\n",
        "rare_freq = 0                   # 등장 빈도가 threshold 보다 작은 단어의 등장 빈도수의 합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc_Yniiu3LKN"
      },
      "outputs": [],
      "source": [
        "for key, value in t.word_counts.items():\n",
        "  total_freq += value\n",
        "  if value < threshold:\n",
        "    rare_cnt += 1\n",
        "    rare_freq += value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpRyvzQa3MbH",
        "outputId": "2ac56c3c-5a68-46d2-dbe2-8aa34f8f6e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 16999\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 5923\n",
            "단어 집합에서 희귀 단어의 비율: 34.843226072121894\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.5931996532973676\n"
          ]
        }
      ],
      "source": [
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print(f'등장 빈도가 {threshold - 1}번 이하인 희귀 단어의 수: {rare_cnt}')\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoo8rfzc3cCX",
        "outputId": "43cc682f-8e77-4b25-eaec-eeaf17bd89bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17001"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# 모든 단어 사용\n",
        "vocab_size = total_cnt + 2\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhbvjJoE3nae"
      },
      "outputs": [],
      "source": [
        "t = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "t.fit_on_texts(train_data)\n",
        "X_train = t.texts_to_sequences(train_data)\n",
        "X_test = t.texts_to_sequences(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJDeO7fUT9wK",
        "outputId": "0a8154e9-0ef7-440b-ee25-9864d98c49e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74, 18.202341787824118)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# 데이터의 최대/평균 길이\n",
        "max(len(s) for s in X_train), sum(map(len, X_train)) / len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYq1T83SUgWD"
      },
      "outputs": [],
      "source": [
        "# 악플 길이를 60으로 설정\n",
        "max_len = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK-Df341Uh8J",
        "outputId": "282c05ff-3d36-4a9f-86f5-c90deed0d7cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28269, 60), (2800, 60))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqsiqzEZh6Ck",
        "outputId": "29e2b3fa-36d0-41f2-ca42-32d0b729776f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28269, 9), (2800, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y_train = to_categorical(y_resampled)\n",
        "Y_train = np.delete(Y_train, 0, 1)\n",
        "Y_test = test_df.iloc[:, 1:].values\n",
        "Y_train.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln0RXe-liL9D"
      },
      "source": [
        "## 모델 정의/설정/학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFRq8MvYiLtM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D, Dropout, Concatenate\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmCT-WN4E6gf"
      },
      "source": [
        "## 셀프 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF8L16qOq-9p"
      },
      "source": [
        "### 멀티 헤드 어텐션\n",
        "- 트랜스포머 인코더의 첫번째 서브층"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1yPCxZtE8ak"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y131InpHE9ye"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads=8):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.embedding_dim = embedding_dim # d_model\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        assert embedding_dim % self.num_heads == 0\n",
        "\n",
        "        self.projection_dim = embedding_dim // num_heads\n",
        "        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
        "\n",
        "    def scaled_dot_product_attention(self, query, key, value):\n",
        "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        logits = matmul_qk / tf.math.sqrt(depth)\n",
        "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "        output = tf.matmul(attention_weights, value)\n",
        "        return output, attention_weights\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # (batch_size, seq_len, embedding_dim)\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "\n",
        "        # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        query = self.split_heads(query, batch_size)  \n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
        "        # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
        "\n",
        "        # (batch_size, seq_len, embedding_dim)\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
        "        outputs = self.dense(concat_attention)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdgKGc1lrVda"
      },
      "source": [
        "### 인코더 설계하기\n",
        "- 두번째 서브칭인 포지션 와이즈 피드 포워드 신경망 추가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaLUJacxE_En"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(embedding_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
        "             tf.keras.layers.Dense(embedding_dim),]\n",
        "        )\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs) # 첫번째 서브층 : 멀티 헤드 어텐션\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output) # Add & Norm\n",
        "        ffn_output = self.ffn(out1) # 두번째 서브층 : 포지션 와이즈 피드 포워드 신경망\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output) # Add & Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIRp1iN7rcmv"
      },
      "source": [
        "### 포지션 임베딩\n",
        "- 임베딩 층을 사용하되, 위치 벡터 학습하도록 임베딩 층의 첫번째 인자로 단어 집합의 크기가 아니라 문장의 최대 길이를 넣어줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUAfcMBFFA0h"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos_emb = tf.keras.layers.Embedding(max_len, embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        max_len = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMmiJDrjrsra"
      },
      "source": [
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNXdyb3CFDuW"
      },
      "outputs": [],
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcxgA6mrs3ty"
      },
      "source": [
        "### 모델 정의/학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIv4f5j0s6zT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6pxy9ytGOnQ"
      },
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAfl2tw5FbzJ",
        "outputId": "4f4fa214-7f01-4cb3-8d1c-6ee5ee0af23e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 60)]              0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 60, 32)           545952    \n",
            " g_14 (TokenAndPositionEmbed                                     \n",
            " ding)                                                           \n",
            "                                                                 \n",
            " transformer_block_14 (Trans  (None, 60, 32)           6464      \n",
            " formerBlock)                                                    \n",
            "                                                                 \n",
            " global_max_pooling1d_6 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 20)                660       \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 20)                0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 9)                 189       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 553,265\n",
            "Trainable params: 553,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = 32  # 각 단어의 임베딩 벡터의 차원\n",
        "num_heads = 2  # 어텐션 헤드의 수\n",
        "dff = 32  # 포지션 와이즈 피드 포워드 신경망의 은닉층의 크기\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(max_len,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
        "x = transformer_block(x)\n",
        "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "outputs = tf.keras.layers.Dense(9, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPlf-xQxFdpp",
        "outputId": "4ec96358-7f76-4fec-e1a8-66b4c4a7c6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "703/707 [============================>.] - ETA: 0s - loss: 1.5631 - accuracy: 0.4598\n",
            "Epoch 1: val_loss improved from inf to 2.05308, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 11s 13ms/step - loss: 1.5605 - accuracy: 0.4611 - val_loss: 2.0531 - val_accuracy: 0.3753\n",
            "Epoch 2/100\n",
            "704/707 [============================>.] - ETA: 0s - loss: 0.8093 - accuracy: 0.7567\n",
            "Epoch 2: val_loss improved from 2.05308 to 1.70508, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 8s 12ms/step - loss: 0.8085 - accuracy: 0.7569 - val_loss: 1.7051 - val_accuracy: 0.4367\n",
            "Epoch 3/100\n",
            "707/707 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.8247\n",
            "Epoch 3: val_loss improved from 1.70508 to 1.54638, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 9s 12ms/step - loss: 0.5802 - accuracy: 0.8247 - val_loss: 1.5464 - val_accuracy: 0.4823\n",
            "Epoch 4/100\n",
            "701/707 [============================>.] - ETA: 0s - loss: 0.4476 - accuracy: 0.8600\n",
            "Epoch 4: val_loss improved from 1.54638 to 1.18753, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 8s 12ms/step - loss: 0.4476 - accuracy: 0.8601 - val_loss: 1.1875 - val_accuracy: 0.5444\n",
            "Epoch 5/100\n",
            "704/707 [============================>.] - ETA: 0s - loss: 0.3719 - accuracy: 0.8796\n",
            "Epoch 5: val_loss improved from 1.18753 to 0.94601, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 8s 12ms/step - loss: 0.3717 - accuracy: 0.8796 - val_loss: 0.9460 - val_accuracy: 0.6599\n",
            "Epoch 6/100\n",
            "701/707 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.8890\n",
            "Epoch 6: val_loss improved from 0.94601 to 0.86791, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 9s 12ms/step - loss: 0.3245 - accuracy: 0.8890 - val_loss: 0.8679 - val_accuracy: 0.6650\n",
            "Epoch 7/100\n",
            "706/707 [============================>.] - ETA: 0s - loss: 0.2861 - accuracy: 0.8967\n",
            "Epoch 7: val_loss improved from 0.86791 to 0.78280, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 8s 12ms/step - loss: 0.2862 - accuracy: 0.8967 - val_loss: 0.7828 - val_accuracy: 0.7032\n",
            "Epoch 8/100\n",
            "704/707 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.9005\n",
            "Epoch 8: val_loss improved from 0.78280 to 0.65197, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 9s 12ms/step - loss: 0.2620 - accuracy: 0.9007 - val_loss: 0.6520 - val_accuracy: 0.7239\n",
            "Epoch 9/100\n",
            "703/707 [============================>.] - ETA: 0s - loss: 0.2474 - accuracy: 0.9035\n",
            "Epoch 9: val_loss did not improve from 0.65197\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.2472 - accuracy: 0.9035 - val_loss: 0.6718 - val_accuracy: 0.7053\n",
            "Epoch 10/100\n",
            "702/707 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.9076\n",
            "Epoch 10: val_loss did not improve from 0.65197\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.2336 - accuracy: 0.9077 - val_loss: 0.6978 - val_accuracy: 0.6986\n",
            "Epoch 11/100\n",
            "700/707 [============================>.] - ETA: 0s - loss: 0.2194 - accuracy: 0.9116\n",
            "Epoch 11: val_loss improved from 0.65197 to 0.56175, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 9s 13ms/step - loss: 0.2198 - accuracy: 0.9113 - val_loss: 0.5617 - val_accuracy: 0.7377\n",
            "Epoch 12/100\n",
            "700/707 [============================>.] - ETA: 0s - loss: 0.2152 - accuracy: 0.9096\n",
            "Epoch 12: val_loss improved from 0.56175 to 0.53852, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 9s 12ms/step - loss: 0.2151 - accuracy: 0.9096 - val_loss: 0.5385 - val_accuracy: 0.7218\n",
            "Epoch 13/100\n",
            "705/707 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.9141\n",
            "Epoch 13: val_loss did not improve from 0.53852\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.2029 - accuracy: 0.9142 - val_loss: 0.6186 - val_accuracy: 0.7230\n",
            "Epoch 14/100\n",
            "703/707 [============================>.] - ETA: 0s - loss: 0.1996 - accuracy: 0.9139\n",
            "Epoch 14: val_loss improved from 0.53852 to 0.48603, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 8s 12ms/step - loss: 0.1996 - accuracy: 0.9139 - val_loss: 0.4860 - val_accuracy: 0.7457\n",
            "Epoch 15/100\n",
            "707/707 [==============================] - ETA: 0s - loss: 0.1966 - accuracy: 0.9154\n",
            "Epoch 15: val_loss did not improve from 0.48603\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.1966 - accuracy: 0.9154 - val_loss: 0.5239 - val_accuracy: 0.7230\n",
            "Epoch 16/100\n",
            "700/707 [============================>.] - ETA: 0s - loss: 0.1926 - accuracy: 0.9167\n",
            "Epoch 16: val_loss improved from 0.48603 to 0.47783, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fee5af6f4d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 8s 12ms/step - loss: 0.1933 - accuracy: 0.9165 - val_loss: 0.4778 - val_accuracy: 0.7204\n",
            "Epoch 17/100\n",
            "707/707 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.9186\n",
            "Epoch 17: val_loss did not improve from 0.47783\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.1839 - accuracy: 0.9186 - val_loss: 0.5032 - val_accuracy: 0.7152\n",
            "Epoch 18/100\n",
            "705/707 [============================>.] - ETA: 0s - loss: 0.1855 - accuracy: 0.9155\n",
            "Epoch 18: val_loss did not improve from 0.47783\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.1854 - accuracy: 0.9155 - val_loss: 0.4881 - val_accuracy: 0.7152\n",
            "Epoch 19/100\n",
            "702/707 [============================>.] - ETA: 0s - loss: 0.1771 - accuracy: 0.9193\n",
            "Epoch 19: val_loss did not improve from 0.47783\n",
            "707/707 [==============================] - 6s 8ms/step - loss: 0.1773 - accuracy: 0.9192 - val_loss: 0.4998 - val_accuracy: 0.7211\n"
          ]
        }
      ],
      "source": [
        "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model_path = 'best-transforemr-attention.h5py'\n",
        "mc = ModelCheckpoint(model_path, verbose=1, save_best_only=True)\n",
        "es = EarlyStopping(patience=3)\n",
        "\n",
        "history = model.fit(X_train, Y_train, validation_split=0.2,\n",
        "                    batch_size=32, epochs=100, callbacks=[mc, es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e08LhEntJA5e",
        "outputId": "559958bc-8fed-44ba-c9d8-110b302f4d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 1s 4ms/step - loss: 2.2721 - accuracy: 0.6971\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.272127151489258, 0.6971428394317627]"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ],
      "source": [
        "best_model = load_model(model_path)\n",
        "best_model.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4cvmug0JJUF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = test_df.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5JrmwarFfCL",
        "outputId": "48b8364f-397a-4c25-b22c-efaff2985b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'근데 아프가니스탄은 이슬람권 국가중에서도 거의 막장수준이라    다른국가 히잡안쓰는애들도 꽤 많음'\n",
            " 62.24408149719238%의 확률로 인종/국적에 대한 악플입니다.\n",
            "None\n",
            "문장       근데 아프가니스탄은 이슬람권 국가중에서도 거의 막장수준이라    다른국가 히잡안쓰는...\n",
            "여성/가족                                                    0\n",
            "남성                                                       0\n",
            "성소수자                                                     0\n",
            "인종/국적                                                    1\n",
            "연령                                                       0\n",
            "지역                                                       0\n",
            "종교                                                       0\n",
            "기타 혐오                                                    0\n",
            "악플/욕설                                                    0\n",
            "Name: 1210, dtype: object\n"
          ]
        }
      ],
      "source": [
        "num=1210\n",
        "text = test_df['문장'][num]\n",
        "print(sentiment_predict(text, best_model,tokenizer=t, max_len=max_len))\n",
        "print(test_df.loc[num])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XazWfV3PaMsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "uz_S3jI-kCak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D, Dropout, Concatenate, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "tWnykSvVkD5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 128, input_length=max_len)(inputs)\n",
        "\n",
        "x_1 = Conv1D(64, 5, activation='relu')(em)\n",
        "X_1 = Dropout(0.5)(x_1)\n",
        "\n",
        "x_2 = Conv1D(32, 5, activation='relu')(em)\n",
        "x_2 = Dropout(0.5)(x_2)\n",
        "\n",
        "x = Concatenate()([x_1, x_2])\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "outputs = Dense(9, activation='sigmoid')(x)\n",
        "\n",
        "model1 = Model(inputs = inputs, outputs = outputs)\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS9kUzGykHsG",
        "outputId": "13f5f6c5-34bf-416b-a292-d05f8509b41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 60, 128)      2176128     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 56, 32)       20512       ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 56, 64)       41024       ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 56, 32)       0           ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 56, 96)       0           ['conv1d_2[0][0]',               \n",
            "                                                                  'dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 96)          0           ['concatenate_1[0][0]']          \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 32)           3104        ['global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 9)            297         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,241,065\n",
            "Trainable params: 2,241,065\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구조 그려보기\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "N6uKo-wzkJ29",
        "outputId": "da50e3f2-6456-4d9d-af8e-025942357d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1_path = 'best-cnn.h5'\n",
        "mc1 = ModelCheckpoint(model1_path, verbose=1, save_best_only=True)\n",
        "es1 = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "raRHW1pHkf1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model1.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc1, es1]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMheuRuak4-Y",
        "outputId": "4bc97ae7-f01b-4cdf-f7ac-935b4d57f1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 1.4381 - accuracy: 0.5367\n",
            "Epoch 1: val_loss improved from inf to 1.90616, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 39s 204ms/step - loss: 1.4381 - accuracy: 0.5367 - val_loss: 1.9062 - val_accuracy: 0.3284\n",
            "Epoch 2/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.5564 - accuracy: 0.8279\n",
            "Epoch 2: val_loss improved from 1.90616 to 1.43654, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 20s 112ms/step - loss: 0.5564 - accuracy: 0.8279 - val_loss: 1.4365 - val_accuracy: 0.4701\n",
            "Epoch 3/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.8769\n",
            "Epoch 3: val_loss improved from 1.43654 to 1.12274, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 20s 112ms/step - loss: 0.3673 - accuracy: 0.8769 - val_loss: 1.1227 - val_accuracy: 0.5952\n",
            "Epoch 4/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.8960\n",
            "Epoch 4: val_loss improved from 1.12274 to 0.96575, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 21s 117ms/step - loss: 0.2927 - accuracy: 0.8960 - val_loss: 0.9658 - val_accuracy: 0.6657\n",
            "Epoch 5/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.9048\n",
            "Epoch 5: val_loss improved from 0.96575 to 0.83904, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 20s 112ms/step - loss: 0.2562 - accuracy: 0.9048 - val_loss: 0.8390 - val_accuracy: 0.7022\n",
            "Epoch 6/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9070\n",
            "Epoch 6: val_loss did not improve from 0.83904\n",
            "177/177 [==============================] - 20s 111ms/step - loss: 0.2342 - accuracy: 0.9070 - val_loss: 0.8720 - val_accuracy: 0.6935\n",
            "Epoch 7/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9087\n",
            "Epoch 7: val_loss did not improve from 0.83904\n",
            "177/177 [==============================] - 20s 111ms/step - loss: 0.2199 - accuracy: 0.9087 - val_loss: 0.9386 - val_accuracy: 0.6809\n",
            "Epoch 8/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.2081 - accuracy: 0.9107\n",
            "Epoch 8: val_loss improved from 0.83904 to 0.75670, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 20s 111ms/step - loss: 0.2081 - accuracy: 0.9107 - val_loss: 0.7567 - val_accuracy: 0.7312\n",
            "Epoch 9/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9102\n",
            "Epoch 9: val_loss did not improve from 0.75670\n",
            "177/177 [==============================] - 20s 111ms/step - loss: 0.2019 - accuracy: 0.9102 - val_loss: 0.7655 - val_accuracy: 0.7248\n",
            "Epoch 10/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.9095\n",
            "Epoch 10: val_loss did not improve from 0.75670\n",
            "177/177 [==============================] - 20s 115ms/step - loss: 0.2011 - accuracy: 0.9095 - val_loss: 0.7840 - val_accuracy: 0.7053\n",
            "Epoch 11/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9118\n",
            "Epoch 11: val_loss improved from 0.75670 to 0.63121, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 20s 112ms/step - loss: 0.1932 - accuracy: 0.9118 - val_loss: 0.6312 - val_accuracy: 0.7437\n",
            "Epoch 12/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9130\n",
            "Epoch 12: val_loss did not improve from 0.63121\n",
            "177/177 [==============================] - 21s 120ms/step - loss: 0.1881 - accuracy: 0.9130 - val_loss: 0.6639 - val_accuracy: 0.7262\n",
            "Epoch 13/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9127\n",
            "Epoch 13: val_loss did not improve from 0.63121\n",
            "177/177 [==============================] - 21s 117ms/step - loss: 0.1877 - accuracy: 0.9127 - val_loss: 0.7377 - val_accuracy: 0.7094\n",
            "Epoch 14/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.9105\n",
            "Epoch 14: val_loss did not improve from 0.63121\n",
            "177/177 [==============================] - 19s 110ms/step - loss: 0.1853 - accuracy: 0.9105 - val_loss: 0.6550 - val_accuracy: 0.7259\n",
            "Epoch 15/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.9120\n",
            "Epoch 15: val_loss improved from 0.63121 to 0.56249, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 20s 111ms/step - loss: 0.1831 - accuracy: 0.9120 - val_loss: 0.5625 - val_accuracy: 0.7395\n",
            "Epoch 16/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9139\n",
            "Epoch 16: val_loss improved from 0.56249 to 0.53291, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 20s 111ms/step - loss: 0.1790 - accuracy: 0.9139 - val_loss: 0.5329 - val_accuracy: 0.7382\n",
            "Epoch 17/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9141\n",
            "Epoch 17: val_loss did not improve from 0.53291\n",
            "177/177 [==============================] - 19s 110ms/step - loss: 0.1764 - accuracy: 0.9141 - val_loss: 0.7133 - val_accuracy: 0.7023\n",
            "Epoch 18/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.9140\n",
            "Epoch 18: val_loss did not improve from 0.53291\n",
            "177/177 [==============================] - 20s 110ms/step - loss: 0.1773 - accuracy: 0.9140 - val_loss: 0.6012 - val_accuracy: 0.7285\n",
            "Epoch 19/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.9157\n",
            "Epoch 19: val_loss did not improve from 0.53291\n",
            "177/177 [==============================] - 20s 111ms/step - loss: 0.1730 - accuracy: 0.9157 - val_loss: 0.5999 - val_accuracy: 0.7259\n",
            "Epoch 20/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9168\n",
            "Epoch 20: val_loss did not improve from 0.53291\n",
            "177/177 [==============================] - 19s 110ms/step - loss: 0.1714 - accuracy: 0.9168 - val_loss: 0.6044 - val_accuracy: 0.7181\n",
            "Epoch 21/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.9149\n",
            "Epoch 21: val_loss improved from 0.53291 to 0.49930, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 20s 110ms/step - loss: 0.1706 - accuracy: 0.9149 - val_loss: 0.4993 - val_accuracy: 0.7499\n",
            "Epoch 22/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9173\n",
            "Epoch 22: val_loss did not improve from 0.49930\n",
            "177/177 [==============================] - 19s 109ms/step - loss: 0.1694 - accuracy: 0.9173 - val_loss: 0.6299 - val_accuracy: 0.7207\n",
            "Epoch 23/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.9150\n",
            "Epoch 23: val_loss did not improve from 0.49930\n",
            "177/177 [==============================] - 19s 109ms/step - loss: 0.1696 - accuracy: 0.9150 - val_loss: 0.6513 - val_accuracy: 0.7032\n",
            "Epoch 24/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9181\n",
            "Epoch 24: val_loss improved from 0.49930 to 0.45705, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 19s 110ms/step - loss: 0.1676 - accuracy: 0.9181 - val_loss: 0.4571 - val_accuracy: 0.7358\n",
            "Epoch 25/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.9164\n",
            "Epoch 25: val_loss did not improve from 0.45705\n",
            "177/177 [==============================] - 19s 110ms/step - loss: 0.1678 - accuracy: 0.9164 - val_loss: 0.4775 - val_accuracy: 0.7437\n",
            "Epoch 26/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.9170\n",
            "Epoch 26: val_loss did not improve from 0.45705\n",
            "177/177 [==============================] - 20s 110ms/step - loss: 0.1654 - accuracy: 0.9170 - val_loss: 0.5878 - val_accuracy: 0.7306\n",
            "Epoch 27/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1657 - accuracy: 0.9163\n",
            "Epoch 27: val_loss did not improve from 0.45705\n",
            "177/177 [==============================] - 20s 110ms/step - loss: 0.1657 - accuracy: 0.9163 - val_loss: 0.5177 - val_accuracy: 0.7269\n",
            "Epoch 28/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9164\n",
            "Epoch 28: val_loss did not improve from 0.45705\n",
            "177/177 [==============================] - 20s 111ms/step - loss: 0.1633 - accuracy: 0.9164 - val_loss: 0.4652 - val_accuracy: 0.7425\n",
            "Epoch 29/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.9176\n",
            "Epoch 29: val_loss improved from 0.45705 to 0.43141, saving model to best-cnn.h5\n",
            "177/177 [==============================] - 21s 117ms/step - loss: 0.1613 - accuracy: 0.9176 - val_loss: 0.4314 - val_accuracy: 0.7446\n",
            "Epoch 30/30\n",
            "177/177 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.9191\n",
            "Epoch 30: val_loss did not improve from 0.43141\n",
            "177/177 [==============================] - 20s 111ms/step - loss: 0.1600 - accuracy: 0.9191 - val_loss: 0.5414 - val_accuracy: 0.7207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model1 = load_model(model1_path)\n",
        "best_model1.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOUVS0Hjk9Xg",
        "outputId": "b949f20a-a44f-4359-eaee-1335fa68d99a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 1s 7ms/step - loss: 1.5304 - accuracy: 0.7182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.530423879623413, 0.7182142734527588]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# clean포함 다중분류"
      ],
      "metadata": {
        "id": "c8pZOQZG1uEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ],
      "metadata": {
        "id": "sJaF4efl2Nky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 개인지칭 라벨은 삭제\n",
        "train_df = train_df.iloc[:, :11]\n",
        "test_df = test_df.iloc[:, :11]\n",
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "id": "Ftmb5YSY1zKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b97b498-f4eb-47da-92fb-7351c8d84d1d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14978, 11), (3730, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 오버샘플링"
      ],
      "metadata": {
        "id": "lQEFyvTA2YHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨링\n",
        "df = pd.concat([train_df['문장'], train_df.iloc[:, 1:] * range(1, 11)], axis=1)\n",
        "\n",
        "dataset_train = pd.DataFrame()\n",
        "for i in range(1, 11):\n",
        "  data = df.loc[df.iloc[:, i] > 0][['문장', df.columns[i]]]\n",
        "  data.columns = ['문장', '라벨']\n",
        "  dataset_train = pd.concat([dataset_train, data])\n",
        "  \n",
        "  dataset_train.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Hr0rXckB2Pj2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = dataset_train['문장'].values.reshape(-1, 1)\n",
        "y = dataset_train.iloc[:, 1:].values"
      ],
      "metadata": {
        "id": "rTcHLISv2cDq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "X_resampled, y_resampled = RandomOverSampler(random_state=0).fit_resample(x, y)"
      ],
      "metadata": {
        "id": "x2JSwlZH2faT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "counter = Counter(y_resampled)\n",
        "plt.bar(counter.keys(), counter.values())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "pwNvdz6H2kxj",
        "outputId": "1f05907d-069e-430c-a32f-2c194a370e64"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 한글 형태소 분석"
      ],
      "metadata": {
        "id": "la4RfQG52srH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_bNh3Kypkb5",
        "outputId": "c94119f2-d434-4735-a7e9-9cb26dde6048"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 18.32 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-06-13 01:47:14--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::3403:4be7, 2406:da00:ff00::22c5:2ef4, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=yvXG0V9Zpjx%2Bl0Z3DI29l%2FQtDuk%3D&Expires=1655085820&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2022-06-13 01:47:15--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=yvXG0V9Zpjx%2Bl0Z3DI29l%2FQtDuk%3D&Expires=1655085820&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.199.17\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.199.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  1.06MB/s    in 1.3s    \n",
            "\n",
            "2022-06-13 01:47:17 (1.06 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-06-13 01:48:33--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22e9:9f55, 2406:da00:ff00::22c5:2ef4, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=xBdeB3fvTyJYwbbmdVyWdZIFbws%3D&Expires=1655085907&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2022-06-13 01:48:34--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=xBdeB3fvTyJYwbbmdVyWdZIFbws%3D&Expires=1655085907&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.145.3\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.145.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  11.1MB/s    in 4.9s    \n",
            "\n",
            "2022-06-13 01:48:39 (9.66 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n",
            "문제를 해결해주신 combacsa님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "W7tl2tV52nll"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mecab = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']"
      ],
      "metadata": {
        "id": "DEqyWVHH2uBk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "for sentence in tqdm(X_resampled):\n",
        "  morphs = mecab.morphs(sentence[0])\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  train_data.append(tmp_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a6cdfdcaae394c2db3b30bef56e458e1",
            "7b2d1889cdbb4c219eca0b906bd0400a",
            "6d5d899a923146aca89656488b61ed22",
            "7779bc0dfc754dc1abd35056481fe18c",
            "d172ab83da054fdfa176182fc0690e34",
            "edcfe7469ef1485ba24964ff85e2cea2",
            "4380fc0a257642aab4ff1ab0cb868ded",
            "64d937ca50b94fc0ae8d2b7164e4c72e",
            "3b29ac0bb05f4a4191f54b85b6d9bad1",
            "67280c232a144ae3953712088a874a51",
            "ba1cdb9c6176453c8a184d9f55b86f1a"
          ]
        },
        "id": "WoUzYpxr2wec",
        "outputId": "1056f132-755d-4331-ed59-93321c88dc3b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/37180 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6cdfdcaae394c2db3b30bef56e458e1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "for sentence in tqdm(test_df.문장):\n",
        "  morphs = mecab.morphs(sentence)\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  test_data.append(tmp_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "01f79b04317d494faafeddd1f3e7c191",
            "7ab7235f54414efc8fc751becf2b8848",
            "494ffcee707e4bfeb4a9182664474acc",
            "4584947ccff1404681354d163f96fb6a",
            "a6e7518c3933484f919693bef2bd1c51",
            "cab3ca7e007847c1aa3f5f79978ddb6c",
            "35f1a47d067d4e3ebd8104f386d36591",
            "0b45fe23218544cb90eb78fa640d0cde",
            "867842df4b7c4c20b02e1a023c4c66a0",
            "2bba77e709044811a8fb07251815317f",
            "b89e13be6c244f0cbaef99607c5f0b32"
          ]
        },
        "id": "NEMDfhax2y4t",
        "outputId": "57169c94-6796-4f5e-89dc-4bf469802779"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3730 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01f79b04317d494faafeddd1f3e7c191"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 토큰화"
      ],
      "metadata": {
        "id": "oSDHLfx_23yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(train_data)"
      ],
      "metadata": {
        "id": "mDLfvkhJ21Zi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 등장 빈도가 3 미만인 것의 갯수\n",
        "threshold = 3\n",
        "total_cnt = len(t.word_index)   # 단어의 수\n",
        "rare_cnt = 0                    # 등장 빈도가 threshold 보다 작은 단어의 갯수\n",
        "total_freq = 0                  # 훈련 데이터의 전체 단어의 빈도수의 합\n",
        "rare_freq = 0                   # 등장 빈도가 threshold 보다 작은 단어의 등장 빈도수의 합"
      ],
      "metadata": {
        "id": "6zemZvBH25R_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in t.word_counts.items():\n",
        "  total_freq += value\n",
        "  if value < threshold:\n",
        "    rare_cnt += 1\n",
        "    rare_freq += value"
      ],
      "metadata": {
        "id": "tymUdC_827Vd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print(f'등장 빈도가 {threshold - 1}번 이하인 희귀 단어의 수: {rare_cnt}')\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOX4bwnq29B-",
        "outputId": "146020db-b238-4890-9feb-b8b638a0abe2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 19677\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 7165\n",
            "단어 집합에서 희귀 단어의 비율: 36.41307109823652\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.4487064738927362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 단어 사용\n",
        "vocab_size = total_cnt + 2\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p44MscVa2_LV",
        "outputId": "43a2c80b-9f9b-4c21-9080-5eb2ea836434"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19679"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "t.fit_on_texts(train_data)\n",
        "X_train = t.texts_to_sequences(train_data)\n",
        "X_test = t.texts_to_sequences(test_data)"
      ],
      "metadata": {
        "id": "mbD8JytU3BGQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 악플 길이를 100으로 설정\n",
        "max_len = 100"
      ],
      "metadata": {
        "id": "qCA-JrNh3Djy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVf1cxTj3GaH",
        "outputId": "c5e1fc40-8a66-4837-d9b4-f679f73d14e6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37180, 100), (3730, 100))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y_train = to_categorical(y_resampled)\n",
        "Y_train = np.delete(Y_train, 0, 1)\n",
        "Y_test = test_df.iloc[:, 1:].values\n",
        "Y_train.shape, Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LISaIrJ3JBn",
        "outputId": "3113f1db-8fcf-4a32-f090-cac9603688cc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37180, 10), (3730, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 정의/설정/학습"
      ],
      "metadata": {
        "id": "W2hTJICy3MrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "n0ZN14U5ntgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D, Dropout, Concatenate, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "I6Z7o5ovntGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 128, input_length=max_len)(inputs)\n",
        "\n",
        "x_1 = Conv1D(64, 5, activation='relu')(em)\n",
        "X_1 = Dropout(0.5)(x_1)\n",
        "\n",
        "x_2 = Conv1D(32, 5, activation='relu')(em)\n",
        "x_2 = Dropout(0.5)(x_2)\n",
        "\n",
        "x = Concatenate()([x_1, x_2])\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model1 = Model(inputs = inputs, outputs = outputs)\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmkWlAoKnv16",
        "outputId": "37573f06-688a-4f30-e86c-0ca84e5a7505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 60, 128)      2518912     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 56, 32)       20512       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 56, 64)       41024       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 56, 32)       0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 56, 96)       0           ['conv1d[0][0]',                 \n",
            "                                                                  'dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 96)          0           ['concatenate[0][0]']            \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           3104        ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10)           330         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,583,882\n",
            "Trainable params: 2,583,882\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구조 그려보기\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model1)"
      ],
      "metadata": {
        "id": "OCprMff6n3mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1_path = 'best-cnn.h5'\n",
        "mc1 = ModelCheckpoint(model1_path, verbose=1, save_best_only=True)\n",
        "es1 = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "N2eByv_Un7vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model1.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc1, es1]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYAUFCJwoCJF",
        "outputId": "a186b021-8b22-4e83-b335-4894ea956038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 1.4142 - accuracy: 0.5435\n",
            "Epoch 1: val_loss improved from inf to 1.94120, saving model to best-cnn2.h5\n",
            "233/233 [==============================] - 47s 195ms/step - loss: 1.4142 - accuracy: 0.5435 - val_loss: 1.9412 - val_accuracy: 0.4016\n",
            "Epoch 2/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.6018 - accuracy: 0.8008\n",
            "Epoch 2: val_loss improved from 1.94120 to 1.37161, saving model to best-cnn2.h5\n",
            "233/233 [==============================] - 31s 135ms/step - loss: 0.6018 - accuracy: 0.8008 - val_loss: 1.3716 - val_accuracy: 0.5184\n",
            "Epoch 3/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.8679\n",
            "Epoch 3: val_loss improved from 1.37161 to 0.96531, saving model to best-cnn2.h5\n",
            "233/233 [==============================] - 31s 132ms/step - loss: 0.3918 - accuracy: 0.8679 - val_loss: 0.9653 - val_accuracy: 0.6768\n",
            "Epoch 4/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.9017\n",
            "Epoch 4: val_loss improved from 0.96531 to 0.80996, saving model to best-cnn2.h5\n",
            "233/233 [==============================] - 33s 141ms/step - loss: 0.2837 - accuracy: 0.9017 - val_loss: 0.8100 - val_accuracy: 0.7254\n",
            "Epoch 5/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9136\n",
            "Epoch 5: val_loss improved from 0.80996 to 0.66701, saving model to best-cnn2.h5\n",
            "233/233 [==============================] - 32s 136ms/step - loss: 0.2324 - accuracy: 0.9136 - val_loss: 0.6670 - val_accuracy: 0.7578\n",
            "Epoch 6/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.9184\n",
            "Epoch 6: val_loss improved from 0.66701 to 0.60508, saving model to best-cnn2.h5\n",
            "233/233 [==============================] - 30s 130ms/step - loss: 0.2035 - accuracy: 0.9184 - val_loss: 0.6051 - val_accuracy: 0.7829\n",
            "Epoch 7/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9224\n",
            "Epoch 7: val_loss did not improve from 0.60508\n",
            "233/233 [==============================] - 30s 129ms/step - loss: 0.1877 - accuracy: 0.9224 - val_loss: 0.6217 - val_accuracy: 0.7555\n",
            "Epoch 8/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9251\n",
            "Epoch 8: val_loss improved from 0.60508 to 0.48361, saving model to best-cnn2.h5\n",
            "233/233 [==============================] - 30s 130ms/step - loss: 0.1779 - accuracy: 0.9251 - val_loss: 0.4836 - val_accuracy: 0.8076\n",
            "Epoch 9/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.9241\n",
            "Epoch 9: val_loss improved from 0.48361 to 0.48139, saving model to best-cnn2.h5\n",
            "233/233 [==============================] - 31s 134ms/step - loss: 0.1735 - accuracy: 0.9241 - val_loss: 0.4814 - val_accuracy: 0.7754\n",
            "Epoch 10/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 0.9261\n",
            "Epoch 10: val_loss did not improve from 0.48139\n",
            "233/233 [==============================] - 31s 132ms/step - loss: 0.1668 - accuracy: 0.9261 - val_loss: 0.5391 - val_accuracy: 0.7698\n",
            "Epoch 11/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.9260\n",
            "Epoch 11: val_loss did not improve from 0.48139\n",
            "233/233 [==============================] - 31s 132ms/step - loss: 0.1632 - accuracy: 0.9260 - val_loss: 0.5280 - val_accuracy: 0.7559\n",
            "Epoch 12/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9274\n",
            "Epoch 12: val_loss did not improve from 0.48139\n",
            "233/233 [==============================] - 30s 129ms/step - loss: 0.1589 - accuracy: 0.9274 - val_loss: 0.5484 - val_accuracy: 0.7612\n",
            "Epoch 13/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.9268\n",
            "Epoch 13: val_loss did not improve from 0.48139\n",
            "233/233 [==============================] - 30s 128ms/step - loss: 0.1564 - accuracy: 0.9268 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
            "Epoch 14/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.9273\n",
            "Epoch 14: val_loss did not improve from 0.48139\n",
            "233/233 [==============================] - 31s 134ms/step - loss: 0.1538 - accuracy: 0.9273 - val_loss: 0.5546 - val_accuracy: 0.7499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model1 = load_model(model1_path)\n",
        "best_model1.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "id": "T9rTJ-oaoGQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b2bbe7-a012-4700-ed79-55ee4cdb0b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117/117 [==============================] - 1s 8ms/step - loss: 1.5055 - accuracy: 0.6378\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5054835081100464, 0.6378015875816345]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. BiLSTM\n",
        "- Embedding Layer\n",
        "- Bidirectional LSTM (Dropout: 10%)\n",
        "- 1-Dimension Global Max Pooling\n",
        "- 1-Dimension Fully Connected Layer\n",
        "- Softmax Activation"
      ],
      "metadata": {
        "id": "8uSuz54ltLcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "Cwh9TOc3tn_u"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 128, input_length=max_len)(inputs)\n",
        "\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(em)\n",
        "x = Dropout(0.1)(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model2 = Model(inputs = inputs, outputs = outputs)\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cPImq_etMU9",
        "outputId": "7e84c980-756b-4cd5-f5c1-da500be451f6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 100, 128)          2518912   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 100, 256)         263168    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 100, 256)          0         \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,784,650\n",
            "Trainable params: 2,784,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2_path = 'best-bilstm.h5'\n",
        "mc2 = ModelCheckpoint(model2_path, verbose=1, save_best_only=True)\n",
        "es2 = EarlyStopping(patience=3)"
      ],
      "metadata": {
        "id": "3FHrEwXkuK40"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model2.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc2, es2]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxww_49EuRC1",
        "outputId": "1e685a09-59bc-4c17-af90-99eb0e50f8a7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 1.4478 - accuracy: 0.5076\n",
            "Epoch 1: val_loss improved from inf to 2.08873, saving model to best-bilstm.h5\n",
            "233/233 [==============================] - 14s 35ms/step - loss: 1.4478 - accuracy: 0.5076 - val_loss: 2.0887 - val_accuracy: 0.3406\n",
            "Epoch 2/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.5953 - accuracy: 0.7964\n",
            "Epoch 2: val_loss improved from 2.08873 to 1.58532, saving model to best-bilstm.h5\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.5953 - accuracy: 0.7965 - val_loss: 1.5853 - val_accuracy: 0.4692\n",
            "Epoch 3/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.4065 - accuracy: 0.8592\n",
            "Epoch 3: val_loss improved from 1.58532 to 1.26158, saving model to best-bilstm.h5\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.4066 - accuracy: 0.8592 - val_loss: 1.2616 - val_accuracy: 0.5313\n",
            "Epoch 4/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.3114 - accuracy: 0.8883\n",
            "Epoch 4: val_loss improved from 1.26158 to 0.98421, saving model to best-bilstm.h5\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.3114 - accuracy: 0.8883 - val_loss: 0.9842 - val_accuracy: 0.6225\n",
            "Epoch 5/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9040\n",
            "Epoch 5: val_loss improved from 0.98421 to 0.83953, saving model to best-bilstm.h5\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.2550 - accuracy: 0.9038 - val_loss: 0.8395 - val_accuracy: 0.6783\n",
            "Epoch 6/30\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.2205 - accuracy: 0.9128\n",
            "Epoch 6: val_loss improved from 0.83953 to 0.65698, saving model to best-bilstm.h5\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.2204 - accuracy: 0.9128 - val_loss: 0.6570 - val_accuracy: 0.7321\n",
            "Epoch 7/30\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.1937 - accuracy: 0.9196\n",
            "Epoch 7: val_loss improved from 0.65698 to 0.56290, saving model to best-bilstm.h5\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.1935 - accuracy: 0.9198 - val_loss: 0.5629 - val_accuracy: 0.7509\n",
            "Epoch 8/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1850 - accuracy: 0.9215\n",
            "Epoch 8: val_loss did not improve from 0.56290\n",
            "233/233 [==============================] - 5s 21ms/step - loss: 0.1851 - accuracy: 0.9216 - val_loss: 0.7690 - val_accuracy: 0.7004\n",
            "Epoch 9/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1746 - accuracy: 0.9227\n",
            "Epoch 9: val_loss improved from 0.56290 to 0.53194, saving model to best-bilstm.h5\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.1746 - accuracy: 0.9227 - val_loss: 0.5319 - val_accuracy: 0.7340\n",
            "Epoch 10/30\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.1646 - accuracy: 0.9264\n",
            "Epoch 10: val_loss improved from 0.53194 to 0.42134, saving model to best-bilstm.h5\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.1646 - accuracy: 0.9264 - val_loss: 0.4213 - val_accuracy: 0.7710\n",
            "Epoch 11/30\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.1651 - accuracy: 0.9261\n",
            "Epoch 11: val_loss did not improve from 0.42134\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 0.1652 - accuracy: 0.9260 - val_loss: 0.5532 - val_accuracy: 0.7222\n",
            "Epoch 12/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1581 - accuracy: 0.9275\n",
            "Epoch 12: val_loss did not improve from 0.42134\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.1582 - accuracy: 0.9275 - val_loss: 0.4763 - val_accuracy: 0.7478\n",
            "Epoch 13/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9288\n",
            "Epoch 13: val_loss did not improve from 0.42134\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.1514 - accuracy: 0.9287 - val_loss: 0.4268 - val_accuracy: 0.7552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model2 = load_model(model2_path)\n",
        "best_model2.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw0dvbszur3g",
        "outputId": "87cd3c78-acdb-467d-defa-f99e5bcda5e1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117/117 [==============================] - 2s 8ms/step - loss: 1.6295 - accuracy: 0.6338\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.629464030265808, 0.6337801814079285]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM + LSTM\n",
        "- Embedding Layer\n",
        "- Bidirectional LSTM + Residual Connection from Embedding Layer\n",
        "- Forward LSTM\n",
        "- 1-Dimsension Global Max Pooling\n",
        "- 1-Dimension Fully Connected Layer (Dropout: 50%)"
      ],
      "metadata": {
        "id": "YybQPtDquhH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional, LayerNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "XxmnU9y_ugZa"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(100,))\n",
        "em = Embedding(30000, 256, input_length=100)(inputs)\n",
        "\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(em)\n",
        "x = LayerNormalization(epsilon=1e-6)(em + x)\n",
        "x = LSTM(128)(x)\n",
        "# x = GlobalMaxPooling1D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model3 = Model(inputs = inputs, outputs = outputs)\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "_xfYXxzTuWnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7a869c-2683-4951-eb88-a955faccecca"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 100, 256)     7680000     ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 100, 256)    394240      ['embedding_4[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 100, 256)    0           ['embedding_4[0][0]',            \n",
            " mbda)                                                            'bidirectional_2[0][0]']        \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 100, 256)    512         ['tf.__operators__.add_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 128)          197120      ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 128)          0           ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 10)           1290        ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,273,162\n",
            "Trainable params: 8,273,162\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3_path = 'best-bilstm-lstm.h5'\n",
        "mc3 = ModelCheckpoint(model3_path, verbose=1, save_best_only=True)\n",
        "es3 = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "crhW9_eX0KDc"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model3.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc3, es3]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SI-iaz30XpQ",
        "outputId": "d9b1d8e4-ca42-4f2a-b095-5f373fda495a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 1.1730 - accuracy: 0.6118\n",
            "Epoch 1: val_loss improved from inf to 1.74928, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 21s 55ms/step - loss: 1.1718 - accuracy: 0.6122 - val_loss: 1.7493 - val_accuracy: 0.4533\n",
            "Epoch 2/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.5053 - accuracy: 0.8325\n",
            "Epoch 2: val_loss improved from 1.74928 to 0.95798, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 11s 46ms/step - loss: 0.5053 - accuracy: 0.8325 - val_loss: 0.9580 - val_accuracy: 0.6649\n",
            "Epoch 3/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.8847\n",
            "Epoch 3: val_loss improved from 0.95798 to 0.83477, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.3335 - accuracy: 0.8847 - val_loss: 0.8348 - val_accuracy: 0.6930\n",
            "Epoch 4/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.2579 - accuracy: 0.9037\n",
            "Epoch 4: val_loss improved from 0.83477 to 0.60819, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 41ms/step - loss: 0.2576 - accuracy: 0.9038 - val_loss: 0.6082 - val_accuracy: 0.7421\n",
            "Epoch 5/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.9137\n",
            "Epoch 5: val_loss improved from 0.60819 to 0.59280, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.2230 - accuracy: 0.9137 - val_loss: 0.5928 - val_accuracy: 0.7406\n",
            "Epoch 6/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 0.9191\n",
            "Epoch 6: val_loss improved from 0.59280 to 0.54935, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.2010 - accuracy: 0.9191 - val_loss: 0.5494 - val_accuracy: 0.7391\n",
            "Epoch 7/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9236\n",
            "Epoch 7: val_loss improved from 0.54935 to 0.45844, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1861 - accuracy: 0.9236 - val_loss: 0.4584 - val_accuracy: 0.7652\n",
            "Epoch 8/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1795 - accuracy: 0.9217\n",
            "Epoch 8: val_loss improved from 0.45844 to 0.44278, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1795 - accuracy: 0.9217 - val_loss: 0.4428 - val_accuracy: 0.7601\n",
            "Epoch 9/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.9235\n",
            "Epoch 9: val_loss improved from 0.44278 to 0.43932, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1743 - accuracy: 0.9235 - val_loss: 0.4393 - val_accuracy: 0.7476\n",
            "Epoch 10/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9261\n",
            "Epoch 10: val_loss did not improve from 0.43932\n",
            "233/233 [==============================] - 9s 39ms/step - loss: 0.1663 - accuracy: 0.9261 - val_loss: 0.4741 - val_accuracy: 0.7405\n",
            "Epoch 11/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.9272\n",
            "Epoch 11: val_loss did not improve from 0.43932\n",
            "233/233 [==============================] - 10s 41ms/step - loss: 0.1632 - accuracy: 0.9272 - val_loss: 0.5024 - val_accuracy: 0.7266\n",
            "Epoch 12/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9240\n",
            "Epoch 12: val_loss improved from 0.43932 to 0.43884, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1675 - accuracy: 0.9240 - val_loss: 0.4388 - val_accuracy: 0.7426\n",
            "Epoch 13/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9258\n",
            "Epoch 13: val_loss did not improve from 0.43884\n",
            "233/233 [==============================] - 10s 45ms/step - loss: 0.1615 - accuracy: 0.9258 - val_loss: 0.4590 - val_accuracy: 0.7324\n",
            "Epoch 14/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9290\n",
            "Epoch 14: val_loss did not improve from 0.43884\n",
            "233/233 [==============================] - 9s 39ms/step - loss: 0.1535 - accuracy: 0.9290 - val_loss: 0.4392 - val_accuracy: 0.7445\n",
            "Epoch 15/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9290\n",
            "Epoch 15: val_loss improved from 0.43884 to 0.43783, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1525 - accuracy: 0.9290 - val_loss: 0.4378 - val_accuracy: 0.7345\n",
            "Epoch 16/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.9298\n",
            "Epoch 16: val_loss did not improve from 0.43783\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1512 - accuracy: 0.9298 - val_loss: 0.4412 - val_accuracy: 0.7462\n",
            "Epoch 17/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.9289\n",
            "Epoch 17: val_loss did not improve from 0.43783\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.1521 - accuracy: 0.9289 - val_loss: 0.4488 - val_accuracy: 0.7282\n",
            "Epoch 18/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1483 - accuracy: 0.9310\n",
            "Epoch 18: val_loss improved from 0.43783 to 0.43074, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 9s 41ms/step - loss: 0.1483 - accuracy: 0.9310 - val_loss: 0.4307 - val_accuracy: 0.7419\n",
            "Epoch 19/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9290\n",
            "Epoch 19: val_loss did not improve from 0.43074\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1484 - accuracy: 0.9291 - val_loss: 0.4524 - val_accuracy: 0.7322\n",
            "Epoch 20/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1453 - accuracy: 0.9294\n",
            "Epoch 20: val_loss improved from 0.43074 to 0.40384, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.1452 - accuracy: 0.9295 - val_loss: 0.4038 - val_accuracy: 0.7297\n",
            "Epoch 21/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9332\n",
            "Epoch 21: val_loss did not improve from 0.40384\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.1393 - accuracy: 0.9332 - val_loss: 0.4302 - val_accuracy: 0.7283\n",
            "Epoch 22/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9331\n",
            "Epoch 22: val_loss did not improve from 0.40384\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1405 - accuracy: 0.9331 - val_loss: 0.4157 - val_accuracy: 0.7332\n",
            "Epoch 23/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9308\n",
            "Epoch 23: val_loss improved from 0.40384 to 0.40134, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 41ms/step - loss: 0.1456 - accuracy: 0.9308 - val_loss: 0.4013 - val_accuracy: 0.7450\n",
            "Epoch 24/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.9303\n",
            "Epoch 24: val_loss did not improve from 0.40134\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1446 - accuracy: 0.9303 - val_loss: 0.4067 - val_accuracy: 0.7361\n",
            "Epoch 25/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9319\n",
            "Epoch 25: val_loss did not improve from 0.40134\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1423 - accuracy: 0.9319 - val_loss: 0.4103 - val_accuracy: 0.7361\n",
            "Epoch 26/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9319\n",
            "Epoch 26: val_loss did not improve from 0.40134\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1385 - accuracy: 0.9319 - val_loss: 0.4169 - val_accuracy: 0.7302\n",
            "Epoch 27/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9335\n",
            "Epoch 27: val_loss did not improve from 0.40134\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1392 - accuracy: 0.9335 - val_loss: 0.4335 - val_accuracy: 0.7251\n",
            "Epoch 28/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.9328\n",
            "Epoch 28: val_loss improved from 0.40134 to 0.40011, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.1372 - accuracy: 0.9328 - val_loss: 0.4001 - val_accuracy: 0.7201\n",
            "Epoch 29/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9353\n",
            "Epoch 29: val_loss did not improve from 0.40011\n",
            "233/233 [==============================] - 9s 40ms/step - loss: 0.1304 - accuracy: 0.9353 - val_loss: 0.4382 - val_accuracy: 0.7242\n",
            "Epoch 30/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9345\n",
            "Epoch 30: val_loss improved from 0.40011 to 0.37485, saving model to best-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 41ms/step - loss: 0.1294 - accuracy: 0.9345 - val_loss: 0.3749 - val_accuracy: 0.7361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model3 = load_model(model3_path)\n",
        "best_model3.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paLjzkE20b7Z",
        "outputId": "b481d3cd-ab32-423e-c1ca-fd0ccfd48f02"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117/117 [==============================] - 2s 10ms/step - loss: 2.8285 - accuracy: 0.6217\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.8284707069396973, 0.6217158436775208]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN + BiLSTM + LSTM"
      ],
      "metadata": {
        "id": "rDRqhfmazNuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional, LayerNormalization, Conv1D, Reshape\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "5F9KNer_2Dbo"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(100,))\n",
        "em = Embedding(30000, 256, input_length=100)(inputs)\n",
        "\n",
        "x = Conv1D(256, 5, activation='relu')(em)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "x = LSTM(128)(x)\n",
        "# x = GlobalMaxPooling1D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model4 = Model(inputs = inputs, outputs = outputs)\n",
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJLS0tJEzNc5",
        "outputId": "a54ee94f-6054-4007-dce8-9a44f199f8b7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, 100, 256)          7680000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 96, 256)           327936    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 96, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 96, 256)          394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,600,586\n",
            "Trainable params: 8,600,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model4_path = 'best-cnn-bilstm-lstm.h5'\n",
        "mc4 = ModelCheckpoint(model4_path, verbose=1, save_best_only=True)\n",
        "es4 = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "dt3wxY7w19et"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model4.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc4, es4]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shlP91Ot2Qv9",
        "outputId": "451169c8-2de3-410e-c3e7-66f3c60c25ad"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 1.3180 - accuracy: 0.5532\n",
            "Epoch 1: val_loss improved from inf to 2.10355, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 30s 56ms/step - loss: 1.3180 - accuracy: 0.5532 - val_loss: 2.1036 - val_accuracy: 0.4053\n",
            "Epoch 2/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.7881\n",
            "Epoch 2: val_loss improved from 2.10355 to 1.81859, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.6547 - accuracy: 0.7881 - val_loss: 1.8186 - val_accuracy: 0.4699\n",
            "Epoch 3/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.8486\n",
            "Epoch 3: val_loss improved from 1.81859 to 1.55559, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.4804 - accuracy: 0.8486 - val_loss: 1.5556 - val_accuracy: 0.4938\n",
            "Epoch 4/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.8736\n",
            "Epoch 4: val_loss improved from 1.55559 to 1.29224, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.3893 - accuracy: 0.8736 - val_loss: 1.2922 - val_accuracy: 0.5935\n",
            "Epoch 5/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.3236 - accuracy: 0.8911\n",
            "Epoch 5: val_loss improved from 1.29224 to 1.02403, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.3236 - accuracy: 0.8911 - val_loss: 1.0240 - val_accuracy: 0.6657\n",
            "Epoch 6/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.9023\n",
            "Epoch 6: val_loss improved from 1.02403 to 0.98627, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 0.2751 - accuracy: 0.9023 - val_loss: 0.9863 - val_accuracy: 0.6551\n",
            "Epoch 7/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.2505 - accuracy: 0.9113\n",
            "Epoch 7: val_loss improved from 0.98627 to 0.91833, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.2505 - accuracy: 0.9113 - val_loss: 0.9183 - val_accuracy: 0.6783\n",
            "Epoch 8/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.2304 - accuracy: 0.9137\n",
            "Epoch 8: val_loss improved from 0.91833 to 0.72783, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 11s 48ms/step - loss: 0.2306 - accuracy: 0.9136 - val_loss: 0.7278 - val_accuracy: 0.6984\n",
            "Epoch 9/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9172\n",
            "Epoch 9: val_loss improved from 0.72783 to 0.65225, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.2146 - accuracy: 0.9172 - val_loss: 0.6523 - val_accuracy: 0.7140\n",
            "Epoch 10/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.9211\n",
            "Epoch 10: val_loss improved from 0.65225 to 0.62013, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.1972 - accuracy: 0.9211 - val_loss: 0.6201 - val_accuracy: 0.7173\n",
            "Epoch 11/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9200\n",
            "Epoch 11: val_loss improved from 0.62013 to 0.56251, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.1964 - accuracy: 0.9200 - val_loss: 0.5625 - val_accuracy: 0.7270\n",
            "Epoch 12/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9222\n",
            "Epoch 12: val_loss did not improve from 0.56251\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.1830 - accuracy: 0.9222 - val_loss: 0.6245 - val_accuracy: 0.7192\n",
            "Epoch 13/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.9239\n",
            "Epoch 13: val_loss improved from 0.56251 to 0.51931, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.1807 - accuracy: 0.9240 - val_loss: 0.5193 - val_accuracy: 0.7239\n",
            "Epoch 14/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9223\n",
            "Epoch 14: val_loss improved from 0.51931 to 0.49773, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 11s 45ms/step - loss: 0.1742 - accuracy: 0.9223 - val_loss: 0.4977 - val_accuracy: 0.7328\n",
            "Epoch 15/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9269\n",
            "Epoch 15: val_loss did not improve from 0.49773\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.1671 - accuracy: 0.9269 - val_loss: 0.5121 - val_accuracy: 0.7283\n",
            "Epoch 16/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.9270\n",
            "Epoch 16: val_loss improved from 0.49773 to 0.48753, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.1648 - accuracy: 0.9270 - val_loss: 0.4875 - val_accuracy: 0.7184\n",
            "Epoch 17/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1619 - accuracy: 0.9277\n",
            "Epoch 17: val_loss did not improve from 0.48753\n",
            "233/233 [==============================] - 10s 45ms/step - loss: 0.1619 - accuracy: 0.9277 - val_loss: 0.5176 - val_accuracy: 0.7250\n",
            "Epoch 18/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9273\n",
            "Epoch 18: val_loss improved from 0.48753 to 0.48624, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 11s 46ms/step - loss: 0.1645 - accuracy: 0.9273 - val_loss: 0.4862 - val_accuracy: 0.7394\n",
            "Epoch 19/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9275\n",
            "Epoch 19: val_loss improved from 0.48624 to 0.46417, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 0.1594 - accuracy: 0.9274 - val_loss: 0.4642 - val_accuracy: 0.7328\n",
            "Epoch 20/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9277\n",
            "Epoch 20: val_loss did not improve from 0.46417\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.1622 - accuracy: 0.9277 - val_loss: 0.4726 - val_accuracy: 0.7189\n",
            "Epoch 21/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.9293\n",
            "Epoch 21: val_loss did not improve from 0.46417\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 0.1546 - accuracy: 0.9293 - val_loss: 0.4767 - val_accuracy: 0.7236\n",
            "Epoch 22/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.9301\n",
            "Epoch 22: val_loss improved from 0.46417 to 0.42733, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 11s 46ms/step - loss: 0.1475 - accuracy: 0.9301 - val_loss: 0.4273 - val_accuracy: 0.7409\n",
            "Epoch 23/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.9316\n",
            "Epoch 23: val_loss did not improve from 0.42733\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.1464 - accuracy: 0.9316 - val_loss: 0.4359 - val_accuracy: 0.7390\n",
            "Epoch 24/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9327\n",
            "Epoch 24: val_loss did not improve from 0.42733\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.1387 - accuracy: 0.9327 - val_loss: 0.4422 - val_accuracy: 0.7290\n",
            "Epoch 25/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9321\n",
            "Epoch 25: val_loss improved from 0.42733 to 0.40230, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 0.1425 - accuracy: 0.9321 - val_loss: 0.4023 - val_accuracy: 0.7294\n",
            "Epoch 26/30\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9308\n",
            "Epoch 26: val_loss did not improve from 0.40230\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.1459 - accuracy: 0.9307 - val_loss: 0.4232 - val_accuracy: 0.7267\n",
            "Epoch 27/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9322\n",
            "Epoch 27: val_loss did not improve from 0.40230\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.1482 - accuracy: 0.9322 - val_loss: 0.4624 - val_accuracy: 0.7141\n",
            "Epoch 28/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9333\n",
            "Epoch 28: val_loss did not improve from 0.40230\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.1402 - accuracy: 0.9333 - val_loss: 0.4285 - val_accuracy: 0.7257\n",
            "Epoch 29/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9333\n",
            "Epoch 29: val_loss improved from 0.40230 to 0.39945, saving model to best-cnn-bilstm-lstm.h5\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 0.1402 - accuracy: 0.9333 - val_loss: 0.3995 - val_accuracy: 0.7321\n",
            "Epoch 30/30\n",
            "233/233 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9337\n",
            "Epoch 30: val_loss did not improve from 0.39945\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.1381 - accuracy: 0.9337 - val_loss: 0.4211 - val_accuracy: 0.7255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model4 = load_model(model4_path)\n",
        "best_model4.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmCDGibx2T-4",
        "outputId": "11916ca5-ca89-4ee2-ec64-bc123caa75cb"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117/117 [==============================] - 2s 10ms/step - loss: 2.6129 - accuracy: 0.6182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.612926721572876, 0.6182305812835693]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 셀프 어텐션"
      ],
      "metadata": {
        "id": "jyCLZ6tYnwZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "O2TVB7r-wZTf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads=8):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.embedding_dim = embedding_dim # d_model\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        assert embedding_dim % self.num_heads == 0\n",
        "\n",
        "        self.projection_dim = embedding_dim // num_heads\n",
        "        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
        "\n",
        "    def scaled_dot_product_attention(self, query, key, value):\n",
        "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        logits = matmul_qk / tf.math.sqrt(depth)\n",
        "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "        output = tf.matmul(attention_weights, value)\n",
        "        return output, attention_weights\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # (batch_size, seq_len, embedding_dim)\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "\n",
        "        # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        query = self.split_heads(query, batch_size)  \n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
        "        # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
        "\n",
        "        # (batch_size, seq_len, embedding_dim)\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
        "        outputs = self.dense(concat_attention)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "aDXg4U5Zwa4G"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(embedding_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
        "             tf.keras.layers.Dense(embedding_dim),]\n",
        "        )\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs) # 첫번째 서브층 : 멀티 헤드 어텐션\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output) # Add & Norm\n",
        "        ffn_output = self.ffn(out1) # 두번째 서브층 : 포지션 와이즈 피드 포워드 신경망\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output) # Add & Norm"
      ],
      "metadata": {
        "id": "kcpTFSnqwdRv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos_emb = tf.keras.layers.Embedding(max_len, embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        max_len = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "id": "aJX4bkTVwgUR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "ZYOUJ_kM3L4N"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "yx-7oA-N4CO0"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 40  # 각 단어의 임베딩 벡터의 차원\n",
        "num_heads = 8  # 어텐션 헤드의 수\n",
        "dff = 2048  # 포지션 와이즈 피드 포워드 신경망의 은닉층의 크기\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(max_len,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
        "x = transformer_block(x)\n",
        "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7nMRelF3S73",
        "outputId": "6d41886c-89b0-42cc-9e67-11c95a005d7b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 100)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 100, 40)          791160    \n",
            " g_8 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_block_8 (Transf  (None, 100, 40)          201160    \n",
            " ormerBlock)                                                     \n",
            "                                                                 \n",
            " global_max_pooling1d_7 (Glo  (None, 40)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 40)                0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 20)                820       \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 20)                0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 993,350\n",
            "Trainable params: 993,350\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model_path = 'best-transforemr-attention.h5py'\n",
        "mc = ModelCheckpoint(model_path, verbose=1, save_best_only=True)\n",
        "es = EarlyStopping(patience=3)\n",
        "\n",
        "history = model.fit(X_train, Y_train, validation_split=0.2,\n",
        "                    batch_size=32, epochs=100, callbacks=[mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgyCWP1l3WMi",
        "outputId": "46dc2079-3372-4d62-cbe7-f238814309b1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "927/930 [============================>.] - ETA: 0s - loss: 1.7003 - accuracy: 0.4084\n",
            "Epoch 1: val_loss improved from inf to 2.42978, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 16s 15ms/step - loss: 1.6980 - accuracy: 0.4094 - val_loss: 2.4298 - val_accuracy: 0.3490\n",
            "Epoch 2/100\n",
            "928/930 [============================>.] - ETA: 0s - loss: 0.9740 - accuracy: 0.6823\n",
            "Epoch 2: val_loss improved from 2.42978 to 2.08136, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 14s 15ms/step - loss: 0.9742 - accuracy: 0.6822 - val_loss: 2.0814 - val_accuracy: 0.3640\n",
            "Epoch 3/100\n",
            "929/930 [============================>.] - ETA: 0s - loss: 0.7350 - accuracy: 0.7529\n",
            "Epoch 3: val_loss improved from 2.08136 to 1.78806, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 15s 16ms/step - loss: 0.7348 - accuracy: 0.7529 - val_loss: 1.7881 - val_accuracy: 0.4481\n",
            "Epoch 4/100\n",
            "928/930 [============================>.] - ETA: 0s - loss: 0.5787 - accuracy: 0.8095\n",
            "Epoch 4: val_loss improved from 1.78806 to 1.69773, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 14s 15ms/step - loss: 0.5787 - accuracy: 0.8095 - val_loss: 1.6977 - val_accuracy: 0.4584\n",
            "Epoch 5/100\n",
            "926/930 [============================>.] - ETA: 0s - loss: 0.4515 - accuracy: 0.8543\n",
            "Epoch 5: val_loss improved from 1.69773 to 1.34835, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 14s 15ms/step - loss: 0.4519 - accuracy: 0.8544 - val_loss: 1.3483 - val_accuracy: 0.5321\n",
            "Epoch 6/100\n",
            "930/930 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8796\n",
            "Epoch 6: val_loss improved from 1.34835 to 1.26134, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 15s 16ms/step - loss: 0.3677 - accuracy: 0.8796 - val_loss: 1.2613 - val_accuracy: 0.5909\n",
            "Epoch 7/100\n",
            "925/930 [============================>.] - ETA: 0s - loss: 0.3109 - accuracy: 0.8953\n",
            "Epoch 7: val_loss improved from 1.26134 to 0.97222, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 15s 17ms/step - loss: 0.3108 - accuracy: 0.8952 - val_loss: 0.9722 - val_accuracy: 0.6473\n",
            "Epoch 8/100\n",
            "928/930 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.9036\n",
            "Epoch 8: val_loss improved from 0.97222 to 0.80870, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 14s 15ms/step - loss: 0.2722 - accuracy: 0.9035 - val_loss: 0.8087 - val_accuracy: 0.6920\n",
            "Epoch 9/100\n",
            "926/930 [============================>.] - ETA: 0s - loss: 0.2411 - accuracy: 0.9099\n",
            "Epoch 9: val_loss improved from 0.80870 to 0.74669, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 15s 16ms/step - loss: 0.2413 - accuracy: 0.9099 - val_loss: 0.7467 - val_accuracy: 0.7045\n",
            "Epoch 10/100\n",
            "926/930 [============================>.] - ETA: 0s - loss: 0.2237 - accuracy: 0.9137\n",
            "Epoch 10: val_loss did not improve from 0.74669\n",
            "930/930 [==============================] - 11s 12ms/step - loss: 0.2237 - accuracy: 0.9137 - val_loss: 0.8405 - val_accuracy: 0.6951\n",
            "Epoch 11/100\n",
            "927/930 [============================>.] - ETA: 0s - loss: 0.2098 - accuracy: 0.9188\n",
            "Epoch 11: val_loss improved from 0.74669 to 0.66491, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 14s 15ms/step - loss: 0.2095 - accuracy: 0.9189 - val_loss: 0.6649 - val_accuracy: 0.7255\n",
            "Epoch 12/100\n",
            "927/930 [============================>.] - ETA: 0s - loss: 0.1971 - accuracy: 0.9200\n",
            "Epoch 12: val_loss improved from 0.66491 to 0.61816, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 14s 15ms/step - loss: 0.1970 - accuracy: 0.9201 - val_loss: 0.6182 - val_accuracy: 0.7037\n",
            "Epoch 13/100\n",
            "927/930 [============================>.] - ETA: 0s - loss: 0.1878 - accuracy: 0.9219\n",
            "Epoch 13: val_loss improved from 0.61816 to 0.59885, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 14s 15ms/step - loss: 0.1883 - accuracy: 0.9217 - val_loss: 0.5988 - val_accuracy: 0.7197\n",
            "Epoch 14/100\n",
            "929/930 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9234\n",
            "Epoch 14: val_loss did not improve from 0.59885\n",
            "930/930 [==============================] - 11s 12ms/step - loss: 0.1806 - accuracy: 0.9234 - val_loss: 0.6899 - val_accuracy: 0.7102\n",
            "Epoch 15/100\n",
            "926/930 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9263\n",
            "Epoch 15: val_loss improved from 0.59885 to 0.51579, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 15s 16ms/step - loss: 0.1766 - accuracy: 0.9263 - val_loss: 0.5158 - val_accuracy: 0.7357\n",
            "Epoch 16/100\n",
            "930/930 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9267\n",
            "Epoch 16: val_loss improved from 0.51579 to 0.46144, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_22_layer_call_fn, embedding_22_layer_call_and_return_conditional_losses, embedding_23_layer_call_fn, embedding_23_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f70a55de210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r930/930 [==============================] - 14s 15ms/step - loss: 0.1705 - accuracy: 0.9267 - val_loss: 0.4614 - val_accuracy: 0.7446\n",
            "Epoch 17/100\n",
            "926/930 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9265\n",
            "Epoch 17: val_loss did not improve from 0.46144\n",
            "930/930 [==============================] - 11s 12ms/step - loss: 0.1662 - accuracy: 0.9264 - val_loss: 0.6177 - val_accuracy: 0.7289\n",
            "Epoch 18/100\n",
            "929/930 [============================>.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9283\n",
            "Epoch 18: val_loss did not improve from 0.46144\n",
            "930/930 [==============================] - 12s 13ms/step - loss: 0.1633 - accuracy: 0.9283 - val_loss: 0.6165 - val_accuracy: 0.7205\n",
            "Epoch 19/100\n",
            "928/930 [============================>.] - ETA: 0s - loss: 0.1649 - accuracy: 0.9271\n",
            "Epoch 19: val_loss did not improve from 0.46144\n",
            "930/930 [==============================] - 11s 12ms/step - loss: 0.1650 - accuracy: 0.9271 - val_loss: 0.5693 - val_accuracy: 0.7339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model(model_path)\n",
        "best_model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbxOEeRk3aHH",
        "outputId": "cb80c3cd-d0e0-4293-80e4-cf5f39624574"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117/117 [==============================] - 1s 7ms/step - loss: 3.0509 - accuracy: 0.5772\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.050936222076416, 0.5772117972373962]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM + 어텐션"
      ],
      "metadata": {
        "id": "Rctiurdp8Uzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "GaRwyLtN8XQA"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query): # 단, key와 value는 같음\n",
        "    # query shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "dyOtK8-08Zqd"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers"
      ],
      "metadata": {
        "id": "iBl_Jq5o8bH5"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model5"
      ],
      "metadata": {
        "id": "9WLk478AAYm7"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)\n",
        "\n",
        "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)\n",
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
        "  (LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)\n",
        "\n",
        "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
        "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태\n",
        "\n",
        "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
        "context_vector, attention_weights = attention(lstm, state_h)\n",
        "\n",
        "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(10, activation=\"softmax\")(dropout)\n",
        "model5 = Model(inputs=sequence_input, outputs=output)"
      ],
      "metadata": {
        "id": "EFXxDhXV8duc"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model5_path = 'best-lstm-attention.h5py'\n",
        "mc5 = ModelCheckpoint(model5_path, verbose=1, save_best_only=True)\n",
        "es5 = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "bJ-_qxlx8tUz"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model5.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=100, batch_size=128, callbacks=[mc5, es5]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkXwsnKE89mk",
        "outputId": "57c7d661-dca5-47cb-ac1c-4736780d8ec6"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 2.0324 - accuracy: 0.2632\n",
            "Epoch 1: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 157s 1s/step - loss: 2.0324 - accuracy: 0.2632 - val_loss: 2.9512 - val_accuracy: 0.0241\n",
            "Epoch 2/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 1.4034 - accuracy: 0.5414\n",
            "Epoch 2: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 121s 1s/step - loss: 1.4034 - accuracy: 0.5414 - val_loss: 2.7048 - val_accuracy: 0.1603\n",
            "Epoch 3/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 1.1270 - accuracy: 0.6483\n",
            "Epoch 3: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 1.1270 - accuracy: 0.6483 - val_loss: 2.6711 - val_accuracy: 0.1442\n",
            "Epoch 4/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.9640 - accuracy: 0.6911\n",
            "Epoch 4: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 121s 1s/step - loss: 0.9640 - accuracy: 0.6911 - val_loss: 2.3986 - val_accuracy: 0.1789\n",
            "Epoch 5/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.8510 - accuracy: 0.7140\n",
            "Epoch 5: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.8510 - accuracy: 0.7140 - val_loss: 2.2931 - val_accuracy: 0.2614\n",
            "Epoch 6/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.7893 - accuracy: 0.7256\n",
            "Epoch 6: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 121s 1s/step - loss: 0.7893 - accuracy: 0.7256 - val_loss: 2.0311 - val_accuracy: 0.2726\n",
            "Epoch 7/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.7263 - accuracy: 0.7432\n",
            "Epoch 7: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.7263 - accuracy: 0.7432 - val_loss: 1.8680 - val_accuracy: 0.3663\n",
            "Epoch 8/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.7554\n",
            "Epoch 8: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.7023 - accuracy: 0.7554 - val_loss: 1.7580 - val_accuracy: 0.3983\n",
            "Epoch 9/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.6471 - accuracy: 0.7786\n",
            "Epoch 9: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.6471 - accuracy: 0.7786 - val_loss: 1.6616 - val_accuracy: 0.4298\n",
            "Epoch 10/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.6077 - accuracy: 0.7881\n",
            "Epoch 10: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.6077 - accuracy: 0.7881 - val_loss: 1.5494 - val_accuracy: 0.4251\n",
            "Epoch 11/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.8071\n",
            "Epoch 11: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 119s 1s/step - loss: 0.5574 - accuracy: 0.8071 - val_loss: 1.4170 - val_accuracy: 0.4545\n",
            "Epoch 12/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.8148\n",
            "Epoch 12: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.5327 - accuracy: 0.8148 - val_loss: 1.3193 - val_accuracy: 0.4619\n",
            "Epoch 13/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 0.8199\n",
            "Epoch 13: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.5175 - accuracy: 0.8199 - val_loss: 1.2784 - val_accuracy: 0.5017\n",
            "Epoch 14/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.4854 - accuracy: 0.8285\n",
            "Epoch 14: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 119s 1s/step - loss: 0.4854 - accuracy: 0.8285 - val_loss: 1.1801 - val_accuracy: 0.5241\n",
            "Epoch 15/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.4759 - accuracy: 0.8335\n",
            "Epoch 15: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.4759 - accuracy: 0.8335 - val_loss: 1.1415 - val_accuracy: 0.5358\n",
            "Epoch 16/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.8405\n",
            "Epoch 16: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 119s 1s/step - loss: 0.4569 - accuracy: 0.8405 - val_loss: 1.1374 - val_accuracy: 0.5328\n",
            "Epoch 17/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.8442\n",
            "Epoch 17: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.4484 - accuracy: 0.8442 - val_loss: 1.0478 - val_accuracy: 0.5393\n",
            "Epoch 18/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.4252 - accuracy: 0.8507\n",
            "Epoch 18: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 119s 1s/step - loss: 0.4252 - accuracy: 0.8507 - val_loss: 1.0570 - val_accuracy: 0.5744\n",
            "Epoch 19/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.4207 - accuracy: 0.8523\n",
            "Epoch 19: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.4207 - accuracy: 0.8523 - val_loss: 0.9792 - val_accuracy: 0.6256\n",
            "Epoch 20/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.8516\n",
            "Epoch 20: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.4158 - accuracy: 0.8516 - val_loss: 0.9460 - val_accuracy: 0.6501\n",
            "Epoch 21/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.8506\n",
            "Epoch 21: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 121s 1s/step - loss: 0.4164 - accuracy: 0.8506 - val_loss: 0.9678 - val_accuracy: 0.6295\n",
            "Epoch 22/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.8557\n",
            "Epoch 22: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 122s 1s/step - loss: 0.4005 - accuracy: 0.8557 - val_loss: 0.8832 - val_accuracy: 0.6602\n",
            "Epoch 23/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.3962 - accuracy: 0.8578\n",
            "Epoch 23: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 121s 1s/step - loss: 0.3962 - accuracy: 0.8578 - val_loss: 0.8766 - val_accuracy: 0.6495\n",
            "Epoch 24/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8607\n",
            "Epoch 24: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 119s 1s/step - loss: 0.3837 - accuracy: 0.8607 - val_loss: 0.8148 - val_accuracy: 0.6891\n",
            "Epoch 25/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.3754 - accuracy: 0.8644\n",
            "Epoch 25: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.3754 - accuracy: 0.8644 - val_loss: 0.7989 - val_accuracy: 0.7033\n",
            "Epoch 26/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.8642\n",
            "Epoch 26: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.3695 - accuracy: 0.8642 - val_loss: 0.7801 - val_accuracy: 0.6868\n",
            "Epoch 27/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8654\n",
            "Epoch 27: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 119s 1s/step - loss: 0.3762 - accuracy: 0.8654 - val_loss: 0.7232 - val_accuracy: 0.7058\n",
            "Epoch 28/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.8639\n",
            "Epoch 28: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 119s 1s/step - loss: 0.3707 - accuracy: 0.8639 - val_loss: 0.8001 - val_accuracy: 0.6911\n",
            "Epoch 29/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.8689\n",
            "Epoch 29: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 119s 1s/step - loss: 0.3585 - accuracy: 0.8689 - val_loss: 0.7654 - val_accuracy: 0.7066\n",
            "Epoch 30/100\n",
            "117/117 [==============================] - ETA: 0s - loss: 0.3592 - accuracy: 0.8673\n",
            "Epoch 30: val_loss did not improve from 0.42134\n",
            "117/117 [==============================] - 120s 1s/step - loss: 0.3592 - accuracy: 0.8673 - val_loss: 0.7535 - val_accuracy: 0.6927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model5 = load_model(model5_path)\n",
        "best_model5.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vc6lIci9M0A",
        "outputId": "42aafe22-b6e4-42aa-a75d-126a4d4fec5e"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117/117 [==============================] - 4s 11ms/step - loss: 1.6295 - accuracy: 0.6338\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.629464030265808, 0.6337801814079285]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실제값에 넣어서 확인"
      ],
      "metadata": {
        "id": "7K41eTqG6D2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = test_df.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\")"
      ],
      "metadata": {
        "id": "k2ovq-gX4XDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num=50\n",
        "text = test_df['문장'][num]\n",
        "print(sentiment_predict(text, best_model,tokenizer=t, max_len=max_len))\n",
        "print(test_df.loc[num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VPZToNO4gFJ",
        "outputId": "48e1f94f-9d9b-4019-b461-45b7da0e5e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'입국금지는 일본이 먼저 때린거 맞자너'\n",
            " 96.88556790351868%의 확률로 clean에 대한 악플입니다.\n",
            "None\n",
            "문장       입국금지는 일본이 먼저 때린거 맞자너\n",
            "여성/가족                       0\n",
            "남성                          0\n",
            "성소수자                        0\n",
            "인종/국적                       0\n",
            "연령                          0\n",
            "지역                          0\n",
            "종교                          0\n",
            "기타 혐오                       0\n",
            "악플/욕설                       0\n",
            "clean                       1\n",
            "Name: 50, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = test_df.columns[1:]\n",
        "\n",
        "    return score.argmax()"
      ],
      "metadata": {
        "id": "kSvShvbL44g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict(train_df['문장'][0], best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVKu4aUT5J5x",
        "outputId": "6c8bcc6c-8c25-43c5-9920-6ebee074a14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_predict = [score.argmax() for score in best_model.predict(X_test)]"
      ],
      "metadata": {
        "id": "gdy0XIl648dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_predict"
      ],
      "metadata": {
        "id": "pXQRgcyX7G8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test data 라벨링\n",
        "df = pd.concat([test_df['문장'], test_df.iloc[:, 1:11] * range(1, 11)], axis=1)\n",
        "\n",
        "dataset_test = pd.DataFrame()\n",
        "for i in range(1, 11):\n",
        "  data = df.loc[df.iloc[:, i] > 0][['문장', df.columns[i]]]\n",
        "  data.columns = ['문장', '라벨']\n",
        "  dataset_test = pd.concat([dataset_test, data])\n",
        "  \n",
        "  dataset_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "gg3DosvI5hm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test['라벨'] = dataset_test['라벨']-1"
      ],
      "metadata": {
        "id": "TehHaG9N7OAY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "악플분류기_다중분류_확인.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "9f5feb42f08914aecde0ece13ac07afe9f84906579ba918f8c70eb200f669000"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 ('min')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c78e9985ce74a80b91ee88cdb1ea306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c81183cb6a2142d1a009d73264ee88da",
              "IPY_MODEL_e2af431ccd05417ea8fdfdafc56c8889",
              "IPY_MODEL_72a9ae1c761642cf9512555a62c55389"
            ],
            "layout": "IPY_MODEL_ef39627d7fb44d45936e426f27049cd9"
          }
        },
        "c81183cb6a2142d1a009d73264ee88da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4b9165854494d59859aeeeb822f930a",
            "placeholder": "​",
            "style": "IPY_MODEL_553762c962d7431994097f49efe58df2",
            "value": "100%"
          }
        },
        "e2af431ccd05417ea8fdfdafc56c8889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eb5b9ee324c47088ca8d66b56ccae58",
            "max": 28269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2ad92551aee4e1e8b6661dc4c19f3cb",
            "value": 28269
          }
        },
        "72a9ae1c761642cf9512555a62c55389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_492ac86a4d0343b883d5fa84ac7d5880",
            "placeholder": "​",
            "style": "IPY_MODEL_a503f7730ec14edd9fb03524c09bd2fc",
            "value": " 28269/28269 [00:04&lt;00:00, 5801.75it/s]"
          }
        },
        "ef39627d7fb44d45936e426f27049cd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4b9165854494d59859aeeeb822f930a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "553762c962d7431994097f49efe58df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0eb5b9ee324c47088ca8d66b56ccae58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ad92551aee4e1e8b6661dc4c19f3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "492ac86a4d0343b883d5fa84ac7d5880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a503f7730ec14edd9fb03524c09bd2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "611cddecd516470abbdbf9d6a9781eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b398155abd544262a59231b7d0351663",
              "IPY_MODEL_177baabb726e4feb8378b091a439cb0e",
              "IPY_MODEL_adf4976adf5840d7953c01c3fa926f13"
            ],
            "layout": "IPY_MODEL_b29e00627b3746ba993f6831eed82184"
          }
        },
        "b398155abd544262a59231b7d0351663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61c0235771cf45b4b28a59de60ab2ab9",
            "placeholder": "​",
            "style": "IPY_MODEL_6382cf5cd703429e92ecaa8dd96d276e",
            "value": "100%"
          }
        },
        "177baabb726e4feb8378b091a439cb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d78a6acea384a8cba70a324824586c0",
            "max": 2800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59900c56414c40b0a313d29aa64f558f",
            "value": 2800
          }
        },
        "adf4976adf5840d7953c01c3fa926f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_439fbf372c1744c49c7bd52010ede68a",
            "placeholder": "​",
            "style": "IPY_MODEL_271f1bb0bbb7495189ec8121ec069ac8",
            "value": " 2800/2800 [00:00&lt;00:00, 6031.30it/s]"
          }
        },
        "b29e00627b3746ba993f6831eed82184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c0235771cf45b4b28a59de60ab2ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6382cf5cd703429e92ecaa8dd96d276e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d78a6acea384a8cba70a324824586c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59900c56414c40b0a313d29aa64f558f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "439fbf372c1744c49c7bd52010ede68a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271f1bb0bbb7495189ec8121ec069ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6cdfdcaae394c2db3b30bef56e458e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b2d1889cdbb4c219eca0b906bd0400a",
              "IPY_MODEL_6d5d899a923146aca89656488b61ed22",
              "IPY_MODEL_7779bc0dfc754dc1abd35056481fe18c"
            ],
            "layout": "IPY_MODEL_d172ab83da054fdfa176182fc0690e34"
          }
        },
        "7b2d1889cdbb4c219eca0b906bd0400a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edcfe7469ef1485ba24964ff85e2cea2",
            "placeholder": "​",
            "style": "IPY_MODEL_4380fc0a257642aab4ff1ab0cb868ded",
            "value": "100%"
          }
        },
        "6d5d899a923146aca89656488b61ed22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64d937ca50b94fc0ae8d2b7164e4c72e",
            "max": 37180,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b29ac0bb05f4a4191f54b85b6d9bad1",
            "value": 37180
          }
        },
        "7779bc0dfc754dc1abd35056481fe18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67280c232a144ae3953712088a874a51",
            "placeholder": "​",
            "style": "IPY_MODEL_ba1cdb9c6176453c8a184d9f55b86f1a",
            "value": " 37180/37180 [00:05&lt;00:00, 2769.29it/s]"
          }
        },
        "d172ab83da054fdfa176182fc0690e34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edcfe7469ef1485ba24964ff85e2cea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4380fc0a257642aab4ff1ab0cb868ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64d937ca50b94fc0ae8d2b7164e4c72e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b29ac0bb05f4a4191f54b85b6d9bad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67280c232a144ae3953712088a874a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba1cdb9c6176453c8a184d9f55b86f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01f79b04317d494faafeddd1f3e7c191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ab7235f54414efc8fc751becf2b8848",
              "IPY_MODEL_494ffcee707e4bfeb4a9182664474acc",
              "IPY_MODEL_4584947ccff1404681354d163f96fb6a"
            ],
            "layout": "IPY_MODEL_a6e7518c3933484f919693bef2bd1c51"
          }
        },
        "7ab7235f54414efc8fc751becf2b8848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab3ca7e007847c1aa3f5f79978ddb6c",
            "placeholder": "​",
            "style": "IPY_MODEL_35f1a47d067d4e3ebd8104f386d36591",
            "value": "100%"
          }
        },
        "494ffcee707e4bfeb4a9182664474acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b45fe23218544cb90eb78fa640d0cde",
            "max": 3730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_867842df4b7c4c20b02e1a023c4c66a0",
            "value": 3730
          }
        },
        "4584947ccff1404681354d163f96fb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bba77e709044811a8fb07251815317f",
            "placeholder": "​",
            "style": "IPY_MODEL_b89e13be6c244f0cbaef99607c5f0b32",
            "value": " 3730/3730 [00:00&lt;00:00, 4199.25it/s]"
          }
        },
        "a6e7518c3933484f919693bef2bd1c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab3ca7e007847c1aa3f5f79978ddb6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35f1a47d067d4e3ebd8104f386d36591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b45fe23218544cb90eb78fa640d0cde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "867842df4b7c4c20b02e1a023c4c66a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bba77e709044811a8fb07251815317f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b89e13be6c244f0cbaef99607c5f0b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}