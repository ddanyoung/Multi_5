{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "악플 다중 분류기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPH2KlEDOQngwJKJeWZb7mV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08516e149bcc44ceb00363d403370336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bee5d6df3c9484c9e3dc1cb7c2381b3",
              "IPY_MODEL_abd0ce1e092045e0886f38f7c9ac9aae",
              "IPY_MODEL_c57efda8f0b144cbb714d5cb9a75d61f"
            ],
            "layout": "IPY_MODEL_09ea2325e69744de9bdff94fb1a035bd"
          }
        },
        "1bee5d6df3c9484c9e3dc1cb7c2381b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09af3b0e7f9646319240a8fe7d55fceb",
            "placeholder": "​",
            "style": "IPY_MODEL_a1112dda635c4a0d8efeae4269238341",
            "value": "100%"
          }
        },
        "abd0ce1e092045e0886f38f7c9ac9aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b6a160a24d54b17aff0db8b4e2badf3",
            "max": 14690,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_022175175d014a6b9198a150c0809b43",
            "value": 14690
          }
        },
        "c57efda8f0b144cbb714d5cb9a75d61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eedc65d4ea8547a5a40bf97fe7f15e4c",
            "placeholder": "​",
            "style": "IPY_MODEL_46568df230764cf6bdf54f04cd4018ac",
            "value": " 14690/14690 [00:02&lt;00:00, 8716.82it/s]"
          }
        },
        "09ea2325e69744de9bdff94fb1a035bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09af3b0e7f9646319240a8fe7d55fceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1112dda635c4a0d8efeae4269238341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b6a160a24d54b17aff0db8b4e2badf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022175175d014a6b9198a150c0809b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eedc65d4ea8547a5a40bf97fe7f15e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46568df230764cf6bdf54f04cd4018ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12a19fed85ac44e0a0ff9d0d315a2437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1b3b5cf469d4724bee0b683d086bd6a",
              "IPY_MODEL_fa9cb9feb5a94822a034d7de70e532a4",
              "IPY_MODEL_9bb720b3ffca49dfbbf7daed4a38bd8f"
            ],
            "layout": "IPY_MODEL_e198174bd77b4f7f956ea3400c2ec411"
          }
        },
        "c1b3b5cf469d4724bee0b683d086bd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52111a848d5f457bae141141c13789a5",
            "placeholder": "​",
            "style": "IPY_MODEL_eea6b7fbd97042a5bb334412275fa376",
            "value": "100%"
          }
        },
        "fa9cb9feb5a94822a034d7de70e532a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e5fdd00a9e042119747510e31e4ed6f",
            "max": 47407,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7effcfa595ab453c931f6ac6d6331949",
            "value": 47407
          }
        },
        "9bb720b3ffca49dfbbf7daed4a38bd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c5cec716bca435e83751a7d4a4f7148",
            "placeholder": "​",
            "style": "IPY_MODEL_1b256fdaa85c4a43b5ffd51e24a2ef26",
            "value": " 47407/47407 [00:08&lt;00:00, 9126.68it/s]"
          }
        },
        "e198174bd77b4f7f956ea3400c2ec411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52111a848d5f457bae141141c13789a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea6b7fbd97042a5bb334412275fa376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e5fdd00a9e042119747510e31e4ed6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7effcfa595ab453c931f6ac6d6331949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c5cec716bca435e83751a7d4a4f7148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b256fdaa85c4a43b5ffd51e24a2ef26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 악플 분류기 - 다중분류"
      ],
      "metadata": {
        "id": "J9CfSaiVib0r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a_ypjpJOTlVQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "df = pd.read_csv(\"/content/common_data1.csv\", encoding='utf-8')"
      ],
      "metadata": {
        "id": "ZH_Zd4m5h7Ab"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:, 1:].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRVv7XwZh-ep",
        "outputId": "396e9af0-0112-4781-bebf-95dc3b1af7e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "여성/가족     5195.0\n",
              "남성        4819.0\n",
              "성소수자      2116.0\n",
              "인종/국적     4971.0\n",
              "연령        4988.0\n",
              "지역        5036.0\n",
              "종교        4719.0\n",
              "기타혐오      4974.0\n",
              "악플/욕설    10894.0\n",
              "clean     4647.0\n",
              "분쟁유발      7681.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smile_train = pd.read_csv(\"/content/unsmile_train_v1.0.tsv\", delimiter='\\t')"
      ],
      "metadata": {
        "id": "HTAfT9JFAir0"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smile_train = smile_train[smile_train['개인지칭'] == 0]"
      ],
      "metadata": {
        "id": "Quhh0pIGEEfI"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strain_data = []\n",
        "for sentence in tqdm(smile_train.문장):\n",
        "  morphs = mecab.morphs(sentence)\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  strain_data.append(tmp_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "08516e149bcc44ceb00363d403370336",
            "1bee5d6df3c9484c9e3dc1cb7c2381b3",
            "abd0ce1e092045e0886f38f7c9ac9aae",
            "c57efda8f0b144cbb714d5cb9a75d61f",
            "09ea2325e69744de9bdff94fb1a035bd",
            "09af3b0e7f9646319240a8fe7d55fceb",
            "a1112dda635c4a0d8efeae4269238341",
            "8b6a160a24d54b17aff0db8b4e2badf3",
            "022175175d014a6b9198a150c0809b43",
            "eedc65d4ea8547a5a40bf97fe7f15e4c",
            "46568df230764cf6bdf54f04cd4018ac"
          ]
        },
        "id": "qVpOMGD7BMfc",
        "outputId": "f3e450b0-cf80-4fd9-c874-af9bd136b958"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/14690 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08516e149bcc44ceb00363d403370336"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strain_data = t.texts_to_sequences(strain_data)"
      ],
      "metadata": {
        "id": "JmCZl01NBdFS"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strain_data = pad_sequences(strain_data, maxlen=max_len)"
      ],
      "metadata": {
        "id": "7A1yUb3XBsru"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strain_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gmWq8ToBuzA",
        "outputId": "ed3c4aca-d7c5-483e-ff6f-816366d841ec"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0, 7097,    2,  442, 1369,    3,  120,  154,  241,    8,\n",
              "       2694], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ],
      "metadata": {
        "id": "SfzxEBh7iiw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복 데이터 확인\n",
        "print(df.shape, df.문장.nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iea1QZm8iOZF",
        "outputId": "1317df0e-ff8a-4fa8-afce-8b10f31b8bbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47409, 12) 47409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류가 안되어 있는 데이터 확인\n",
        "print(df[df.sum(axis=1) == 0].index)\n",
        "\n",
        "# 분류 안되어 있는 데이터 삭제\n",
        "df = df[df.sum(axis=1) != 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JNI4tD4imPr",
        "outputId": "facf0d51-7f16-484d-c273-f4679a1235e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Int64Index([38299, 44356], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트 전처리"
      ],
      "metadata": {
        "id": "KKer_96DitFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
        "df.문장 = df.문장.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ').str.strip()\n",
        "df.문장.replace('', np.nan, inplace=True)\n",
        "print(df.문장.isna().sum())\n",
        "df.dropna(how='any', inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5IX3wYqiogr",
        "outputId": "4fb09a60-7240-4a41-b74d-1a75f10d9202"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47407, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 한글 형태소 분석"
      ],
      "metadata": {
        "id": "Zfuo5EuEi1jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LepsJccUiwBn",
        "outputId": "2655405b-9d33-4678-93b3-4a98dccce633"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 9.57 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 70.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-06-13 05:31:21--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=uuiRPXlQASCvwQLykxY321sCSkk%3D&Expires=1655099543&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2022-06-13 05:31:21--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=uuiRPXlQASCvwQLykxY321sCSkk%3D&Expires=1655099543&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.36.236\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.36.236|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  7.59MB/s    in 0.2s    \n",
            "\n",
            "2022-06-13 05:31:22 (7.59 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-06-13 05:32:51--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::3403:4be7, 2406:da00:ff00::22c0:3470, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=vJ4yeyRsQ2iUGbF2IfJVWQbR5ow%3D&Expires=1655099808&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2022-06-13 05:32:51--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=vJ4yeyRsQ2iUGbF2IfJVWQbR5ow%3D&Expires=1655099808&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.39.116\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.39.116|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  64.1MB/s    in 0.7s    \n",
            "\n",
            "2022-06-13 05:32:52 (64.1 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n",
            "문제를 해결해주신 combacsa님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "jQI8aeFUi24V"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mecab = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']"
      ],
      "metadata": {
        "id": "60sRgabei6L_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "for sentence in tqdm(df.문장):\n",
        "  morphs = mecab.morphs(sentence)\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  train_data.append(tmp_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "12a19fed85ac44e0a0ff9d0d315a2437",
            "c1b3b5cf469d4724bee0b683d086bd6a",
            "fa9cb9feb5a94822a034d7de70e532a4",
            "9bb720b3ffca49dfbbf7daed4a38bd8f",
            "e198174bd77b4f7f956ea3400c2ec411",
            "52111a848d5f457bae141141c13789a5",
            "eea6b7fbd97042a5bb334412275fa376",
            "8e5fdd00a9e042119747510e31e4ed6f",
            "7effcfa595ab453c931f6ac6d6331949",
            "6c5cec716bca435e83751a7d4a4f7148",
            "1b256fdaa85c4a43b5ffd51e24a2ef26"
          ]
        },
        "id": "1IY6fmFYi7Wh",
        "outputId": "079725fc-44c5-4866-8c08-7a887ac79cfe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/47407 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12a19fed85ac44e0a0ff9d0d315a2437"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 토큰화"
      ],
      "metadata": {
        "id": "GTlxIum4jAGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "DK_cTI4UjBQ0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "3tzDrKc8j0MU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(train_data, df.iloc[:, 1:], test_size=0.2)"
      ],
      "metadata": {
        "id": "nTBi_b7ej3TX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "_AvY2UCej78F"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 등장 빈도가 3 미만인 것의 갯수\n",
        "threshold = 3\n",
        "total_cnt = len(t.word_index)   # 단어의 수\n",
        "rare_cnt = 0                    # 등장 빈도가 threshold 보다 작은 단어의 갯수\n",
        "total_freq = 0                  # 훈련 데이터의 전체 단어의 빈도수의 합\n",
        "rare_freq = 0                   # 등장 빈도가 threshold 보다 작은 단어의 등장 빈도수의 합"
      ],
      "metadata": {
        "id": "OerlaZlPkNIC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in t.word_counts.items():\n",
        "  total_freq += value\n",
        "  if value < threshold:\n",
        "    rare_cnt += 1\n",
        "    rare_freq += value"
      ],
      "metadata": {
        "id": "XLLIkcmPkOvd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print(f'등장 빈도가 {threshold - 1}번 이하인 희귀 단어의 수: {rare_cnt}')\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9CcXvimkQzA",
        "outputId": "fe1c2a0c-3150-4238-c28c-72c19a446e5f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 36985\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 21328\n",
            "단어 집합에서 희귀 단어의 비율: 57.66662160335271\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.926213551633787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 단어 사용\n",
        "vocab_size = total_cnt + 2\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFc63qS0kR5b",
        "outputId": "fe315ca8-c01e-42f9-de5a-7ac354d8feb8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36987"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "t.fit_on_texts(train_data)\n",
        "X_train = t.texts_to_sequences(X_train)\n",
        "X_test = t.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "6sr9gEiokTSV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('tokenizer.pkl','wb') as f:\n",
        "  pickle.dump(t,f)"
      ],
      "metadata": {
        "id": "yrcPP3FfwQIl"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 최대/평균 길이\n",
        "max(len(s) for s in X_train), sum(map(len, X_train)) / len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv_x4Zeljkuw",
        "outputId": "974bc5e2-fac9-46c3-d291-b68ed795d0fb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(164, 23.96089650626236)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 악플 길이를 100으로 설정\n",
        "max_len = 100"
      ],
      "metadata": {
        "id": "gFF3yk2BkY5C"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig1n57APkbNq",
        "outputId": "df60ac80-98da-4335-ae75-35d59e0155ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37925, 100), (9482, 100))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = Y_train.values\n",
        "Y_test = Y_test.values"
      ],
      "metadata": {
        "id": "ny4EYotFtWTY"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape, Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y5-Xs4Pkdou",
        "outputId": "d2c2d67f-ebee-43e3-8e7c-f5b9412e3ecb"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37925, 11), (9482, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 정의/설정/학습"
      ],
      "metadata": {
        "id": "zd5Jmi-Vkqdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM + 어텐션"
      ],
      "metadata": {
        "id": "ZR3XvpGJLafV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "NCgr7Yd1kdPB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query): # 단, key와 value는 같음\n",
        "    # query shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "Oh_thD6cksDG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)\n",
        "\n",
        "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)\n",
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
        "  (LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)\n",
        "\n",
        "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
        "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태\n",
        "\n",
        "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
        "context_vector, attention_weights = attention(lstm, state_h)\n",
        "\n",
        "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(11, activation=\"softmax\")(dropout)\n",
        "model5 = Model(inputs=sequence_input, outputs=output)"
      ],
      "metadata": {
        "id": "_Q1WhhIJlNAe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model5_path = 'best-lstm-attention.h5py'\n",
        "mc5 = ModelCheckpoint(model5_path, verbose=1, save_best_only=True)\n",
        "es5 = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "pdshGCKclywK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model5.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=100, batch_size=128, callbacks=[mc5, es5]\n",
        ")"
      ],
      "metadata": {
        "id": "VwGQ4-zil5gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 트랜스포머"
      ],
      "metadata": {
        "id": "exn1phJQo2y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "5Zc63dZ3l7l6"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads=8):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.embedding_dim = embedding_dim # d_model\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        assert embedding_dim % self.num_heads == 0\n",
        "\n",
        "        self.projection_dim = embedding_dim // num_heads\n",
        "        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
        "\n",
        "    def scaled_dot_product_attention(self, query, key, value):\n",
        "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        logits = matmul_qk / tf.math.sqrt(depth)\n",
        "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "        output = tf.matmul(attention_weights, value)\n",
        "        return output, attention_weights\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # (batch_size, seq_len, embedding_dim)\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "\n",
        "        # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        query = self.split_heads(query, batch_size)  \n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
        "        # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
        "\n",
        "        # (batch_size, seq_len, embedding_dim)\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
        "        outputs = self.dense(concat_attention)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "58BP4834o5Zx"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(embedding_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
        "             tf.keras.layers.Dense(embedding_dim),]\n",
        "        )\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs) # 첫번째 서브층 : 멀티 헤드 어텐션\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output) # Add & Norm\n",
        "        ffn_output = self.ffn(out1) # 두번째 서브층 : 포지션 와이즈 피드 포워드 신경망\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output) # Add & Norm"
      ],
      "metadata": {
        "id": "YmLtGjjvo6eR"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos_emb = tf.keras.layers.Embedding(max_len, embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        max_len = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "id": "UF7-GaQ_o8iC"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "c4n0uGMio9oM"
      },
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 32  # 각 단어의 임베딩 벡터의 차원\n",
        "num_heads = 2  # 어텐션 헤드의 수\n",
        "dff = 32  # 포지션 와이즈 피드 포워드 신경망의 은닉층의 크기\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(max_len,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
        "x = transformer_block(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "outputs = tf.keras.layers.Dense(11, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "4pYfP2Eeo-76"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model_path = 'best-transforemr-attention.h5py'\n",
        "mc = ModelCheckpoint(model_path, verbose=1, save_best_only=True)\n",
        "es = EarlyStopping(patience=3)"
      ],
      "metadata": {
        "id": "d5GNiH2VpALA"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, Y_train, validation_split=0.2,\n",
        "                    batch_size=128, epochs=100, callbacks=[mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eeL2WcOpCfu",
        "outputId": "d9c9c77f-7e2a-464a-e7e2-a97d70926a3b"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "236/238 [============================>.] - ETA: 0s - loss: 19.5956 - accuracy: 0.0965\n",
            "Epoch 1: val_loss improved from inf to 11.09348, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_44_layer_call_fn, embedding_44_layer_call_and_return_conditional_losses, embedding_45_layer_call_fn, embedding_45_layer_call_and_return_conditional_losses, multi_head_attention_6_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7f3f4e2a3390> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r238/238 [==============================] - 7s 31ms/step - loss: 19.5950 - accuracy: 0.0965 - val_loss: 11.0935 - val_accuracy: 0.0868\n",
            "Epoch 2/100\n",
            "237/238 [============================>.] - ETA: 0s - loss: 19.5039 - accuracy: 0.0928\n",
            "Epoch 2: val_loss did not improve from 11.09348\n",
            "238/238 [==============================] - 2s 10ms/step - loss: 19.5056 - accuracy: 0.0928 - val_loss: 24.0235 - val_accuracy: 0.1140\n",
            "Epoch 3/100\n",
            "238/238 [==============================] - ETA: 0s - loss: 31.9577 - accuracy: 0.0970\n",
            "Epoch 3: val_loss did not improve from 11.09348\n",
            "238/238 [==============================] - 2s 10ms/step - loss: 31.9577 - accuracy: 0.0970 - val_loss: 24.4832 - val_accuracy: 0.0993\n",
            "Epoch 4/100\n",
            "234/238 [============================>.] - ETA: 0s - loss: 38.0051 - accuracy: 0.0917\n",
            "Epoch 4: val_loss did not improve from 11.09348\n",
            "238/238 [==============================] - 2s 10ms/step - loss: 38.1576 - accuracy: 0.0915 - val_loss: 81.0570 - val_accuracy: 0.0409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model(model_path)\n",
        "best_model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkcd7P5qpDqP",
        "outputId": "ef609d0b-3c76-4c1a-dc71-88625c9f75d8"
      },
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "297/297 [==============================] - 2s 7ms/step - loss: 11.0119 - accuracy: 0.0825\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11.011927604675293, 0.0824720486998558]"
            ]
          },
          "metadata": {},
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM"
      ],
      "metadata": {
        "id": "6pIjOoRfpeIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "gBOrKzzypfOH"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 128, input_length=max_len)(inputs)\n",
        "\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(em)\n",
        "x = Dropout(0.1)(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "outputs = Dense(11, activation='softmax')(x)\n",
        "\n",
        "model2 = Model(inputs = inputs, outputs = outputs)\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzmfYHqvphTp",
        "outputId": "b6376c05-4674-4716-c5f9-165d3a13634a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_9 (Embedding)     (None, 100, 128)          4734336   \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (None, 100, 256)         263168    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 100, 256)          0         \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 11)                2827      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,000,331\n",
            "Trainable params: 5,000,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2_path = 'best-bilstm.h5'\n",
        "mc2 = ModelCheckpoint(model2_path, verbose=1, save_best_only=True)\n",
        "es2 = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "7i2F7s2Ypiim"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model2.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc2, es2]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGCadgvUpkoo",
        "outputId": "d1051269-cc2a-43f4-9f44-0566606f0479"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 2.7947 - accuracy: 0.1774\n",
            "Epoch 1: val_loss improved from inf to 2.51077, saving model to best-bilstm.h5\n",
            "238/238 [==============================] - 70s 266ms/step - loss: 2.7947 - accuracy: 0.1774 - val_loss: 2.5108 - val_accuracy: 0.2982\n",
            "Epoch 2/30\n",
            "236/238 [============================>.] - ETA: 0s - loss: 2.1253 - accuracy: 0.4619\n",
            "Epoch 2: val_loss improved from 2.51077 to 1.99253, saving model to best-bilstm.h5\n",
            "238/238 [==============================] - 6s 23ms/step - loss: 2.1248 - accuracy: 0.4617 - val_loss: 1.9925 - val_accuracy: 0.4803\n",
            "Epoch 3/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 1.8541 - accuracy: 0.5535\n",
            "Epoch 3: val_loss improved from 1.99253 to 1.98132, saving model to best-bilstm.h5\n",
            "238/238 [==============================] - 6s 24ms/step - loss: 1.8541 - accuracy: 0.5535 - val_loss: 1.9813 - val_accuracy: 0.5202\n",
            "Epoch 4/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 1.6861 - accuracy: 0.6160\n",
            "Epoch 4: val_loss did not improve from 1.98132\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 1.6861 - accuracy: 0.6160 - val_loss: 1.9910 - val_accuracy: 0.5564\n",
            "Epoch 5/30\n",
            "236/238 [============================>.] - ETA: 0s - loss: 1.6388 - accuracy: 0.6391\n",
            "Epoch 5: val_loss did not improve from 1.98132\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 1.6408 - accuracy: 0.6385 - val_loss: 2.0747 - val_accuracy: 0.5404\n",
            "Epoch 6/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.8111 - accuracy: 0.5917\n",
            "Epoch 6: val_loss did not improve from 1.98132\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 1.8112 - accuracy: 0.5917 - val_loss: 2.1448 - val_accuracy: 0.5318\n",
            "Epoch 7/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.6384 - accuracy: 0.6419\n",
            "Epoch 7: val_loss did not improve from 1.98132\n",
            "238/238 [==============================] - 6s 25ms/step - loss: 1.6383 - accuracy: 0.6420 - val_loss: 2.1525 - val_accuracy: 0.5303\n",
            "Epoch 8/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.6011 - accuracy: 0.6669\n",
            "Epoch 8: val_loss did not improve from 1.98132\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 1.6013 - accuracy: 0.6669 - val_loss: 2.9323 - val_accuracy: 0.4489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model2 = load_model(model2_path)\n",
        "best_model2.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyoZGMyVplu9",
        "outputId": "eda4579b-a4ae-4587-9f78-77b161ff00f8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "297/297 [==============================] - 3s 8ms/step - loss: 1.9721 - accuracy: 0.5128\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9720739126205444, 0.5127609968185425]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM + LSTM"
      ],
      "metadata": {
        "id": "UBwTTu6WqLNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional, LayerNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "vS9_9RyXqOZS"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model3"
      ],
      "metadata": {
        "id": "dbLh58UJqxiT"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 512, input_length=max_len)(inputs)\n",
        "\n",
        "x = Bidirectional(LSTM(256, return_sequences=True))(em)\n",
        "x = LayerNormalization(epsilon=1e-6)(em + x)\n",
        "# x = Conv1D(256, 5, activation='relu')(x)\n",
        "# x = GlobalMaxPooling1D()(x)\n",
        "x = LSTM(512)(x)\n",
        "# x = Dropout(0.1)(x)\n",
        "outputs = Dense(11, activation='softmax')(x)\n",
        "\n",
        "model3 = Model(inputs = inputs, outputs = outputs)\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8hfkXehqP6N",
        "outputId": "7c6d1da0-6c4e-4fba-e009-c6936e880607"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_29\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_34 (InputLayer)          [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_35 (Embedding)       (None, 100, 512)     18937344    ['input_34[0][0]']               \n",
            "                                                                                                  \n",
            " bidirectional_35 (Bidirectiona  (None, 100, 512)    1574912     ['embedding_35[0][0]']           \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_20 (TFOpL  (None, 100, 512)    0           ['embedding_35[0][0]',           \n",
            " ambda)                                                           'bidirectional_35[0][0]']       \n",
            "                                                                                                  \n",
            " layer_normalization_24 (LayerN  (None, 100, 512)    1024        ['tf.__operators__.add_20[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " lstm_61 (LSTM)                 (None, 512)          2099200     ['layer_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " dense_59 (Dense)               (None, 11)           5643        ['lstm_61[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22,618,123\n",
            "Trainable params: 22,618,123\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3_path = 'best-bilstm-lstm.h5'\n",
        "mc3 = ModelCheckpoint(model3_path, verbose=1, save_best_only=True)\n",
        "es3 = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "ls8kJK5UqViC"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model3.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=50, batch_size=128, callbacks=[mc3, es3]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2PtavLkqXty",
        "outputId": "2ff90d93-4e8f-40c4-8157-ad6783ecb366"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.7482 - accuracy: 0.5953\n",
            "Epoch 1: val_loss improved from inf to 1.50746, saving model to best-bilstm-lstm.h5\n",
            "238/238 [==============================] - 35s 128ms/step - loss: 1.7484 - accuracy: 0.5953 - val_loss: 1.5075 - val_accuracy: 0.7374\n",
            "Epoch 2/50\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.5650 - accuracy: 0.7538\n",
            "Epoch 2: val_loss did not improve from 1.50746\n",
            "238/238 [==============================] - 29s 123ms/step - loss: 1.5672 - accuracy: 0.7537 - val_loss: 1.9192 - val_accuracy: 0.7168\n",
            "Epoch 3/50\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.7350 - accuracy: 0.7733\n",
            "Epoch 3: val_loss did not improve from 1.50746\n",
            "238/238 [==============================] - 29s 121ms/step - loss: 1.7349 - accuracy: 0.7733 - val_loss: 2.8980 - val_accuracy: 0.6784\n",
            "Epoch 4/50\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.9206 - accuracy: 0.7904\n",
            "Epoch 4: val_loss did not improve from 1.50746\n",
            "238/238 [==============================] - 29s 121ms/step - loss: 1.9204 - accuracy: 0.7904 - val_loss: 3.4747 - val_accuracy: 0.6912\n",
            "Epoch 5/50\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.8680 - accuracy: 0.8047\n",
            "Epoch 5: val_loss did not improve from 1.50746\n",
            "238/238 [==============================] - 29s 121ms/step - loss: 1.8687 - accuracy: 0.8046 - val_loss: 5.5198 - val_accuracy: 0.6438\n",
            "Epoch 6/50\n",
            "237/238 [============================>.] - ETA: 0s - loss: 2.0566 - accuracy: 0.8028\n",
            "Epoch 6: val_loss did not improve from 1.50746\n",
            "238/238 [==============================] - 29s 122ms/step - loss: 2.0567 - accuracy: 0.8028 - val_loss: 5.2125 - val_accuracy: 0.7147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model3 = load_model(model3_path)\n",
        "best_model3.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbZ4nbsGqZEp",
        "outputId": "78aaa222-035f-4f27-cd4e-4388da82f6cb"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "297/297 [==============================] - 6s 15ms/step - loss: 1.4836 - accuracy: 0.7311\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4835562705993652, 0.7310693860054016]"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smile_train.iloc[:, 1:].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq7kw1lBEX7H",
        "outputId": "249368ef-abec-45df-e483-56828eda7cf5"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 1, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 1, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model3.evaluate(strain_data, smile_train.iloc[:, 1:].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMZUAqsEEQze",
        "outputId": "3a8120f1-b129-4cfb-dd87-8892ce197bc6"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "460/460 [==============================] - 8s 17ms/step - loss: 1.3336 - accuracy: 0.6649\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3336364030838013, 0.6649421453475952]"
            ]
          },
          "metadata": {},
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = best_model3.predict(X_test)"
      ],
      "metadata": {
        "id": "OA28wGcY-TPM"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smile_train[smile_train['개인지칭'] != 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VFp0R03gD3Iw",
        "outputId": "58f1aa31-2e18-455a-8a1b-0a20bffc2248"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       여성/가족  남성  성소수자  인종/국적  연령  지역  종교  기타 혐오  악플/욕설  clean  개인지칭\n",
              "0          0   0     0      0   0   0   0      0      0      1     0\n",
              "1          0   0     0      0   0   0   1      0      0      0     0\n",
              "2          0   0     0      0   0   0   0      0      0      1     0\n",
              "3          0   0     0      0   0   0   0      0      0      1     0\n",
              "4          1   0     0      0   0   0   0      0      0      0     0\n",
              "...      ...  ..   ...    ...  ..  ..  ..    ...    ...    ...   ...\n",
              "15000      0   0     0      0   0   0   0      0      0      1     0\n",
              "15001      0   0     0      0   0   1   0      0      0      0     0\n",
              "15002      1   0     0      1   0   0   0      0      0      0     0\n",
              "15003      0   0     0      0   0   0   0      0      1      0     0\n",
              "15004      0   0     0      0   1   0   0      0      0      0     0\n",
              "\n",
              "[15005 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f0f424c-2657-4ef9-9fca-35b882dbd1af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타 혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "      <th>개인지칭</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15000</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15001</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15002</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15003</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15004</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15005 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f0f424c-2657-4ef9-9fca-35b882dbd1af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f0f424c-2657-4ef9-9fca-35b882dbd1af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f0f424c-2657-4ef9-9fca-35b882dbd1af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = df.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\")"
      ],
      "metadata": {
        "id": "GWXihsJ4vel0"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num=15000\n",
        "text = smile_train['문장'][num]\n",
        "print(sentiment_predict(text, best_model3,tokenizer=t, max_len=max_len))\n",
        "print(smile_train.loc[num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYMlHC6kAxRj",
        "outputId": "be23c66c-9f72-4a7a-fe9d-2cdbce179fe2"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'께롱께롱께롱'\n",
            " 87.7479076385498%의 확률로 clean에 대한 악플입니다.\n",
            "None\n",
            "문장       께롱께롱께롱!!!\n",
            "여성/가족            0\n",
            "남성               0\n",
            "성소수자             0\n",
            "인종/국적            0\n",
            "연령               0\n",
            "지역               0\n",
            "종교               0\n",
            "기타 혐오            0\n",
            "악플/욕설            0\n",
            "clean            1\n",
            "개인지칭             0\n",
            "Name: 15000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num=9000\n",
        "text = df['문장'][num]\n",
        "print(sentiment_predict(text, best_model3,tokenizer=t, max_len=max_len))\n",
        "print(df.loc[num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LLqx2NTvgN8",
        "outputId": "fdde4bf8-b8a6-48bb-f53f-1889b5ad2bdf"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'뭔 저런 벙신이 검사출신이데  등신도 저런 등신은 없었네  역대급 등신 출몰이네  아니면 기레기들 소음 까지도 기사로 취급하는 놈 까지도    이지'\n",
            " 47.057145833969116%의 확률로 기타혐오에 대한 악플입니다.\n",
            "None\n",
            "문장       뭔 저런 벙신이 검사출신이데  등신도 저런 등신은 없었네  역대급 등신 출몰이네  ...\n",
            "여성/가족                                                    0\n",
            "남성                                                       0\n",
            "성소수자                                                     0\n",
            "인종/국적                                                    0\n",
            "연령                                                       0\n",
            "지역                                                       0\n",
            "종교                                                       0\n",
            "기타혐오                                                     1\n",
            "악플/욕설                                                    1\n",
            "clean                                                    0\n",
            "분쟁유발                                                   0.0\n",
            "Name: 9000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3ENQ8_wL7hZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN + BiLSTM + LSTM"
      ],
      "metadata": {
        "id": "eDSOoC1dyC1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Dropout, Bidirectional, LayerNormalization, Conv1D, Reshape\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "ZnThUWNSwvlQ"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model4"
      ],
      "metadata": {
        "id": "lIXK5OEDzxgM"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(max_len,))\n",
        "em = Embedding(vocab_size, 256, input_length=max_len)(inputs)\n",
        "\n",
        "x = Conv1D(256, 5, activation='relu')(em)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "x = LSTM(128)(x)\n",
        "# x = GlobalMaxPooling1D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(11, activation='softmax')(x)\n",
        "\n",
        "model4 = Model(inputs = inputs, outputs = outputs)\n",
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXe6JWT6yGvQ",
        "outputId": "9e766f41-1ade-45b4-a1c1-e2b1b8c2ad79"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_22 (InputLayer)       [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_23 (Embedding)    (None, 100, 256)          9468672   \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 96, 256)           327936    \n",
            "                                                                 \n",
            " bidirectional_23 (Bidirecti  (None, 96, 256)          394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " lstm_37 (LSTM)              (None, 128)               197120    \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 11)                1419      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,389,387\n",
            "Trainable params: 10,389,387\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model4_path = 'best-cnn-bilstm-lstm.h5'\n",
        "mc4 = ModelCheckpoint(model4_path, verbose=1, save_best_only=True)\n",
        "es4 = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "12RVVEVpyIrQ"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model4.fit(\n",
        "    X_train, Y_train, validation_split=0.2,\n",
        "    epochs=30, batch_size=128, callbacks=[mc4, es4]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vyCd042yLCx",
        "outputId": "6ae86157-d050-4548-dc2d-e303227fefa4"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "238/238 [==============================] - ETA: 0s - loss: 2.8160 - accuracy: 0.2669\n",
            "Epoch 1: val_loss improved from inf to 1.95072, saving model to best-cnn-bilstm-lstm.h5\n",
            "238/238 [==============================] - 16s 49ms/step - loss: 2.8160 - accuracy: 0.2669 - val_loss: 1.9507 - val_accuracy: 0.5051\n",
            "Epoch 2/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 2.0635 - accuracy: 0.5611\n",
            "Epoch 2: val_loss improved from 1.95072 to 1.63866, saving model to best-cnn-bilstm-lstm.h5\n",
            "238/238 [==============================] - 10s 44ms/step - loss: 2.0637 - accuracy: 0.5611 - val_loss: 1.6387 - val_accuracy: 0.6210\n",
            "Epoch 3/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.8955 - accuracy: 0.6276\n",
            "Epoch 3: val_loss did not improve from 1.63866\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.8955 - accuracy: 0.6275 - val_loss: 1.8558 - val_accuracy: 0.6160\n",
            "Epoch 4/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.9052 - accuracy: 0.6319\n",
            "Epoch 4: val_loss did not improve from 1.63866\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.9050 - accuracy: 0.6320 - val_loss: 1.7791 - val_accuracy: 0.6349\n",
            "Epoch 5/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.8559 - accuracy: 0.6608\n",
            "Epoch 5: val_loss did not improve from 1.63866\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.8564 - accuracy: 0.6608 - val_loss: 2.2520 - val_accuracy: 0.5901\n",
            "Epoch 6/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.8982 - accuracy: 0.6621\n",
            "Epoch 6: val_loss did not improve from 1.63866\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.8983 - accuracy: 0.6620 - val_loss: 2.4088 - val_accuracy: 0.6224\n",
            "Epoch 7/30\n",
            "237/238 [============================>.] - ETA: 0s - loss: 1.8988 - accuracy: 0.6764\n",
            "Epoch 7: val_loss did not improve from 1.63866\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.8985 - accuracy: 0.6764 - val_loss: 2.4803 - val_accuracy: 0.6252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model4 = load_model(model4_path)\n",
        "best_model4.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx2dRbD4yS7X",
        "outputId": "0f875d20-8b73-4d0f-bde9-e548d7a80a15"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "297/297 [==============================] - 4s 10ms/step - loss: 1.6609 - accuracy: 0.6170\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6609307527542114, 0.6169584393501282]"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    }
  ]
}